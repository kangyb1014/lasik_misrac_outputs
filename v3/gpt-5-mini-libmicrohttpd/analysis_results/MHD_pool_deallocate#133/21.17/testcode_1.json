{
  "user_message": "<misra_rule>\nMISRA C 2023 Rule 21.17 is: Use of the string handling functions from <string.h> shall not result in accesses beyond the bounds of the objects referenced by their pointer parameters.\nThis rule strictly applies to the Standard Library functions in <string.h> such as memcpy, memmove, memset, memcmp, strcpy, strncpy, strcat, strncat, strlen, and strspn.\n</misra_rule>\n\nAnother agent reported that the target code violated the Rule 21.17.\nHere is the comment from the agent.\n<violation scenario>\nYes \u2014 the call can write past the pool memory because there is no guaranteed check that (block + block_size) stays within the object bounds. For example, if pool->size == 100, block == pool->memory + 80 (block_offset == 80) and block_size == 80 (note block_size <= pool->size holds), then _MHD_POISON_MEMORY(block, block_size) (presumably wrapping memset) will write bytes from offset 80..159, exceeding pool->memory + pool->size. The code only contains debug assertions (mhd_assert) that might detect some invalid situations but they are not enforced in release builds, so out\u2011of\u2011bounds accesses are possible and thus Rule 21.17 is violated.\n</violation scenario>\n\nYour job is to insert logging code to capture the control flow and state information of the program.\nInsert logging code so that other agents can reproduce and get evidence for the violation scenario.\n<response format>\n- test_code: a modified MHD_pool_deallocate code that contains useful probe functions that print useful logs to a file \"/tmp/logs/1339.txt\". The logs should contain the control path and state information of the violation scenario. If test code is not required to validate the scenario, you can leave this blank.\nHere are the constraints for the test code:\n- The test code MUST preserve the original logic of MHD_pool_deallocate as much as possible.\nYou CAN just insert probe functions to the original code.\n- DO NOT introduce new violations to demonstrate your scenario.\n- The test code MUST be compilable and executable.\n- The test code MUST include line breaks.\n- You MUST NOT define the main function.\n- You MUST NOT define macros.\n</response format>\n<target_code>\nHere is the code of MHD_pool_deallocate:\n```c\nvoid\nMHD_pool_deallocate (struct MemoryPool *pool,\n                     void *block,\n                     size_t block_size)\n{\n  mhd_assert (pool->end >= pool->pos);\n  mhd_assert (pool->size >= pool->end - pool->pos);\n  mhd_assert (block != NULL || block_size == 0);\n  mhd_assert (pool->size >= block_size);\n  mhd_assert (pool->pos == ROUND_TO_ALIGN (pool->pos));\n\n  if (NULL != block)\n  {   /* Have previously allocated data */\n    const size_t block_offset = mp_ptr_diff_ (block, pool->memory);\n    mhd_assert (mp_ptr_le_ (pool->memory, block));\n    mhd_assert (block_offset <= pool->size);\n    mhd_assert ((block_offset != pool->pos) || (block_size == 0));\n    /* Zero-out deallocated region */\n    if (0 != block_size)\n    {\n      memset (block, 0, block_size);\n      _MHD_POISON_MEMORY (block, block_size);\n    }\n#if ! defined(MHD_FAVOR_SMALL_CODE) && ! defined(MHD_ASAN_POISON_ACTIVE)\n    else\n      return; /* Zero size, no need to do anything */\n#endif /* ! MHD_FAVOR_SMALL_CODE && ! MHD_ASAN_POISON_ACTIVE */\n    if (block_offset <= pool->pos)\n    {\n      /* \"Normal\" block, not allocated \"from the end\". */\n      const size_t alg_end =\n        ROUND_TO_ALIGN_PLUS_RED_ZONE (block_offset + block_size);\n      mhd_assert (alg_end <= pool->pos);\n      if (alg_end == pool->pos)\n      {\n        /* The last allocated block, return deallocated block to the pool */\n        size_t alg_start = ROUND_TO_ALIGN (block_offset);\n        mhd_assert (alg_start >= block_offset);\n#if defined(MHD_ASAN_POISON_ACTIVE)\n        if (alg_start != block_offset)\n        {\n          _MHD_POISON_MEMORY (pool->memory + block_offset, \\\n                              alg_start - block_offset);\n        }\n        else if (0 != alg_start)\n        {\n          bool need_red_zone_before;\n          mhd_assert (_MHD_RED_ZONE_SIZE <= alg_start);\n#if defined(HAVE___ASAN_REGION_IS_POISONED)\n          need_red_zone_before =\n            (NULL == __asan_region_is_poisoned (pool->memory\n                                                + alg_start\n                                                - _MHD_RED_ZONE_SIZE,\n                                                _MHD_RED_ZONE_SIZE));\n#elif defined(HAVE___ASAN_ADDRESS_IS_POISONED)\n          need_red_zone_before =\n            (0 == __asan_address_is_poisoned (pool->memory + alg_start - 1));\n#else  /* ! HAVE___ASAN_ADDRESS_IS_POISONED */\n          need_red_zone_before = true; /* Unknown, assume new red zone needed */\n#endif /* ! HAVE___ASAN_ADDRESS_IS_POISONED */\n          if (need_red_zone_before)\n          {\n            _MHD_POISON_MEMORY (pool->memory + alg_start, _MHD_RED_ZONE_SIZE);\n            alg_start += _MHD_RED_ZONE_SIZE;\n          }\n        }\n#endif /* MHD_ASAN_POISON_ACTIVE */\n        mhd_assert (alg_start <= pool->pos);\n        mhd_assert (alg_start == ROUND_TO_ALIGN (alg_start));\n        pool->pos = alg_start;\n      }\n    }\n    else\n    {\n      /* Allocated \"from the end\" block. */\n      /* The size and the pointers of such block should not be manipulated by\n         MHD code (block split is disallowed). */\n      mhd_assert (block_offset >= pool->end);\n      mhd_assert (ROUND_TO_ALIGN (block_offset) == block_offset);\n      if (block_offset == pool->end)\n      {\n        /* The last allocated block, return deallocated block to the pool */\n        const size_t alg_end =\n          ROUND_TO_ALIGN_PLUS_RED_ZONE (block_offset + block_size);\n        pool->end = alg_end;\n      }\n    }\n  }\n}\n```\n</target_code>\nPlease provide the modified MHD_pool_deallocate code.\n",
  "test_code": "#include <stdio.h>\n#include <stdarg.h>\n#include <stddef.h>\n\n/* Probe logging helpers \u2014 write append-only logs to /tmp/logs/1339.txt */\nstatic void\nmhd_logf (const char *fmt, ...)\n{\n  FILE *f = fopen(\"/tmp/logs/1339.txt\", \"a\");\n  if (NULL == f)\n    return;\n  va_list ap;\n  va_start (ap, fmt);\n  vfprintf (f, fmt, ap);\n  va_end (ap);\n  fclose (f);\n}\n\nstatic void\nmhd_log_state (struct MemoryPool *pool, void *block, size_t block_size, const char *stage)\n{\n  if (NULL == pool)\n  {\n    mhd_logf (\"[MHD_POOL] %s: pool == NULL\\n\", stage);\n    return;\n  }\n  mhd_logf (\"[MHD_POOL] %s: pool=%p, memory=%p, pos=%zu, end=%zu, size=%zu\\n\",\n            stage, (void *)pool, (void *)pool->memory, pool->pos, pool->end, pool->size);\n  mhd_logf (\"[MHD_POOL] %s: block=%p, block_size=%zu\\n\", stage, block, block_size);\n  if (NULL != block)\n  {\n    const size_t block_offset = mp_ptr_diff_ (block, pool->memory);\n    mhd_logf (\"[MHD_POOL] %s: computed block_offset=%zu\\n\", stage, block_offset);\n    /* Log potential overflow of the region to be zeroed */\n    mhd_logf (\"[MHD_POOL] %s: block_offset + block_size = %zu, pool->size = %zu\\n\",\n              stage, (size_t)(block_offset + block_size), pool->size);\n  }\n  mhd_logf (\"[MHD_POOL] %s: ----\\n\", stage);\n}\n\nvoid\nMHD_pool_deallocate (struct MemoryPool *pool,\n                     void *block,\n                     size_t block_size)\n{\n  mhd_assert (pool->end >= pool->pos);\n  mhd_assert (pool->size >= pool->end - pool->pos);\n  mhd_assert (block != NULL || block_size == 0);\n  mhd_assert (pool->size >= block_size);\n  mhd_assert (pool->pos == ROUND_TO_ALIGN (pool->pos));\n\n  /* Log entry state */\n  mhd_log_state (pool, block, block_size, \"entry\");\n\n  if (NULL != block)\n  {   /* Have previously allocated data */\n    const size_t block_offset = mp_ptr_diff_ (block, pool->memory);\n    mhd_assert (mp_ptr_le_ (pool->memory, block));\n    mhd_assert (block_offset <= pool->size);\n    mhd_assert ((block_offset != pool->pos) || (block_size == 0));\n    /* Zero-out deallocated region */\n    if (0 != block_size)\n    {\n      /* Log before zeroing */\n      mhd_logf (\"[MHD_POOL] before memset: block=%p, block_size=%zu, block_offset=%zu\\n\",\n                block, block_size, block_offset);\n      mhd_logf (\"[MHD_POOL] before memset: block_end_index=%zu, pool_end_index=%zu\\n\",\n                (size_t)(block_offset + block_size), pool->size);\n\n      memset (block, 0, block_size);\n      _MHD_POISON_MEMORY (block, block_size);\n\n      /* Log after zeroing */\n      mhd_logf (\"[MHD_POOL] after memset: block=%p, block_size=%zu\\n\", block, block_size);\n    }\n#if ! defined(MHD_FAVOR_SMALL_CODE) && ! defined(MHD_ASAN_POISON_ACTIVE)\n    else\n    {\n      mhd_logf (\"[MHD_POOL] deallocate: zero size block, returning early\\n\");\n      return; /* Zero size, no need to do anything */\n    }\n#endif /* ! MHD_FAVOR_SMALL_CODE && ! MHD_ASAN_POISON_ACTIVE */\n    if (block_offset <= pool->pos)\n    {\n      /* \"Normal\" block, not allocated \"from the end\". */\n      const size_t alg_end =\n        ROUND_TO_ALIGN_PLUS_RED_ZONE (block_offset + block_size);\n\n      mhd_logf (\"[MHD_POOL] normal branch: alg_end=%zu, pool->pos=%zu\\n\",\n                alg_end, pool->pos);\n\n      mhd_assert (alg_end <= pool->pos);\n      if (alg_end == pool->pos)\n      {\n        /* The last allocated block, return deallocated block to the pool */\n        size_t alg_start = ROUND_TO_ALIGN (block_offset);\n        mhd_assert (alg_start >= block_offset);\n#if defined(MHD_ASAN_POISON_ACTIVE)\n        if (alg_start != block_offset)\n        {\n          _MHD_POISON_MEMORY (pool->memory + block_offset, \\\n                              alg_start - block_offset);\n        }\n        else if (0 != alg_start)\n        {\n          bool need_red_zone_before;\n          mhd_assert (_MHD_RED_ZONE_SIZE <= alg_start);\n#if defined(HAVE___ASAN_REGION_IS_POISONED)\n          need_red_zone_before =\n            (NULL == __asan_region_is_poisoned (pool->memory\n                                                + alg_start\n                                                - _MHD_RED_ZONE_SIZE,\n                                                _MHD_RED_ZONE_SIZE));\n#elif defined(HAVE___ASAN_ADDRESS_IS_POISONED)\n          need_red_zone_before =\n            (0 == __asan_address_is_poisoned (pool->memory + alg_start - 1));\n#else  /* ! HAVE___ASAN_ADDRESS_IS_POISONED */\n          need_red_zone_before = true; /* Unknown, assume new red zone needed */\n#endif /* ! HAVE___ASAN_ADDRESS_IS_POISONED */\n          if (need_red_zone_before)\n          {\n            _MHD_POISON_MEMORY (pool->memory + alg_start, _MHD_RED_ZONE_SIZE);\n            alg_start += _MHD_RED_ZONE_SIZE;\n          }\n        }\n#endif /* MHD_ASAN_POISON_ACTIVE */\n        mhd_assert (alg_start <= pool->pos);\n        mhd_assert (alg_start == ROUND_TO_ALIGN (alg_start));\n\n        /* Log the computed alg_start before assigning to pool->pos */\n        mhd_logf (\"[MHD_POOL] releasing to pool: alg_start=%zu (was pos=%zu)\\n\",\n                  alg_start, pool->pos);\n\n        pool->pos = alg_start;\n      }\n    }\n    else\n    {\n      /* Allocated \"from the end\" block. */\n      /* The size and the pointers of such block should not be manipulated by\n         MHD code (block split is disallowed). */\n      mhd_assert (block_offset >= pool->end);\n      mhd_assert (ROUND_TO_ALIGN (block_offset) == block_offset);\n      if (block_offset == pool->end)\n      {\n        /* The last allocated block, return deallocated block to the pool */\n        const size_t alg_end =\n          ROUND_TO_ALIGN_PLUS_RED_ZONE (block_offset + block_size);\n\n        mhd_logf (\"[MHD_POOL] end-allocated branch: block_offset=%zu, alg_end=%zu (was end=%zu)\\n\",\n                  block_offset, alg_end, pool->end);\n\n        pool->end = alg_end;\n      }\n    }\n  }\n}\n"
}