{
  "user_message": "<misra_rule>\nMISRA C 2023 Rule 8.13 is: A pointer should point to a const-qualified type whenever possible.\n\n</misra_rule>\n<response format>\nProvide your answer with these fields.\n- is_rule_violated: whether the rule is violated or not (true/false),\n- scenario: a specific violation scenario.\n</response format>\n<target_code>\nHere is the code of metal_linux_irq_init:\n```c\nint metal_linux_irq_init(void)\n{\n\tint ret;\n\n\tmemset(&irqs, 0, sizeof(irqs));\n\n\tirq_notify_fd = eventfd(0, EFD_CLOEXEC);\n\tif (irq_notify_fd < 0) {\n\t\tmetal_log(METAL_LOG_ERROR,\n\t\t\t  \"Failed to create eventfd for IRQ handling.\\n\");\n\t\treturn  -EAGAIN;\n\t}\n\n\tmetal_mutex_init(&irq_lock);\n\tirq_handling_stop = false;\n\tret = metal_irq_register_controller(&linux_irq_cntr);\n\tif (ret < 0) {\n\t\tmetal_log(METAL_LOG_ERROR,\n\t\t\t  \"Linux IRQ controller failed to register.\\n\");\n\t\treturn -EINVAL;\n\t}\n\tret = pthread_create(&irq_pthread, NULL,\n\t\t\t     metal_linux_irq_handling, NULL);\n\tif (ret != 0) {\n\t\tmetal_log(METAL_LOG_ERROR, \"Failed to create IRQ thread: %d.\\n\",\n\t\t\t  ret);\n\t\treturn -EAGAIN;\n\t}\n\n\treturn 0;\n}\n```\n</target_code>\n<additional code>Here are the definitions of symbols that are close to the target function metal_linux_irq_init:\nint metal_irq_register_controller(struct metal_irq_controller *cntr)\n{\n\tint irq_base;\n\tstruct metal_list *node;\n\n\tif (cntr == NULL) {\n\t\treturn -EINVAL;\n\t}\n\tmetal_list_for_each(&irq_cntrs, node) {\n\t\tif (node == &cntr->node) {\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\t/*\n\t * Allocate IRQ numbers which are not yet used by any IRQ\n\t * controllers.\n\t */\n\tirq_base = metal_irq_allocate(cntr->irq_base, cntr->irq_num);\n\tif (irq_base == METAL_IRQ_ANY) {\n\t\treturn -EINVAL;\n\t}\n\tcntr->irq_base = irq_base;\n\n\tmetal_list_add_tail(&irq_cntrs, &cntr->node);\n\treturn 0;\n}\n...\nstruct metal_irq_controller {\n\tint irq_base; /**< Start of IRQ number of the range managed by\n\t\t \t* the IRQ controller\n\t\t \t*/\n\tint irq_num; /**< Number of IRQs managed by the IRQ controller */\n\tvoid *arg; /**< Argument to pass to interrupt controller function */\n\tmetal_irq_set_enable irq_set_enable; /**< function to set IRQ enable */\n\tmetal_cntr_irq_register irq_register; /**< function to register IRQ\n\t\t\t\t\t\t* handler\n\t\t\t\t\t\t*/\n\tstruct metal_list node; /**< list node */\n\tstruct metal_irq *irqs; /**< Array of IRQs managed by the controller */\n}\n...\nstatic METAL_IRQ_CONTROLLER_DECLARE(linux_irq_cntr,\n\t\t\t\t    0, MAX_IRQS,\n\t\t\t\t    NULL,\n\t\t\t\t    metal_linux_irq_set_enable, NULL,\n\t\t\t\t    irqs)\n...\nstatic int metal_irq_allocate(int irq_base, int irq_num)\n{\n\tstruct metal_list *node;\n\tstruct metal_irq_controller *cntr;\n\tint irq_tocheck = irq_base, irq_end_tocheck;\n\n\tif (irq_num == 0) {\n\t\treturn METAL_IRQ_ANY;\n\t}\n\tif (irq_tocheck == METAL_IRQ_ANY) {\n\t\tirq_tocheck = 0;\n\t}\n\tirq_end_tocheck = irq_tocheck + irq_num;\n\n\tmetal_list_for_each(&irq_cntrs, node) {\n\t\tint cntr_irq_base, cntr_irq_end;\n\n\t\tcntr = metal_container_of(node,\n\t\t\t\t\t  struct metal_irq_controller, node);\n\t\tcntr_irq_base = cntr->irq_base;\n\t\tcntr_irq_end = cntr_irq_base + cntr->irq_num;\n\t\tif (irq_tocheck < cntr_irq_end &&\n\t\t    irq_end_tocheck > cntr_irq_base) {\n\t\t\tif (irq_base != METAL_IRQ_ANY) {\n\t\t\t\t/* IRQ has been allocated */\n\t\t\t\treturn METAL_IRQ_ANY;\n\t\t\t}\n\t\t\tirq_tocheck = cntr_irq_end;\n\t\t\tirq_end_tocheck = irq_tocheck + irq_num;\n\t\t}\n\t}\n\treturn irq_tocheck;\n}\n...\nstatic metal_mutex_t irq_lock\n...\n#define metal_log(level, fmt, __VA_ARGS__) ({if(_metal.common.log_handler&&level<=_metal.common.log_level)_metal.common.log_handler(level,metal_fmt(fmt),##__VA_ARGS__);\\\n})\n...\nstatic void *metal_linux_irq_handling(void *args)\n{\n\tstruct sched_param param;\n\tuint64_t val;\n\tint ret;\n\tint i, j, pfds_total;\n\tstruct pollfd *pfds;\n\n\t(void)args;\n\n\tpfds = (struct pollfd *)malloc(FD_SETSIZE * sizeof(struct pollfd));\n\tif (!pfds) {\n\t\tmetal_log(METAL_LOG_ERROR,\n\t\t\t  \"%s: failed to allocate irq fds mem.\\n\", __func__);\n\t\treturn NULL;\n\t}\n\n\tparam.sched_priority = sched_get_priority_max(SCHED_FIFO);\n\t/* Ignore the set scheduler error */\n\tret = sched_setscheduler(0, SCHED_FIFO, &param);\n\tif (ret) {\n\t\tmetal_log(METAL_LOG_WARNING,\n\t\t\t  \"%s: Failed to set scheduler: %s.\\n\", __func__,\n\t\t\t  strerror(ret));\n\t}\n\n\twhile (1) {\n\t\tmetal_mutex_acquire(&irq_lock);\n\t\tif (irq_handling_stop) {\n\t\t\t/* Killing this IRQ handling thread */\n\t\t\tmetal_mutex_release(&irq_lock);\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Get the fdset */\n\t\tmemset(pfds, 0, MAX_IRQS * sizeof(struct pollfd));\n\t\tpfds[0].fd = irq_notify_fd;\n\t\tpfds[0].events = POLLIN;\n\t\tj = 1;\n\t\tmetal_bitmap_for_each_set_bit(irqs_enabled, i,\n\t\t\t\t\t      linux_irq_cntr.irq_num) {\n\t\t\tpfds[j].fd = i;\n\t\t\tpfds[j].events = POLLIN;\n\t\t\tj++;\n\t\t}\n\t\tmetal_mutex_release(&irq_lock);\n\t\t/* Wait for interrupt */\n\t\tret = poll(pfds, j, -1);\n\t\tif (ret < 0) {\n\t\t\tmetal_log(METAL_LOG_ERROR, \"%s: poll() failed: %s.\\n\",\n\t\t\t\t  __func__, strerror(errno));\n\t\t\tbreak;\n\t\t}\n\t\t/* Waken up from interrupt */\n\t\tpfds_total = j;\n\t\tfor (i = 0; i < pfds_total; i++) {\n\t\t\tif ((pfds[i].fd == irq_notify_fd) &&\n\t\t\t    (pfds[i].revents & (POLLIN | POLLRDNORM))) {\n\t\t\t\t/* IRQ registration change notification */\n\t\t\t\tif (read(pfds[i].fd,\n\t\t\t\t\t (void *)&val, sizeof(uint64_t)) < 0)\n\t\t\t\t\tmetal_log(METAL_LOG_ERROR,\n\t\t\t\t\t\t  \"%s, read irq fd %d failed\\n\",\n\t\t\t\t\t\t  __func__, pfds[i].fd);\n\t\t\t} else if ((pfds[i].revents & (POLLIN | POLLRDNORM))) {\n\t\t\t\tstruct metal_device *dev = NULL;\n\t\t\t\tint irq_handled = 0;\n\t\t\t\tint fd;\n\n\t\t\t\tfd = pfds[i].fd;\n\t\t\t\tdev = irqs_devs[fd];\n\t\t\t\tmetal_mutex_acquire(&irq_lock);\n\t\t\t\tif (metal_irq_handle(&irqs[fd], fd)\n\t\t\t\t    == METAL_IRQ_HANDLED)\n\t\t\t\t\tirq_handled = 1;\n\t\t\t\tif (irq_handled) {\n\t\t\t\t\tif (dev && dev->bus->ops.dev_irq_ack)\n\t\t\t\t\t\tdev->bus->ops.dev_irq_ack(\n\t\t\t\t\t\t\tdev->bus, dev, fd);\n\t\t\t\t}\n\t\t\t\tmetal_mutex_release(&irq_lock);\n\t\t\t} else if (pfds[i].revents) {\n\t\t\t\tmetal_log(METAL_LOG_DEBUG,\n\t\t\t\t\t  \"%s: poll unexpected. fd %d: %d\\n\",\n\t\t\t\t\t  __func__,\n\t\t\t\t\t  pfds[i].fd, pfds[i].revents);\n\t\t\t}\n\t\t}\n\t}\n\tfree(pfds);\n\treturn NULL;\n}\n...\nstatic struct metal_irq irqs[MAX_IRQS]\n...\nstatic pthread_t irq_pthread\n</additional code>\n<target_code>\nHere is the code fragment that you need to analyze:\n```c\nstruct metal_irq_controller *cntr;\n```\nFocus on the above code fragment and judge whether it violates the rule 8.13 or not.\n</target_code>\n",
  "is_rule_violated": true,
  "scenario": "In metal_irq_allocate the local pointer 'struct metal_irq_controller *cntr;' is only used to read fields (cntr->irq_base, cntr->irq_num) after being set via metal_container_of. Because the pointed-to object is not modified through cntr in that function, the pointer could and should be declared as pointing to a const-qualified type (const struct metal_irq_controller *cntr). Therefore the current declaration violates MISRA C 2023 Rule 8.13. Note: other places (e.g. metal_irq_register_controller where cntr->irq_base is assigned) must remain non-const, but this local variable in metal_irq_allocate should be const."
}