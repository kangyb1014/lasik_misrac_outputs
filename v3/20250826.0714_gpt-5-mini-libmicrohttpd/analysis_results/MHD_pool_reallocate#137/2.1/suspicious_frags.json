{
  "user_message": "<misra_rule>\nThe target MISRA C 2023 Rule 2.1 is: A project shall not contain unreachable code.\n\n</misra_rule>\n<instruction>\nOther agents will judge whether the code follows the MISRA C 2023 guidelines.\nThey will investigate the code fragments you give.\nYour job is to find code fragments in the code that should be investigated to check whether the code follows the MISRA C rule.\n</instruction>\n<response format>\nProvide your answer with these fields.\n- suspicious_frags: The list of suspicious code fragments in the code.\nIt should contain only the code fragments exists in the code. If you do not find any suspicious code fragments, return an empty list for suspicious_frags\n- explanation: The explanation of why other code fragments should NOT be investigated.\nIt is very important to not miss any suspicious code fragments, so please give a sufficient explanation why other code fragments should not be investigated.\nDO NOT give any explanation for the selected suspicious code fragments.\n</response format>\n<target_code>\nHere is the code of MHD_pool_reallocate:\n```c\nvoid *\nMHD_pool_reallocate (struct MemoryPool *pool,\n                     void *old,\n                     size_t old_size,\n                     size_t new_size)\n{\n  size_t asize;\n  uint8_t *new_blc;\n\n  mhd_assert (pool->end >= pool->pos);\n  mhd_assert (pool->size >= pool->end - pool->pos);\n  mhd_assert (old != NULL || old_size == 0);\n  mhd_assert (pool->size >= old_size);\n  mhd_assert (pool->pos == ROUND_TO_ALIGN (pool->pos));\n#if defined(MHD_ASAN_POISON_ACTIVE) && defined(HAVE___ASAN_REGION_IS_POISONED)\n  mhd_assert (NULL == __asan_region_is_poisoned (old, old_size));\n#endif /* MHD_ASAN_POISON_ACTIVE && HAVE___ASAN_REGION_IS_POISONED */\n\n  if (NULL != old)\n  {   /* Have previously allocated data */\n    const size_t old_offset = mp_ptr_diff_ (old, pool->memory);\n    const bool shrinking = (old_size > new_size);\n\n    mhd_assert (mp_ptr_le_ (pool->memory, old));\n    /* (pool->memory + pool->size >= (uint8_t*) old + old_size) */\n    mhd_assert ((pool->size - _MHD_RED_ZONE_SIZE) >= (old_offset + old_size));\n    /* Blocks \"from the end\" must not be reallocated */\n    /* (old_size == 0 || pool->memory + pool->pos > (uint8_t*) old) */\n    mhd_assert ((old_size == 0) || \\\n                (pool->pos > old_offset));\n    mhd_assert ((old_size == 0) || \\\n                ((pool->end - _MHD_RED_ZONE_SIZE) >= (old_offset + old_size)));\n    /* Try resizing in-place */\n    if (shrinking)\n    {     /* Shrinking in-place, zero-out freed part */\n      memset ((uint8_t *) old + new_size, 0, old_size - new_size);\n      _MHD_POISON_MEMORY ((uint8_t *) old + new_size, old_size - new_size);\n    }\n    if (pool->pos ==\n        ROUND_TO_ALIGN_PLUS_RED_ZONE (old_offset + old_size))\n    {     /* \"old\" block is the last allocated block */\n      const size_t new_apos =\n        ROUND_TO_ALIGN_PLUS_RED_ZONE (old_offset + new_size);\n      if (! shrinking)\n      {                               /* Grow in-place, check for enough space. */\n        if ( (new_apos > pool->end) ||\n             (new_apos < pool->pos) ) /* Value wrap */\n          return NULL;                /* No space */\n      }\n      /* Resized in-place */\n      pool->pos = new_apos;\n      _MHD_UNPOISON_MEMORY (old, new_size);\n      return old;\n    }\n    if (shrinking)\n      return old;   /* Resized in-place, freed part remains allocated */\n  }\n  /* Need to allocate new block */\n  asize = ROUND_TO_ALIGN_PLUS_RED_ZONE (new_size);\n  if ( ( (0 == asize) &&\n         (0 != new_size) ) || /* Value wrap, too large new_size. */\n       (asize > pool->end - pool->pos) ) /* Not enough space */\n    return NULL;\n\n  new_blc = pool->memory + pool->pos;\n  pool->pos += asize;\n\n  _MHD_UNPOISON_MEMORY (new_blc, new_size);\n  if (0 != old_size)\n  {\n    /* Move data to new block, old block remains allocated */\n    memcpy (new_blc, old, old_size);\n    /* Zero-out old block */\n    memset (old, 0, old_size);\n    _MHD_POISON_MEMORY (old, old_size);\n  }\n  return new_blc;\n}\n```\n</target_code>\nPlease find suspicious code fragments in the code and report them. Other agents can not investigate other fragments that you do not report, so it is very important to find all suspicious fragments without missing any. Report the suspicious fragments AS MUCH AS POSSIBLE.",
  "suspicious_frags": [
    "if (shrinking)\n      return old;   /* Resized in-place, freed part remains allocated */",
    "#if defined(MHD_ASAN_POISON_ACTIVE) && defined(HAVE___ASAN_REGION_IS_POISONED)\n  mhd_assert (NULL == __asan_region_is_poisoned (old, old_size));\n#endif /* MHD_ASAN_POISON_ACTIVE && HAVE___ASAN_REGION_IS_POISONED */",
    "if ( ( (0 == asize) &&\n         (0 != new_size) ) || /* Value wrap, too large new_size. */\n       (asize > pool->end - pool->pos) ) /* Not enough space */\n    return NULL;",
    "if (! shrinking)\n      {                               /* Grow in-place, check for enough space. */\n        if ( (new_apos > pool->end) ||\n             (new_apos < pool->pos) ) /* Value wrap */\n          return NULL;                /* No space */\n      }",
    "if (shrinking)\n    {     /* Shrinking in-place, zero-out freed part */\n      memset ((uint8_t *) old + new_size, 0, old_size - new_size);\n      _MHD_POISON_MEMORY ((uint8_t *) old + new_size, old_size - new_size);\n    }",
    "if (0 != old_size)\n  {\n    /* Move data to new block, old block remains allocated */\n    memcpy (new_blc, old, old_size);\n    /* Zero-out old block */\n    memset (old, 0, old_size);\n    _MHD_POISON_MEMORY (old, old_size);\n  }",
    "if (pool->pos ==\n        ROUND_TO_ALIGN_PLUS_RED_ZONE (old_offset + old_size))\n    {     /* \"old\" block is the last allocated block */\n      const size_t new_apos =\n        ROUND_TO_ALIGN_PLUS_RED_ZONE (old_offset + new_size);\n      if (! shrinking)\n      {                               /* Grow in-place, check for enough space. */\n        if ( (new_apos > pool->end) ||\n             (new_apos < pool->pos) ) /* Value wrap */\n          return NULL;                /* No space */\n      }\n      /* Resized in-place */\n      pool->pos = new_apos;\n      _MHD_UNPOISON_MEMORY (old, new_size);\n      return old;\n    }"
  ],
  "explanation": "I selected fragments that contain conditional returns, wrap-detection conditions, or conditional compilation and data-movement code that are likely to hide unreachable code or branches that are never taken under normal, non-wrapped arithmetic. These include: the whole branch that handles the case where the old block is the last allocated block (it contains nested tests and an unconditional return), the nested check for (new_apos < pool->pos) labelled \"Value wrap\" (this subcondition is suspicious because under normal non-wrapping growth it cannot be true), the early and late 'if (shrinking)' branches (one does clearing/poisoning, the other returns \u2014 their interaction can produce paths that may or may not be reachable), the asize wrap/overflow check that returns NULL, the conditional ASAN assert block (compiled in only under certain macros), and the final data-move/poison block guarded by if (0 != old_size).\n\nWhy other fragments need not be investigated here: most remaining lines are assertions (mhd_assert), simple local variable declarations and straightforward assignments (asize = ..., new_blc = ..., pool->pos += asize), unpoisoning calls that directly precede returns, and the top-level if (NULL != old) that directs control flow. Assertions do not by themselves create unreachable code in the compiled product when they are active; when they are compiled out they simply disappear rather than leaving dead code. The simple assignments and calls without conditional returns are standard reachable operations as part of normal control flow. The suspect fragments listed above are those that most likely hide unreachable branches (e.g. branches that only trigger on integer wrap, duplicated/conditional returns, or code present only under conditional compilation) and therefore warrant investigation for MISRA C Rule 2.1 compliance."
}