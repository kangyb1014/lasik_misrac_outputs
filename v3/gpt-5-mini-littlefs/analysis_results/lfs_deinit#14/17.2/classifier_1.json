{
  "user_message": "<misra_rule>\nMISRA C 2023 Rule 17.2 is: Functions shall not call themselves, either directly or indirectly.\n\n</misra_rule>\n<response format>\nProvide your answer with these fields.\n- is_rule_violated: whether the rule is violated or not (true/false),\n- scenario: a specific violation scenario.\n</response format>\n<target_code>\nHere is the code of lfs_deinit:\n```c\nstatic int lfs_deinit(lfs_t *lfs) {\n    // free allocated memory\n    if (!lfs->cfg->read_buffer) {\n        lfs_free(lfs->rcache.buffer);\n    }\n\n    if (!lfs->cfg->prog_buffer) {\n        lfs_free(lfs->pcache.buffer);\n    }\n\n    if (!lfs->cfg->lookahead_buffer) {\n        lfs_free(lfs->lookahead.buffer);\n    }\n\n    return 0;\n}\n```\n</target_code>\n<additional code>Here are the definitions of symbols that are close to the target function lfs_deinit:\nstatic int lfs_init(lfs_t *lfs, const struct lfs_config *cfg) {\n    lfs->cfg = cfg;\n    lfs->block_count = cfg->block_count;  // May be 0\n    int err = 0;\n\n#ifdef LFS_MULTIVERSION\n    // this driver only supports minor version < current minor version\n    LFS_ASSERT(!lfs->cfg->disk_version || (\n            (0xffff & (lfs->cfg->disk_version >> 16))\n                    == LFS_DISK_VERSION_MAJOR\n                && (0xffff & (lfs->cfg->disk_version >> 0))\n                    <= LFS_DISK_VERSION_MINOR));\n#endif\n\n    // check that bool is a truthy-preserving type\n    //\n    // note the most common reason for this failure is a before-c99 compiler,\n    // which littlefs currently does not support\n    LFS_ASSERT((bool)0x80000000);\n\n    // check that the required io functions are provided\n    LFS_ASSERT(lfs->cfg->read != NULL);\n#ifndef LFS_READONLY\n    LFS_ASSERT(lfs->cfg->prog != NULL);\n    LFS_ASSERT(lfs->cfg->erase != NULL);\n    LFS_ASSERT(lfs->cfg->sync != NULL);\n#endif\n\n    // validate that the lfs-cfg sizes were initiated properly before\n    // performing any arithmetic logics with them\n    LFS_ASSERT(lfs->cfg->read_size != 0);\n    LFS_ASSERT(lfs->cfg->prog_size != 0);\n    LFS_ASSERT(lfs->cfg->cache_size != 0);\n\n    // check that block size is a multiple of cache size is a multiple\n    // of prog and read sizes\n    LFS_ASSERT(lfs->cfg->cache_size % lfs->cfg->read_size == 0);\n    LFS_ASSERT(lfs->cfg->cache_size % lfs->cfg->prog_size == 0);\n    LFS_ASSERT(lfs->cfg->block_size % lfs->cfg->cache_size == 0);\n\n    // check that the block size is large enough to fit all ctz pointers\n    LFS_ASSERT(lfs->cfg->block_size >= 128);\n    // this is the exact calculation for all ctz pointers, if this fails\n    // and the simpler assert above does not, math must be broken\n    LFS_ASSERT(4*lfs_npw2(0xffffffff / (lfs->cfg->block_size-2*4))\n            <= lfs->cfg->block_size);\n\n    // block_cycles = 0 is no longer supported.\n    //\n    // block_cycles is the number of erase cycles before littlefs evicts\n    // metadata logs as a part of wear leveling. Suggested values are in the\n    // range of 100-1000, or set block_cycles to -1 to disable block-level\n    // wear-leveling.\n    LFS_ASSERT(lfs->cfg->block_cycles != 0);\n\n    // check that compact_thresh makes sense\n    //\n    // metadata can't be compacted below block_size/2, and metadata can't\n    // exceed a block_size\n    LFS_ASSERT(lfs->cfg->compact_thresh == 0\n            || lfs->cfg->compact_thresh >= lfs->cfg->block_size/2);\n    LFS_ASSERT(lfs->cfg->compact_thresh == (lfs_size_t)-1\n            || lfs->cfg->compact_thresh <= lfs->cfg->block_size);\n\n    // check that metadata_max is a multiple of read_size and prog_size,\n    // and a factor of the block_size\n    LFS_ASSERT(!lfs->cfg->metadata_max\n            || lfs->cfg->metadata_max % lfs->cfg->read_size == 0);\n    LFS_ASSERT(!lfs->cfg->metadata_max\n            || lfs->cfg->metadata_max % lfs->cfg->prog_size == 0);\n    LFS_ASSERT(!lfs->cfg->metadata_max\n            || lfs->cfg->block_size % lfs->cfg->metadata_max == 0);\n\n    // setup read cache\n    if (lfs->cfg->read_buffer) {\n        lfs->rcache.buffer = lfs->cfg->read_buffer;\n    } else {\n        lfs->rcache.buffer = lfs_malloc(lfs->cfg->cache_size);\n        if (!lfs->rcache.buffer) {\n            err = LFS_ERR_NOMEM;\n            goto cleanup;\n        }\n    }\n\n    // setup program cache\n    if (lfs->cfg->prog_buffer) {\n        lfs->pcache.buffer = lfs->cfg->prog_buffer;\n    } else {\n        lfs->pcache.buffer = lfs_malloc(lfs->cfg->cache_size);\n        if (!lfs->pcache.buffer) {\n            err = LFS_ERR_NOMEM;\n            goto cleanup;\n        }\n    }\n\n    // zero to avoid information leaks\n    lfs_cache_zero(lfs, &lfs->rcache);\n    lfs_cache_zero(lfs, &lfs->pcache);\n\n    // setup lookahead buffer, note mount finishes initializing this after\n    // we establish a decent pseudo-random seed\n    LFS_ASSERT(lfs->cfg->lookahead_size > 0);\n    if (lfs->cfg->lookahead_buffer) {\n        lfs->lookahead.buffer = lfs->cfg->lookahead_buffer;\n    } else {\n        lfs->lookahead.buffer = lfs_malloc(lfs->cfg->lookahead_size);\n        if (!lfs->lookahead.buffer) {\n            err = LFS_ERR_NOMEM;\n            goto cleanup;\n        }\n    }\n\n    // check that the size limits are sane\n    LFS_ASSERT(lfs->cfg->name_max <= LFS_NAME_MAX);\n    lfs->name_max = lfs->cfg->name_max;\n    if (!lfs->name_max) {\n        lfs->name_max = LFS_NAME_MAX;\n    }\n\n    LFS_ASSERT(lfs->cfg->file_max <= LFS_FILE_MAX);\n    lfs->file_max = lfs->cfg->file_max;\n    if (!lfs->file_max) {\n        lfs->file_max = LFS_FILE_MAX;\n    }\n\n    LFS_ASSERT(lfs->cfg->attr_max <= LFS_ATTR_MAX);\n    lfs->attr_max = lfs->cfg->attr_max;\n    if (!lfs->attr_max) {\n        lfs->attr_max = LFS_ATTR_MAX;\n    }\n\n    LFS_ASSERT(lfs->cfg->metadata_max <= lfs->cfg->block_size);\n\n    LFS_ASSERT(lfs->cfg->inline_max == (lfs_size_t)-1\n            || lfs->cfg->inline_max <= lfs->cfg->cache_size);\n    LFS_ASSERT(lfs->cfg->inline_max == (lfs_size_t)-1\n            || lfs->cfg->inline_max <= lfs->attr_max);\n    LFS_ASSERT(lfs->cfg->inline_max == (lfs_size_t)-1\n            || lfs->cfg->inline_max <= ((lfs->cfg->metadata_max)\n                ? lfs->cfg->metadata_max\n                : lfs->cfg->block_size)/8);\n    lfs->inline_max = lfs->cfg->inline_max;\n    if (lfs->inline_max == (lfs_size_t)-1) {\n        lfs->inline_max = 0;\n    } else if (lfs->inline_max == 0) {\n        lfs->inline_max = lfs_min(\n                lfs->cfg->cache_size,\n                lfs_min(\n                    lfs->attr_max,\n                    ((lfs->cfg->metadata_max)\n                        ? lfs->cfg->metadata_max\n                        : lfs->cfg->block_size)/8));\n    }\n\n    // setup default state\n    lfs->root[0] = LFS_BLOCK_NULL;\n    lfs->root[1] = LFS_BLOCK_NULL;\n    lfs->mlist = NULL;\n    lfs->seed = 0;\n    lfs->gdisk = (lfs_gstate_t){0};\n    lfs->gstate = (lfs_gstate_t){0};\n    lfs->gdelta = (lfs_gstate_t){0};\n#ifdef LFS_MIGRATE\n    lfs->lfs1 = NULL;\n#endif\n\n    return 0;\n\ncleanup:\n    lfs_deinit(lfs);\n    return err;\n}\n...\nstatic int lfs_format_(lfs_t *lfs, const struct lfs_config *cfg) {\n    int err = 0;\n    {\n        err = lfs_init(lfs, cfg);\n        if (err) {\n            return err;\n        }\n\n        LFS_ASSERT(cfg->block_count != 0);\n\n        // create free lookahead\n        memset(lfs->lookahead.buffer, 0, lfs->cfg->lookahead_size);\n        lfs->lookahead.start = 0;\n        lfs->lookahead.size = lfs_min(8*lfs->cfg->lookahead_size,\n                lfs->block_count);\n        lfs->lookahead.next = 0;\n        lfs_alloc_ckpoint(lfs);\n\n        // create root dir\n        lfs_mdir_t root;\n        err = lfs_dir_alloc(lfs, &root);\n        if (err) {\n            goto cleanup;\n        }\n\n        // write one superblock\n        lfs_superblock_t superblock = {\n            .version     = lfs_fs_disk_version(lfs),\n            .block_size  = lfs->cfg->block_size,\n            .block_count = lfs->block_count,\n            .name_max    = lfs->name_max,\n            .file_max    = lfs->file_max,\n            .attr_max    = lfs->attr_max,\n        };\n\n        lfs_superblock_tole32(&superblock);\n        err = lfs_dir_commit(lfs, &root, LFS_MKATTRS(\n                {LFS_MKTAG(LFS_TYPE_CREATE, 0, 0), NULL},\n                {LFS_MKTAG(LFS_TYPE_SUPERBLOCK, 0, 8), \"littlefs\"},\n                {LFS_MKTAG(LFS_TYPE_INLINESTRUCT, 0, sizeof(superblock)),\n                    &superblock}));\n        if (err) {\n            goto cleanup;\n        }\n\n        // force compaction to prevent accidentally mounting any\n        // older version of littlefs that may live on disk\n        root.erased = false;\n        err = lfs_dir_commit(lfs, &root, NULL, 0);\n        if (err) {\n            goto cleanup;\n        }\n\n        // sanity check that fetch works\n        err = lfs_dir_fetch(lfs, &root, (const lfs_block_t[2]){0, 1});\n        if (err) {\n            goto cleanup;\n        }\n    }\n\ncleanup:\n    lfs_deinit(lfs);\n    return err;\n\n}\n...\nstatic int lfs_unmount_(lfs_t *lfs) {\n    return lfs_deinit(lfs);\n}\n</additional code>\n<target_code>\nHere is the code fragment that you need to analyze:\n```c\ncleanup:\n    lfs_deinit(lfs);\n    return err;\n```\nFocus on the above code fragment and judge whether it violates the rule 17.2 or not.\n</target_code>\n",
  "is_rule_violated": false,
  "scenario": "In lfs_init (or other callers) the cleanup path calls lfs_deinit(lfs); lfs_deinit only frees buffers (calls lfs_free) and returns 0 and does not call lfs_init (nor any other function shown that would call back to lfs_init). Therefore there is no direct or indirect recursion in the provided code."
}