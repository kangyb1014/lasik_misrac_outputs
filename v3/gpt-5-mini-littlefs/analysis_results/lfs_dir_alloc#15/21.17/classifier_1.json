{
  "user_message": "<misra_rule>\nMISRA C 2023 Rule 21.17 is: Use of the string handling functions from <string.h> shall not result in accesses beyond the bounds of the objects referenced by their pointer parameters.\nThis rule strictly applies to the Standard Library functions in <string.h> such as memcpy, memmove, memset, memcmp, strcpy, strncpy, strcat, strncat, strlen, and strspn.\n</misra_rule>\n<response format>\nProvide your answer with these fields.\n- is_rule_violated: whether the rule is violated or not (true/false),\n- scenario: a specific violation scenario.\n</response format>\n<target_code>\nHere is the code of lfs_dir_alloc:\n```c\nstatic int lfs_dir_alloc(lfs_t *lfs, lfs_mdir_t *dir) {\n    // allocate pair of dir blocks (backwards, so we write block 1 first)\n    for (int i = 0; i < 2; i++) {\n        int err = lfs_alloc(lfs, &dir->pair[(i+1)%2]);\n        if (err) {\n            return err;\n        }\n    }\n\n    // zero for reproducibility in case initial block is unreadable\n    dir->rev = 0;\n\n    // rather than clobbering one of the blocks we just pretend\n    // the revision may be valid\n    int err = lfs_bd_read(lfs,\n            NULL, &lfs->rcache, sizeof(dir->rev),\n            dir->pair[0], 0, &dir->rev, sizeof(dir->rev));\n    dir->rev = lfs_fromle32(dir->rev);\n    if (err && err != LFS_ERR_CORRUPT) {\n        return err;\n    }\n\n    // to make sure we don't immediately evict, align the new revision count\n    // to our block_cycles modulus, see lfs_dir_compact for why our modulus\n    // is tweaked this way\n    if (lfs->cfg->block_cycles > 0) {\n        dir->rev = lfs_alignup(dir->rev, ((lfs->cfg->block_cycles+1)|1));\n    }\n\n    // set defaults\n    dir->off = sizeof(dir->rev);\n    dir->etag = 0xffffffff;\n    dir->count = 0;\n    dir->tail[0] = LFS_BLOCK_NULL;\n    dir->tail[1] = LFS_BLOCK_NULL;\n    dir->erased = false;\n    dir->split = false;\n\n    // don't write out yet, let caller take care of that\n    return 0;\n}\n```\n</target_code>\n<additional code>Here are the definitions of symbols that are close to the target function lfs_dir_alloc:\nstatic int lfs_alloc(lfs_t *lfs, lfs_block_t *block) {\n    while (true) {\n        // scan our lookahead buffer for free blocks\n        while (lfs->lookahead.next < lfs->lookahead.size) {\n            if (!(lfs->lookahead.buffer[lfs->lookahead.next / 8]\n                    & (1U << (lfs->lookahead.next % 8)))) {\n                // found a free block\n                *block = (lfs->lookahead.start + lfs->lookahead.next)\n                        % lfs->block_count;\n\n                // eagerly find next free block to maximize how many blocks\n                // lfs_alloc_ckpoint makes available for scanning\n                while (true) {\n                    lfs->lookahead.next += 1;\n                    lfs->lookahead.ckpoint -= 1;\n\n                    if (lfs->lookahead.next >= lfs->lookahead.size\n                            || !(lfs->lookahead.buffer[lfs->lookahead.next / 8]\n                                & (1U << (lfs->lookahead.next % 8)))) {\n                        return 0;\n                    }\n                }\n            }\n\n            lfs->lookahead.next += 1;\n            lfs->lookahead.ckpoint -= 1;\n        }\n\n        // In order to keep our block allocator from spinning forever when our\n        // filesystem is full, we mark points where there are no in-flight\n        // allocations with a checkpoint before starting a set of allocations.\n        //\n        // If we've looked at all blocks since the last checkpoint, we report\n        // the filesystem as out of storage.\n        //\n        if (lfs->lookahead.ckpoint <= 0) {\n            LFS_ERROR(\"No more free space 0x%\"PRIx32,\n                    (lfs->lookahead.start + lfs->lookahead.next)\n                        % lfs->block_count);\n            return LFS_ERR_NOSPC;\n        }\n\n        // No blocks in our lookahead buffer, we need to scan the filesystem for\n        // unused blocks in the next lookahead window.\n        int err = lfs_alloc_scan(lfs);\n        if(err) {\n            return err;\n        }\n    }\n}\n...\nstatic int lfs_alloc_scan(lfs_t *lfs) {\n    // move lookahead buffer to the first unused block\n    //\n    // note we limit the lookahead buffer to at most the amount of blocks\n    // checkpointed, this prevents the math in lfs_alloc from underflowing\n    lfs->lookahead.start = (lfs->lookahead.start + lfs->lookahead.next) \n            % lfs->block_count;\n    lfs->lookahead.next = 0;\n    lfs->lookahead.size = lfs_min(\n            8*lfs->cfg->lookahead_size,\n            lfs->lookahead.ckpoint);\n\n    // find mask of free blocks from tree\n    memset(lfs->lookahead.buffer, 0, lfs->cfg->lookahead_size);\n    int err = lfs_fs_traverse_(lfs, lfs_alloc_lookahead, lfs, true);\n    if (err) {\n        lfs_alloc_drop(lfs);\n        return err;\n    }\n\n    return 0;\n}\n...\nstatic int lfs_bd_read(lfs_t *lfs,\n        const lfs_cache_t *pcache, lfs_cache_t *rcache, lfs_size_t hint,\n        lfs_block_t block, lfs_off_t off,\n        void *buffer, lfs_size_t size) {\n    uint8_t *data = buffer;\n    if (off+size > lfs->cfg->block_size\n            || (lfs->block_count && block >= lfs->block_count)) {\n        return LFS_ERR_CORRUPT;\n    }\n\n    while (size > 0) {\n        lfs_size_t diff = size;\n\n        if (pcache && block == pcache->block &&\n                off < pcache->off + pcache->size) {\n            if (off >= pcache->off) {\n                // is already in pcache?\n                diff = lfs_min(diff, pcache->size - (off-pcache->off));\n                memcpy(data, &pcache->buffer[off-pcache->off], diff);\n\n                data += diff;\n                off += diff;\n                size -= diff;\n                continue;\n            }\n\n            // pcache takes priority\n            diff = lfs_min(diff, pcache->off-off);\n        }\n\n        if (block == rcache->block &&\n                off < rcache->off + rcache->size) {\n            if (off >= rcache->off) {\n                // is already in rcache?\n                diff = lfs_min(diff, rcache->size - (off-rcache->off));\n                memcpy(data, &rcache->buffer[off-rcache->off], diff);\n\n                data += diff;\n                off += diff;\n                size -= diff;\n                continue;\n            }\n\n            // rcache takes priority\n            diff = lfs_min(diff, rcache->off-off);\n        }\n\n        if (size >= hint && off % lfs->cfg->read_size == 0 &&\n                size >= lfs->cfg->read_size) {\n            // bypass cache?\n            diff = lfs_aligndown(diff, lfs->cfg->read_size);\n            int err = lfs->cfg->read(lfs->cfg, block, off, data, diff);\n            if (err) {\n                return err;\n            }\n\n            data += diff;\n            off += diff;\n            size -= diff;\n            continue;\n        }\n\n        // load to cache, first condition can no longer fail\n        LFS_ASSERT(!lfs->block_count || block < lfs->block_count);\n        rcache->block = block;\n        rcache->off = lfs_aligndown(off, lfs->cfg->read_size);\n        rcache->size = lfs_min(\n                lfs_min(\n                    lfs_alignup(off+hint, lfs->cfg->read_size),\n                    lfs->cfg->block_size)\n                - rcache->off,\n                lfs->cfg->cache_size);\n        int err = lfs->cfg->read(lfs->cfg, rcache->block,\n                rcache->off, rcache->buffer, rcache->size);\n        LFS_ASSERT(err <= 0);\n        if (err) {\n            return err;\n        }\n    }\n\n    return 0;\n}\n...\ntypedef struct lfs {\n    lfs_cache_t rcache;\n    lfs_cache_t pcache;\n\n    lfs_block_t root[2];\n    struct lfs_mlist {\n        struct lfs_mlist *next;\n        uint16_t id;\n        uint8_t type;\n        lfs_mdir_t m;\n    } *mlist;\n    uint32_t seed;\n\n    lfs_gstate_t gstate;\n    lfs_gstate_t gdisk;\n    lfs_gstate_t gdelta;\n\n    struct lfs_lookahead {\n        lfs_block_t start;\n        lfs_block_t size;\n        lfs_block_t next;\n        lfs_block_t ckpoint;\n        uint8_t *buffer;\n    } lookahead;\n\n    const struct lfs_config *cfg;\n    lfs_size_t block_count;\n    lfs_size_t name_max;\n    lfs_size_t file_max;\n    lfs_size_t attr_max;\n    lfs_size_t inline_max;\n\n#ifdef LFS_MIGRATE\n    struct lfs1 *lfs1;\n#endif\n} lfs_t\n...\ntypedef struct lfs_mdir {\n    lfs_block_t pair[2];\n    uint32_t rev;\n    lfs_off_t off;\n    uint32_t etag;\n    uint16_t count;\n    bool erased;\n    bool split;\n    lfs_block_t tail[2];\n} lfs_mdir_t\n...\n#define LFS_BLOCK_NULL ((lfs_block_t)-1)\n</additional code>\n<target_code>\nHere is the code fragment that you need to analyze:\n```c\nmemcpy(data, &pcache->buffer[off-pcache->off], diff);\n```\nFocus on the above code fragment and judge whether it violates the rule 21.17 or not.\n</target_code>\n",
  "is_rule_violated": false,
  "scenario": "Not violated. The memcpy is guarded: the if-condition requires off >= pcache->off and off < pcache->off + pcache->size, so index (off - pcache->off) is in [0, pcache->size). diff is then reduced with diff = lfs_min(diff, pcache->size - (off-pcache->off)), ensuring the copy length does not exceed the remaining bytes in pcache->buffer. The destination copy length is <= size, and earlier checks ensure off+size is within the block bounds. Therefore the memcpy call cannot access beyond the bounds of the source or destination buffers (unless other invariants about pcache->buffer allocation are broken elsewhere)."
}