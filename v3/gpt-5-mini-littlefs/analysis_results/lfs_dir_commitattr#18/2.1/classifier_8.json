{
  "user_message": "<misra_rule>\nMISRA C 2023 Rule 2.1 is: A project shall not contain unreachable code.\n\n</misra_rule>\n<response format>\nProvide your answer with these fields.\n- is_rule_violated: whether the rule is violated or not (true/false),\n- scenario: a specific violation scenario.\n</response format>\n<target_code>\nHere is the code of lfs_dir_commitattr:\n```c\nstatic int lfs_dir_commitattr(lfs_t *lfs, struct lfs_commit *commit,\n        lfs_tag_t tag, const void *buffer) {\n    // check if we fit\n    lfs_size_t dsize = lfs_tag_dsize(tag);\n    if (commit->off + dsize > commit->end) {\n        return LFS_ERR_NOSPC;\n    }\n\n    // write out tag\n    lfs_tag_t ntag = lfs_tobe32((tag & 0x7fffffff) ^ commit->ptag);\n    int err = lfs_dir_commitprog(lfs, commit, &ntag, sizeof(ntag));\n    if (err) {\n        return err;\n    }\n\n    if (!(tag & 0x80000000)) {\n        // from memory\n        err = lfs_dir_commitprog(lfs, commit, buffer, dsize-sizeof(tag));\n        if (err) {\n            return err;\n        }\n    } else {\n        // from disk\n        const struct lfs_diskoff *disk = buffer;\n        for (lfs_off_t i = 0; i < dsize-sizeof(tag); i++) {\n            // rely on caching to make this efficient\n            uint8_t dat;\n            err = lfs_bd_read(lfs,\n                    NULL, &lfs->rcache, dsize-sizeof(tag)-i,\n                    disk->block, disk->off+i, &dat, 1);\n            if (err) {\n                return err;\n            }\n\n            err = lfs_dir_commitprog(lfs, commit, &dat, 1);\n            if (err) {\n                return err;\n            }\n        }\n    }\n\n    commit->ptag = tag & 0x7fffffff;\n    return 0;\n}\n```\n</target_code>\n<additional code>Here are the definitions of symbols that are close to the target function lfs_dir_commitattr:\nstatic inline lfs_size_t lfs_tag_dsize(lfs_tag_t tag) {\n    return sizeof(tag) + lfs_tag_size(tag + lfs_tag_isdelete(tag));\n}\n...\nstatic inline lfs_size_t lfs_tag_size(lfs_tag_t tag) {\n    return tag & 0x000003ff;\n}\n...\nstatic inline bool lfs_tag_isdelete(lfs_tag_t tag) {\n    return ((int32_t)(tag << 22) >> 22) == -1;\n}\n...\nstatic int lfs_dir_commitprog(lfs_t *lfs, struct lfs_commit *commit,\n        const void *buffer, lfs_size_t size) {\n    int err = lfs_bd_prog(lfs,\n            &lfs->pcache, &lfs->rcache, false,\n            commit->block, commit->off ,\n            (const uint8_t*)buffer, size);\n    if (err) {\n        return err;\n    }\n\n    commit->crc = lfs_crc(commit->crc, buffer, size);\n    commit->off += size;\n    return 0;\n}\n...\nstatic int lfs_bd_read(lfs_t *lfs,\n        const lfs_cache_t *pcache, lfs_cache_t *rcache, lfs_size_t hint,\n        lfs_block_t block, lfs_off_t off,\n        void *buffer, lfs_size_t size) {\n    uint8_t *data = buffer;\n    if (off+size > lfs->cfg->block_size\n            || (lfs->block_count && block >= lfs->block_count)) {\n        return LFS_ERR_CORRUPT;\n    }\n\n    while (size > 0) {\n        lfs_size_t diff = size;\n\n        if (pcache && block == pcache->block &&\n                off < pcache->off + pcache->size) {\n            if (off >= pcache->off) {\n                // is already in pcache?\n                diff = lfs_min(diff, pcache->size - (off-pcache->off));\n                memcpy(data, &pcache->buffer[off-pcache->off], diff);\n\n                data += diff;\n                off += diff;\n                size -= diff;\n                continue;\n            }\n\n            // pcache takes priority\n            diff = lfs_min(diff, pcache->off-off);\n        }\n\n        if (block == rcache->block &&\n                off < rcache->off + rcache->size) {\n            if (off >= rcache->off) {\n                // is already in rcache?\n                diff = lfs_min(diff, rcache->size - (off-rcache->off));\n                memcpy(data, &rcache->buffer[off-rcache->off], diff);\n\n                data += diff;\n                off += diff;\n                size -= diff;\n                continue;\n            }\n\n            // rcache takes priority\n            diff = lfs_min(diff, rcache->off-off);\n        }\n\n        if (size >= hint && off % lfs->cfg->read_size == 0 &&\n                size >= lfs->cfg->read_size) {\n            // bypass cache?\n            diff = lfs_aligndown(diff, lfs->cfg->read_size);\n            int err = lfs->cfg->read(lfs->cfg, block, off, data, diff);\n            if (err) {\n                return err;\n            }\n\n            data += diff;\n            off += diff;\n            size -= diff;\n            continue;\n        }\n\n        // load to cache, first condition can no longer fail\n        LFS_ASSERT(!lfs->block_count || block < lfs->block_count);\n        rcache->block = block;\n        rcache->off = lfs_aligndown(off, lfs->cfg->read_size);\n        rcache->size = lfs_min(\n                lfs_min(\n                    lfs_alignup(off+hint, lfs->cfg->read_size),\n                    lfs->cfg->block_size)\n                - rcache->off,\n                lfs->cfg->cache_size);\n        int err = lfs->cfg->read(lfs->cfg, rcache->block,\n                rcache->off, rcache->buffer, rcache->size);\n        LFS_ASSERT(err <= 0);\n        if (err) {\n            return err;\n        }\n    }\n\n    return 0;\n}\n...\nstruct lfs_diskoff {\n    lfs_block_t block;\n    lfs_off_t off;\n}\n...\ntypedef uint32_t lfs_size_t\n...\ntypedef uint32_t lfs_off_t\n...\ntypedef struct lfs {\n    lfs_cache_t rcache;\n    lfs_cache_t pcache;\n\n    lfs_block_t root[2];\n    struct lfs_mlist {\n        struct lfs_mlist *next;\n        uint16_t id;\n        uint8_t type;\n        lfs_mdir_t m;\n    } *mlist;\n    uint32_t seed;\n\n    lfs_gstate_t gstate;\n    lfs_gstate_t gdisk;\n    lfs_gstate_t gdelta;\n\n    struct lfs_lookahead {\n        lfs_block_t start;\n        lfs_block_t size;\n        lfs_block_t next;\n        lfs_block_t ckpoint;\n        uint8_t *buffer;\n    } lookahead;\n\n    const struct lfs_config *cfg;\n    lfs_size_t block_count;\n    lfs_size_t name_max;\n    lfs_size_t file_max;\n    lfs_size_t attr_max;\n    lfs_size_t inline_max;\n\n#ifdef LFS_MIGRATE\n    struct lfs1 *lfs1;\n#endif\n} lfs_t\n</additional code>\n<target_code>\nHere is the code fragment that you need to analyze:\n```c\nif (size >= hint && off % lfs->cfg->read_size == 0 &&\n                size >= lfs->cfg->read_size) {\n            // bypass cache?\n            diff = lfs_aligndown(diff, lfs->cfg->read_size);\n            int err = lfs->cfg->read(lfs->cfg, block, off, data, diff);\n            if (err) {\n                return err;\n            }\n\n            data += diff;\n            off += diff;\n            size -= diff;\n            continue;\n        }\n```\nFocus on the above code fragment and judge whether it violates the rule 2.1 or not.\n</target_code>\n",
  "is_rule_violated": false,
  "scenario": "Not violated. The branch is reachable when lfs_bd_read is called with remaining size >= hint and >= cfg->read_size and an offset aligned to read_size. For example, with cfg->read_size = 64, hint = 128, off = 0, and size = 256, the condition (size >= hint && off % read_size == 0 && size >= read_size) is true and the bypass-cache path executes."
}