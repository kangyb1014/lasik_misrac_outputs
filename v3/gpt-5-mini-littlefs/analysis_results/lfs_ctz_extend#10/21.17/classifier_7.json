{
  "user_message": "<misra_rule>\nMISRA C 2023 Rule 21.17 is: Use of the string handling functions from <string.h> shall not result in accesses beyond the bounds of the objects referenced by their pointer parameters.\nThis rule strictly applies to the Standard Library functions in <string.h> such as memcpy, memmove, memset, memcmp, strcpy, strncpy, strcat, strncat, strlen, and strspn.\n</misra_rule>\n<response format>\nProvide your answer with these fields.\n- is_rule_violated: whether the rule is violated or not (true/false),\n- scenario: a specific violation scenario.\n</response format>\n<target_code>\nHere is the code of lfs_ctz_extend:\n```c\nstatic int lfs_ctz_extend(lfs_t *lfs,\n        lfs_cache_t *pcache, lfs_cache_t *rcache,\n        lfs_block_t head, lfs_size_t size,\n        lfs_block_t *block, lfs_off_t *off) {\n    while (true) {\n        // go ahead and grab a block\n        lfs_block_t nblock;\n        int err = lfs_alloc(lfs, &nblock);\n        if (err) {\n            return err;\n        }\n\n        {\n            err = lfs_bd_erase(lfs, nblock);\n            if (err) {\n                if (err == LFS_ERR_CORRUPT) {\n                    goto relocate;\n                }\n                return err;\n            }\n\n            if (size == 0) {\n                *block = nblock;\n                *off = 0;\n                return 0;\n            }\n\n            lfs_size_t noff = size - 1;\n            lfs_off_t index = lfs_ctz_index(lfs, &noff);\n            noff = noff + 1;\n\n            // just copy out the last block if it is incomplete\n            if (noff != lfs->cfg->block_size) {\n                for (lfs_off_t i = 0; i < noff; i++) {\n                    uint8_t data;\n                    err = lfs_bd_read(lfs,\n                            NULL, rcache, noff-i,\n                            head, i, &data, 1);\n                    if (err) {\n                        return err;\n                    }\n\n                    err = lfs_bd_prog(lfs,\n                            pcache, rcache, true,\n                            nblock, i, &data, 1);\n                    if (err) {\n                        if (err == LFS_ERR_CORRUPT) {\n                            goto relocate;\n                        }\n                        return err;\n                    }\n                }\n\n                *block = nblock;\n                *off = noff;\n                return 0;\n            }\n\n            // append block\n            index += 1;\n            lfs_size_t skips = lfs_ctz(index) + 1;\n            lfs_block_t nhead = head;\n            for (lfs_off_t i = 0; i < skips; i++) {\n                nhead = lfs_tole32(nhead);\n                err = lfs_bd_prog(lfs, pcache, rcache, true,\n                        nblock, 4*i, &nhead, 4);\n                nhead = lfs_fromle32(nhead);\n                if (err) {\n                    if (err == LFS_ERR_CORRUPT) {\n                        goto relocate;\n                    }\n                    return err;\n                }\n\n                if (i != skips-1) {\n                    err = lfs_bd_read(lfs,\n                            NULL, rcache, sizeof(nhead),\n                            nhead, 4*i, &nhead, sizeof(nhead));\n                    nhead = lfs_fromle32(nhead);\n                    if (err) {\n                        return err;\n                    }\n                }\n            }\n\n            *block = nblock;\n            *off = 4*skips;\n            return 0;\n        }\n\nrelocate:\n        LFS_DEBUG(\"Bad block at 0x%\"PRIx32, nblock);\n\n        // just clear cache and try a new block\n        lfs_cache_drop(lfs, pcache);\n    }\n}\n```\n</target_code>\n<additional code>Here are the definitions of symbols that are close to the target function lfs_ctz_extend:\nstatic int lfs_bd_read(lfs_t *lfs,\n        const lfs_cache_t *pcache, lfs_cache_t *rcache, lfs_size_t hint,\n        lfs_block_t block, lfs_off_t off,\n        void *buffer, lfs_size_t size) {\n    uint8_t *data = buffer;\n    if (off+size > lfs->cfg->block_size\n            || (lfs->block_count && block >= lfs->block_count)) {\n        return LFS_ERR_CORRUPT;\n    }\n\n    while (size > 0) {\n        lfs_size_t diff = size;\n\n        if (pcache && block == pcache->block &&\n                off < pcache->off + pcache->size) {\n            if (off >= pcache->off) {\n                // is already in pcache?\n                diff = lfs_min(diff, pcache->size - (off-pcache->off));\n                memcpy(data, &pcache->buffer[off-pcache->off], diff);\n\n                data += diff;\n                off += diff;\n                size -= diff;\n                continue;\n            }\n\n            // pcache takes priority\n            diff = lfs_min(diff, pcache->off-off);\n        }\n\n        if (block == rcache->block &&\n                off < rcache->off + rcache->size) {\n            if (off >= rcache->off) {\n                // is already in rcache?\n                diff = lfs_min(diff, rcache->size - (off-rcache->off));\n                memcpy(data, &rcache->buffer[off-rcache->off], diff);\n\n                data += diff;\n                off += diff;\n                size -= diff;\n                continue;\n            }\n\n            // rcache takes priority\n            diff = lfs_min(diff, rcache->off-off);\n        }\n\n        if (size >= hint && off % lfs->cfg->read_size == 0 &&\n                size >= lfs->cfg->read_size) {\n            // bypass cache?\n            diff = lfs_aligndown(diff, lfs->cfg->read_size);\n            int err = lfs->cfg->read(lfs->cfg, block, off, data, diff);\n            if (err) {\n                return err;\n            }\n\n            data += diff;\n            off += diff;\n            size -= diff;\n            continue;\n        }\n\n        // load to cache, first condition can no longer fail\n        LFS_ASSERT(!lfs->block_count || block < lfs->block_count);\n        rcache->block = block;\n        rcache->off = lfs_aligndown(off, lfs->cfg->read_size);\n        rcache->size = lfs_min(\n                lfs_min(\n                    lfs_alignup(off+hint, lfs->cfg->read_size),\n                    lfs->cfg->block_size)\n                - rcache->off,\n                lfs->cfg->cache_size);\n        int err = lfs->cfg->read(lfs->cfg, rcache->block,\n                rcache->off, rcache->buffer, rcache->size);\n        LFS_ASSERT(err <= 0);\n        if (err) {\n            return err;\n        }\n    }\n\n    return 0;\n}\n...\nstatic int lfs_bd_prog(lfs_t *lfs,\n        lfs_cache_t *pcache, lfs_cache_t *rcache, bool validate,\n        lfs_block_t block, lfs_off_t off,\n        const void *buffer, lfs_size_t size) {\n    const uint8_t *data = buffer;\n    LFS_ASSERT(block == LFS_BLOCK_INLINE || block < lfs->block_count);\n    LFS_ASSERT(off + size <= lfs->cfg->block_size);\n\n    while (size > 0) {\n        if (block == pcache->block &&\n                off >= pcache->off &&\n                off < pcache->off + lfs->cfg->cache_size) {\n            // already fits in pcache?\n            lfs_size_t diff = lfs_min(size,\n                    lfs->cfg->cache_size - (off-pcache->off));\n            memcpy(&pcache->buffer[off-pcache->off], data, diff);\n\n            data += diff;\n            off += diff;\n            size -= diff;\n\n            pcache->size = lfs_max(pcache->size, off - pcache->off);\n            if (pcache->size == lfs->cfg->cache_size) {\n                // eagerly flush out pcache if we fill up\n                int err = lfs_bd_flush(lfs, pcache, rcache, validate);\n                if (err) {\n                    return err;\n                }\n            }\n\n            continue;\n        }\n\n        // pcache must have been flushed, either by programming and\n        // entire block or manually flushing the pcache\n        LFS_ASSERT(pcache->block == LFS_BLOCK_NULL);\n\n        // prepare pcache, first condition can no longer fail\n        pcache->block = block;\n        pcache->off = lfs_aligndown(off, lfs->cfg->prog_size);\n        pcache->size = 0;\n    }\n\n    return 0;\n}\n...\nstatic int lfs_bd_erase(lfs_t *lfs, lfs_block_t block) {\n    LFS_ASSERT(block < lfs->block_count);\n    int err = lfs->cfg->erase(lfs->cfg, block);\n    LFS_ASSERT(err <= 0);\n    return err;\n}\n...\nstatic int lfs_bd_flush(lfs_t *lfs,\n        lfs_cache_t *pcache, lfs_cache_t *rcache, bool validate) {\n    if (pcache->block != LFS_BLOCK_NULL && pcache->block != LFS_BLOCK_INLINE) {\n        LFS_ASSERT(pcache->block < lfs->block_count);\n        lfs_size_t diff = lfs_alignup(pcache->size, lfs->cfg->prog_size);\n        int err = lfs->cfg->prog(lfs->cfg, pcache->block,\n                pcache->off, pcache->buffer, diff);\n        LFS_ASSERT(err <= 0);\n        if (err) {\n            return err;\n        }\n\n        if (validate) {\n            // check data on disk\n            lfs_cache_drop(lfs, rcache);\n            int res = lfs_bd_cmp(lfs,\n                    NULL, rcache, diff,\n                    pcache->block, pcache->off, pcache->buffer, diff);\n            if (res < 0) {\n                return res;\n            }\n\n            if (res != LFS_CMP_EQ) {\n                return LFS_ERR_CORRUPT;\n            }\n        }\n\n        lfs_cache_zero(lfs, pcache);\n    }\n\n    return 0;\n}\n...\nstatic int lfs_ctz_index(lfs_t *lfs, lfs_off_t *off) {\n    lfs_off_t size = *off;\n    lfs_off_t b = lfs->cfg->block_size - 2*4;\n    lfs_off_t i = size / b;\n    if (i == 0) {\n        return 0;\n    }\n\n    i = (size - 4*(lfs_popc(i-1)+2)) / b;\n    *off = size - b*i - 4*lfs_popc(i);\n    return i;\n}\n...\nstruct lfs_ctz {\n        lfs_block_t head;\n        lfs_size_t size;\n    }\n...\nstatic int lfs_alloc(lfs_t *lfs, lfs_block_t *block) {\n    while (true) {\n        // scan our lookahead buffer for free blocks\n        while (lfs->lookahead.next < lfs->lookahead.size) {\n            if (!(lfs->lookahead.buffer[lfs->lookahead.next / 8]\n                    & (1U << (lfs->lookahead.next % 8)))) {\n                // found a free block\n                *block = (lfs->lookahead.start + lfs->lookahead.next)\n                        % lfs->block_count;\n\n                // eagerly find next free block to maximize how many blocks\n                // lfs_alloc_ckpoint makes available for scanning\n                while (true) {\n                    lfs->lookahead.next += 1;\n                    lfs->lookahead.ckpoint -= 1;\n\n                    if (lfs->lookahead.next >= lfs->lookahead.size\n                            || !(lfs->lookahead.buffer[lfs->lookahead.next / 8]\n                                & (1U << (lfs->lookahead.next % 8)))) {\n                        return 0;\n                    }\n                }\n            }\n\n            lfs->lookahead.next += 1;\n            lfs->lookahead.ckpoint -= 1;\n        }\n\n        // In order to keep our block allocator from spinning forever when our\n        // filesystem is full, we mark points where there are no in-flight\n        // allocations with a checkpoint before starting a set of allocations.\n        //\n        // If we've looked at all blocks since the last checkpoint, we report\n        // the filesystem as out of storage.\n        //\n        if (lfs->lookahead.ckpoint <= 0) {\n            LFS_ERROR(\"No more free space 0x%\"PRIx32,\n                    (lfs->lookahead.start + lfs->lookahead.next)\n                        % lfs->block_count);\n            return LFS_ERR_NOSPC;\n        }\n\n        // No blocks in our lookahead buffer, we need to scan the filesystem for\n        // unused blocks in the next lookahead window.\n        int err = lfs_alloc_scan(lfs);\n        if(err) {\n            return err;\n        }\n    }\n}\n...\nstatic inline void lfs_cache_drop(lfs_t *lfs, lfs_cache_t *rcache) {\n    // do not zero, cheaper if cache is readonly or only going to be\n    // written with identical data (during relocates)\n    (void)lfs;\n    rcache->block = LFS_BLOCK_NULL;\n}\n...\ntypedef uint32_t lfs_off_t\n</additional code>\n<target_code>\nHere is the code fragment that you need to analyze:\n```c\nmemcpy(&pcache->buffer[off-pcache->off], data, diff);\n```\nFocus on the above code fragment and judge whether it violates the rule 21.17 or not.\n</target_code>\n",
  "is_rule_violated": false,
  "scenario": "No violation: before the memcpy the code checks that block == pcache->block and off is in [pcache->off, pcache->off + cfg->cache_size). diff is computed as lfs_min(size, cfg->cache_size - (off-pcache->off)), guaranteeing (off-pcache->off) + diff <= cfg->cache_size, so the destination &pcache->buffer[off-pcache->off]..+diff stays within pcache->buffer. The source pointer 'data' has at least 'size' bytes remaining and diff <= size, so the source is also large enough. (A violation could only occur if external invariants are broken, e.g. pcache->buffer is smaller than cfg->cache_size or integer overflow.)"
}