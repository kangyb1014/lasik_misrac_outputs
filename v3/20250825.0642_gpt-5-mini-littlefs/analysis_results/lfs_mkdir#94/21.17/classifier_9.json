{
  "user_message": "<misra_rule>\nMISRA C 2023 Rule 21.17 is: Use of the string handling functions from <string.h> shall not result in accesses beyond the bounds of the objects referenced by their pointer parameters.\nThis rule strictly applies to the Standard Library functions in <string.h> such as memcpy, memmove, memset, memcmp, strcpy, strncpy, strcat, strncat, strlen, and strspn.\n</misra_rule>\n<response format>\nProvide your answer with these fields.\n- is_rule_violated: whether the rule is violated or not (true/false),\n- scenario: a specific violation scenario.\n</response format>\n<target_code>\nHere is the code of lfs_mkdir:\n```c\nint lfs_mkdir(lfs_t *lfs, const char *path) {\n    int err = LFS_LOCK(lfs->cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_mkdir(%p, \\\"%s\\\")\", (void*)lfs, path);\n\n    err = lfs_mkdir_(lfs, path);\n\n    LFS_TRACE(\"lfs_mkdir -> %d\", err);\n    LFS_UNLOCK(lfs->cfg);\n    return err;\n}\n```\n</target_code>\n<additional code>Here are the definitions of symbols that are close to the target function lfs_mkdir:\nstatic int lfs_mkdir_(lfs_t *lfs, const char *path) {\n    // deorphan if we haven't yet, needed at most once after poweron\n    int err = lfs_fs_forceconsistency(lfs);\n    if (err) {\n        return err;\n    }\n\n    struct lfs_mlist cwd;\n    cwd.next = lfs->mlist;\n    uint16_t id;\n    err = lfs_dir_find(lfs, &cwd.m, &path, &id);\n    if (!(err == LFS_ERR_NOENT && lfs_path_islast(path))) {\n        return (err < 0) ? err : LFS_ERR_EXIST;\n    }\n\n    // check that name fits\n    lfs_size_t nlen = lfs_path_namelen(path);\n    if (nlen > lfs->name_max) {\n        return LFS_ERR_NAMETOOLONG;\n    }\n\n    // build up new directory\n    lfs_alloc_ckpoint(lfs);\n    lfs_mdir_t dir;\n    err = lfs_dir_alloc(lfs, &dir);\n    if (err) {\n        return err;\n    }\n\n    // find end of list\n    lfs_mdir_t pred = cwd.m;\n    while (pred.split) {\n        err = lfs_dir_fetch(lfs, &pred, pred.tail);\n        if (err) {\n            return err;\n        }\n    }\n\n    // setup dir\n    lfs_pair_tole32(pred.tail);\n    err = lfs_dir_commit(lfs, &dir, LFS_MKATTRS(\n            {LFS_MKTAG(LFS_TYPE_SOFTTAIL, 0x3ff, 8), pred.tail}));\n    lfs_pair_fromle32(pred.tail);\n    if (err) {\n        return err;\n    }\n\n    // current block not end of list?\n    if (cwd.m.split) {\n        // update tails, this creates a desync\n        err = lfs_fs_preporphans(lfs, +1);\n        if (err) {\n            return err;\n        }\n\n        // it's possible our predecessor has to be relocated, and if\n        // our parent is our predecessor's predecessor, this could have\n        // caused our parent to go out of date, fortunately we can hook\n        // ourselves into littlefs to catch this\n        cwd.type = 0;\n        cwd.id = 0;\n        lfs->mlist = &cwd;\n\n        lfs_pair_tole32(dir.pair);\n        err = lfs_dir_commit(lfs, &pred, LFS_MKATTRS(\n                {LFS_MKTAG(LFS_TYPE_SOFTTAIL, 0x3ff, 8), dir.pair}));\n        lfs_pair_fromle32(dir.pair);\n        if (err) {\n            lfs->mlist = cwd.next;\n            return err;\n        }\n\n        lfs->mlist = cwd.next;\n        err = lfs_fs_preporphans(lfs, -1);\n        if (err) {\n            return err;\n        }\n    }\n\n    // now insert into our parent block\n    lfs_pair_tole32(dir.pair);\n    err = lfs_dir_commit(lfs, &cwd.m, LFS_MKATTRS(\n            {LFS_MKTAG(LFS_TYPE_CREATE, id, 0), NULL},\n            {LFS_MKTAG(LFS_TYPE_DIR, id, nlen), path},\n            {LFS_MKTAG(LFS_TYPE_DIRSTRUCT, id, 8), dir.pair},\n            {LFS_MKTAG_IF(!cwd.m.split,\n                LFS_TYPE_SOFTTAIL, 0x3ff, 8), dir.pair}));\n    lfs_pair_fromle32(dir.pair);\n    if (err) {\n        return err;\n    }\n\n    return 0;\n}\n...\nstatic lfs_stag_t lfs_dir_find(lfs_t *lfs, lfs_mdir_t *dir,\n        const char **path, uint16_t *id) {\n    // we reduce path to a single name if we can find it\n    const char *name = *path;\n\n    // default to root dir\n    lfs_stag_t tag = LFS_MKTAG(LFS_TYPE_DIR, 0x3ff, 0);\n    dir->tail[0] = lfs->root[0];\n    dir->tail[1] = lfs->root[1];\n\n    // empty paths are not allowed\n    if (*name == '\\0') {\n        return LFS_ERR_INVAL;\n    }\n\n    while (true) {\nnextname:\n        // skip slashes if we're a directory\n        if (lfs_tag_type3(tag) == LFS_TYPE_DIR) {\n            name += strspn(name, \"/\");\n        }\n        lfs_size_t namelen = strcspn(name, \"/\");\n\n        // skip '.'\n        if (namelen == 1 && memcmp(name, \".\", 1) == 0) {\n            name += namelen;\n            goto nextname;\n        }\n\n        // error on unmatched '..', trying to go above root?\n        if (namelen == 2 && memcmp(name, \"..\", 2) == 0) {\n            return LFS_ERR_INVAL;\n        }\n\n        // skip if matched by '..' in name\n        const char *suffix = name + namelen;\n        lfs_size_t sufflen;\n        int depth = 1;\n        while (true) {\n            suffix += strspn(suffix, \"/\");\n            sufflen = strcspn(suffix, \"/\");\n            if (sufflen == 0) {\n                break;\n            }\n\n            if (sufflen == 1 && memcmp(suffix, \".\", 1) == 0) {\n                // noop\n            } else if (sufflen == 2 && memcmp(suffix, \"..\", 2) == 0) {\n                depth -= 1;\n                if (depth == 0) {\n                    name = suffix + sufflen;\n                    goto nextname;\n                }\n            } else {\n                depth += 1;\n            }\n\n            suffix += sufflen;\n        }\n\n        // found path\n        if (*name == '\\0') {\n            return tag;\n        }\n\n        // update what we've found so far\n        *path = name;\n\n        // only continue if we're a directory\n        if (lfs_tag_type3(tag) != LFS_TYPE_DIR) {\n            return LFS_ERR_NOTDIR;\n        }\n\n        // grab the entry data\n        if (lfs_tag_id(tag) != 0x3ff) {\n            lfs_stag_t res = lfs_dir_get(lfs, dir, LFS_MKTAG(0x700, 0x3ff, 0),\n                    LFS_MKTAG(LFS_TYPE_STRUCT, lfs_tag_id(tag), 8), dir->tail);\n            if (res < 0) {\n                return res;\n            }\n            lfs_pair_fromle32(dir->tail);\n        }\n\n        // find entry matching name\n        while (true) {\n            tag = lfs_dir_fetchmatch(lfs, dir, dir->tail,\n                    LFS_MKTAG(0x780, 0, 0),\n                    LFS_MKTAG(LFS_TYPE_NAME, 0, namelen),\n                    id,\n                    lfs_dir_find_match, &(struct lfs_dir_find_match){\n                        lfs, name, namelen});\n            if (tag < 0) {\n                return tag;\n            }\n\n            if (tag) {\n                break;\n            }\n\n            if (!dir->split) {\n                return LFS_ERR_NOENT;\n            }\n        }\n\n        // to next name\n        name += namelen;\n    }\n}\n...\nstatic inline bool lfs_path_islast(const char *path) {\n    lfs_size_t namelen = lfs_path_namelen(path);\n    return path[namelen + strspn(path + namelen, \"/\")] == '\\0';\n}\n...\nstatic inline lfs_size_t lfs_path_namelen(const char *path) {\n    return strcspn(path, \"/\");\n}\n...\nstatic void lfs_alloc_ckpoint(lfs_t *lfs) {\n    lfs->lookahead.ckpoint = lfs->block_count;\n}\n...\nstatic int lfs_dir_alloc(lfs_t *lfs, lfs_mdir_t *dir) {\n    // allocate pair of dir blocks (backwards, so we write block 1 first)\n    for (int i = 0; i < 2; i++) {\n        int err = lfs_alloc(lfs, &dir->pair[(i+1)%2]);\n        if (err) {\n            return err;\n        }\n    }\n\n    // zero for reproducibility in case initial block is unreadable\n    dir->rev = 0;\n\n    // rather than clobbering one of the blocks we just pretend\n    // the revision may be valid\n    int err = lfs_bd_read(lfs,\n            NULL, &lfs->rcache, sizeof(dir->rev),\n            dir->pair[0], 0, &dir->rev, sizeof(dir->rev));\n    dir->rev = lfs_fromle32(dir->rev);\n    if (err && err != LFS_ERR_CORRUPT) {\n        return err;\n    }\n\n    // to make sure we don't immediately evict, align the new revision count\n    // to our block_cycles modulus, see lfs_dir_compact for why our modulus\n    // is tweaked this way\n    if (lfs->cfg->block_cycles > 0) {\n        dir->rev = lfs_alignup(dir->rev, ((lfs->cfg->block_cycles+1)|1));\n    }\n\n    // set defaults\n    dir->off = sizeof(dir->rev);\n    dir->etag = 0xffffffff;\n    dir->count = 0;\n    dir->tail[0] = LFS_BLOCK_NULL;\n    dir->tail[1] = LFS_BLOCK_NULL;\n    dir->erased = false;\n    dir->split = false;\n\n    // don't write out yet, let caller take care of that\n    return 0;\n}\n...\nstatic int lfs_dir_fetch(lfs_t *lfs,\n        lfs_mdir_t *dir, const lfs_block_t pair[2]) {\n    // note, mask=-1, tag=-1 can never match a tag since this\n    // pattern has the invalid bit set\n    return (int)lfs_dir_fetchmatch(lfs, dir, pair,\n            (lfs_tag_t)-1, (lfs_tag_t)-1, NULL, NULL, NULL);\n}\n...\nstatic int lfs_dir_commit(lfs_t *lfs, lfs_mdir_t *dir,\n        const struct lfs_mattr *attrs, int attrcount) {\n    int orphans = lfs_dir_orphaningcommit(lfs, dir, attrs, attrcount);\n    if (orphans < 0) {\n        return orphans;\n    }\n\n    if (orphans) {\n        // make sure we've removed all orphans, this is a noop if there\n        // are none, but if we had nested blocks failures we may have\n        // created some\n        int err = lfs_fs_deorphan(lfs, false);\n        if (err) {\n            return err;\n        }\n    }\n\n    return 0;\n}\n...\nstatic inline void lfs_pair_tole32(lfs_block_t pair[2]) {\n    pair[0] = lfs_tole32(pair[0]);\n    pair[1] = lfs_tole32(pair[1]);\n}\n...\nstatic inline void lfs_pair_fromle32(lfs_block_t pair[2]) {\n    pair[0] = lfs_fromle32(pair[0]);\n    pair[1] = lfs_fromle32(pair[1]);\n}\n...\nstatic int lfs_fs_forceconsistency(lfs_t *lfs) {\n    int err = lfs_fs_desuperblock(lfs);\n    if (err) {\n        return err;\n    }\n\n    err = lfs_fs_demove(lfs);\n    if (err) {\n        return err;\n    }\n\n    err = lfs_fs_deorphan(lfs, true);\n    if (err) {\n        return err;\n    }\n\n    return 0;\n}\n...\nstatic int lfs_fs_preporphans(lfs_t *lfs, int8_t orphans) {\n    LFS_ASSERT(lfs_tag_size(lfs->gstate.tag) > 0x000 || orphans >= 0);\n    LFS_ASSERT(lfs_tag_size(lfs->gstate.tag) < 0x1ff || orphans <= 0);\n    lfs->gstate.tag += orphans;\n    lfs->gstate.tag = ((lfs->gstate.tag & ~LFS_MKTAG(0x800, 0, 0)) |\n            ((uint32_t)lfs_gstate_hasorphans(&lfs->gstate) << 31));\n\n    return 0;\n}\n...\ntypedef struct lfs {\n    lfs_cache_t rcache;\n    lfs_cache_t pcache;\n\n    lfs_block_t root[2];\n    struct lfs_mlist {\n        struct lfs_mlist *next;\n        uint16_t id;\n        uint8_t type;\n        lfs_mdir_t m;\n    } *mlist;\n    uint32_t seed;\n\n    lfs_gstate_t gstate;\n    lfs_gstate_t gdisk;\n    lfs_gstate_t gdelta;\n\n    struct lfs_lookahead {\n        lfs_block_t start;\n        lfs_block_t size;\n        lfs_block_t next;\n        lfs_block_t ckpoint;\n        uint8_t *buffer;\n    } lookahead;\n\n    const struct lfs_config *cfg;\n    lfs_size_t block_count;\n    lfs_size_t name_max;\n    lfs_size_t file_max;\n    lfs_size_t attr_max;\n    lfs_size_t inline_max;\n\n#ifdef LFS_MIGRATE\n    struct lfs1 *lfs1;\n#endif\n} lfs_t\n...\nstruct lfs_config {\n    // Opaque user provided context that can be used to pass\n    // information to the block device operations\n    void *context;\n\n    // Read a region in a block. Negative error codes are propagated\n    // to the user.\n    int (*read)(const struct lfs_config *c, lfs_block_t block,\n            lfs_off_t off, void *buffer, lfs_size_t size);\n\n    // Program a region in a block. The block must have previously\n    // been erased. Negative error codes are propagated to the user.\n    // May return LFS_ERR_CORRUPT if the block should be considered bad.\n    int (*prog)(const struct lfs_config *c, lfs_block_t block,\n            lfs_off_t off, const void *buffer, lfs_size_t size);\n\n    // Erase a block. A block must be erased before being programmed.\n    // The state of an erased block is undefined. Negative error codes\n    // are propagated to the user.\n    // May return LFS_ERR_CORRUPT if the block should be considered bad.\n    int (*erase)(const struct lfs_config *c, lfs_block_t block);\n\n    // Sync the state of the underlying block device. Negative error codes\n    // are propagated to the user.\n    int (*sync)(const struct lfs_config *c);\n\n#ifdef LFS_THREADSAFE\n    // Lock the underlying block device. Negative error codes\n    // are propagated to the user.\n    int (*lock)(const struct lfs_config *c);\n\n    // Unlock the underlying block device. Negative error codes\n    // are propagated to the user.\n    int (*unlock)(const struct lfs_config *c);\n#endif\n\n    // Minimum size of a block read in bytes. All read operations will be a\n    // multiple of this value.\n    lfs_size_t read_size;\n\n    // Minimum size of a block program in bytes. All program operations will be\n    // a multiple of this value.\n    lfs_size_t prog_size;\n\n    // Size of an erasable block in bytes. This does not impact ram consumption\n    // and may be larger than the physical erase size. However, non-inlined\n    // files take up at minimum one block. Must be a multiple of the read and\n    // program sizes.\n    lfs_size_t block_size;\n\n    // Number of erasable blocks on the device. Defaults to block_count stored\n    // on disk when zero.\n    lfs_size_t block_count;\n\n    // Number of erase cycles before littlefs evicts metadata logs and moves\n    // the metadata to another block. Suggested values are in the\n    // range 100-1000, with large values having better performance at the cost\n    // of less consistent wear distribution.\n    //\n    // Set to -1 to disable block-level wear-leveling.\n    int32_t block_cycles;\n\n    // Size of block caches in bytes. Each cache buffers a portion of a block in\n    // RAM. The littlefs needs a read cache, a program cache, and one additional\n    // cache per file. Larger caches can improve performance by storing more\n    // data and reducing the number of disk accesses. Must be a multiple of the\n    // read and program sizes, and a factor of the block size.\n    lfs_size_t cache_size;\n\n    // Size of the lookahead buffer in bytes. A larger lookahead buffer\n    // increases the number of blocks found during an allocation pass. The\n    // lookahead buffer is stored as a compact bitmap, so each byte of RAM\n    // can track 8 blocks.\n    lfs_size_t lookahead_size;\n\n    // Threshold for metadata compaction during lfs_fs_gc in bytes. Metadata\n    // pairs that exceed this threshold will be compacted during lfs_fs_gc.\n    // Defaults to ~88% block_size when zero, though the default may change\n    // in the future.\n    //\n    // Note this only affects lfs_fs_gc. Normal compactions still only occur\n    // when full.\n    //\n    // Set to -1 to disable metadata compaction during lfs_fs_gc.\n    lfs_size_t compact_thresh;\n\n    // Optional statically allocated read buffer. Must be cache_size.\n    // By default lfs_malloc is used to allocate this buffer.\n    void *read_buffer;\n\n    // Optional statically allocated program buffer. Must be cache_size.\n    // By default lfs_malloc is used to allocate this buffer.\n    void *prog_buffer;\n\n    // Optional statically allocated lookahead buffer. Must be lookahead_size.\n    // By default lfs_malloc is used to allocate this buffer.\n    void *lookahead_buffer;\n\n    // Optional upper limit on length of file names in bytes. No downside for\n    // larger names except the size of the info struct which is controlled by\n    // the LFS_NAME_MAX define. Defaults to LFS_NAME_MAX or name_max stored on\n    // disk when zero.\n    lfs_size_t name_max;\n\n    // Optional upper limit on files in bytes. No downside for larger files\n    // but must be <= LFS_FILE_MAX. Defaults to LFS_FILE_MAX or file_max stored\n    // on disk when zero.\n    lfs_size_t file_max;\n\n    // Optional upper limit on custom attributes in bytes. No downside for\n    // larger attributes size but must be <= LFS_ATTR_MAX. Defaults to\n    // LFS_ATTR_MAX or attr_max stored on disk when zero.\n    lfs_size_t attr_max;\n\n    // Optional upper limit on total space given to metadata pairs in bytes. On\n    // devices with large blocks (e.g. 128kB) setting this to a low size (2-8kB)\n    // can help bound the metadata compaction time. Must be <= block_size.\n    // Defaults to block_size when zero.\n    lfs_size_t metadata_max;\n\n    // Optional upper limit on inlined files in bytes. Inlined files live in\n    // metadata and decrease storage requirements, but may be limited to\n    // improve metadata-related performance. Must be <= cache_size, <=\n    // attr_max, and <= block_size/8. Defaults to the largest possible\n    // inline_max when zero.\n    //\n    // Set to -1 to disable inlined files.\n    lfs_size_t inline_max;\n\n#ifdef LFS_MULTIVERSION\n    // On-disk version to use when writing in the form of 16-bit major version\n    // + 16-bit minor version. This limiting metadata to what is supported by\n    // older minor versions. Note that some features will be lost. Defaults to \n    // to the most recent minor version when zero.\n    uint32_t disk_version;\n#endif\n}\n...\ntypedef struct lfs_dir {\n    struct lfs_dir *next;\n    uint16_t id;\n    uint8_t type;\n    lfs_mdir_t m;\n\n    lfs_off_t pos;\n    lfs_block_t head[2];\n} lfs_dir_t\n...\n#define LFS_NAME_MAX 255\n</additional code>\n<target_code>\nHere is the code fragment that you need to analyze:\n```c\nsufflen = strcspn(suffix, \"/\");\n```\nFocus on the above code fragment and judge whether it violates the rule 21.17 or not.\n</target_code>\n",
  "is_rule_violated": false,
  "scenario": "Not violated in this code path. 'suffix' is derived from 'name' (which is '*path') and namelen = strcspn(name, \"/\") so suffix = name + namelen points at either a '/' or the terminating '\\0'. The code then advances suffix by strspn(suffix, \"/\") which still leaves suffix pointing within the original null-terminated path buffer (either at a non-slash character or at '\\0'). Therefore sufflen = strcspn(suffix, \"/\") only scans the remaining, null-terminated portion of the original string and cannot read beyond the object bounds. (Note: if the caller provided a non-null-terminated 'path', any usage of <string.h> would be unsafe, but that is a precondition of the API, not a defect in this fragment.)"
}