{
  "user_message": "<misra_rule>\nMISRA C 2023 Rule 21.17 is: Use of the string handling functions from <string.h> shall not result in accesses beyond the bounds of the objects referenced by their pointer parameters.\nThis rule strictly applies to the Standard Library functions in <string.h> such as memcpy, memmove, memset, memcmp, strcpy, strncpy, strcat, strncat, strlen, and strspn.\n</misra_rule>\n\nAnother agent reported that the target code violated the Rule 21.17.\nHere is the comment from the agent.\n<violation scenario>\nYes. lfs_cache_zero calls memset(pcache->buffer, 0xff, lfs->cfg->cache_size) without verifying that the user-supplied buffer is at least cfg->cache_size. In lfs_init, rcache.buffer is set to cfg->read_buffer when non-NULL (no size check). If cfg->read_buffer points to a buffer smaller than cfg->cache_size, the memset invoked by lfs_cache_zero will write past the end of that buffer, violating Rule 21.17.\n</violation scenario>\n\nYour job is to insert logging code to capture the control flow and state information of the program.\nInsert logging code so that other agents can reproduce and get evidence for the violation scenario.\n<response format>\n- test_code: a modified lfs_init code that contains useful probe functions that print useful logs to a file \"/tmp/logs/939.txt\". The logs should contain the control path and state information of the violation scenario. If test code is not required to validate the scenario, you can leave this blank.\nHere are the constraints for the test code:\n- The test code MUST preserve the original logic of lfs_init as much as possible.\nYou CAN just insert probe functions to the original code.\n- DO NOT introduce new violations to demonstrate your scenario.\n- The test code MUST be compilable and executable.\n- The test code MUST include line breaks.\n- You MUST NOT define the main function.\n- You MUST NOT define macros.\n</response format>\n<target_code>\nHere is the code of lfs_init:\n```c\nstatic int lfs_init(lfs_t *lfs, const struct lfs_config *cfg) {\n    lfs->cfg = cfg;\n    lfs->block_count = cfg->block_count;  // May be 0\n    int err = 0;\n\n#ifdef LFS_MULTIVERSION\n    // this driver only supports minor version < current minor version\n    LFS_ASSERT(!lfs->cfg->disk_version || (\n            (0xffff & (lfs->cfg->disk_version >> 16))\n                    == LFS_DISK_VERSION_MAJOR\n                && (0xffff & (lfs->cfg->disk_version >> 0))\n                    <= LFS_DISK_VERSION_MINOR));\n#endif\n\n    // check that bool is a truthy-preserving type\n    //\n    // note the most common reason for this failure is a before-c99 compiler,\n    // which littlefs currently does not support\n    LFS_ASSERT((bool)0x80000000);\n\n    // check that the required io functions are provided\n    LFS_ASSERT(lfs->cfg->read != NULL);\n#ifndef LFS_READONLY\n    LFS_ASSERT(lfs->cfg->prog != NULL);\n    LFS_ASSERT(lfs->cfg->erase != NULL);\n    LFS_ASSERT(lfs->cfg->sync != NULL);\n#endif\n\n    // validate that the lfs-cfg sizes were initiated properly before\n    // performing any arithmetic logics with them\n    LFS_ASSERT(lfs->cfg->read_size != 0);\n    LFS_ASSERT(lfs->cfg->prog_size != 0);\n    LFS_ASSERT(lfs->cfg->cache_size != 0);\n\n    // check that block size is a multiple of cache size is a multiple\n    // of prog and read sizes\n    LFS_ASSERT(lfs->cfg->cache_size % lfs->cfg->read_size == 0);\n    LFS_ASSERT(lfs->cfg->cache_size % lfs->cfg->prog_size == 0);\n    LFS_ASSERT(lfs->cfg->block_size % lfs->cfg->cache_size == 0);\n\n    // check that the block size is large enough to fit all ctz pointers\n    LFS_ASSERT(lfs->cfg->block_size >= 128);\n    // this is the exact calculation for all ctz pointers, if this fails\n    // and the simpler assert above does not, math must be broken\n    LFS_ASSERT(4*lfs_npw2(0xffffffff / (lfs->cfg->block_size-2*4))\n            <= lfs->cfg->block_size);\n\n    // block_cycles = 0 is no longer supported.\n    //\n    // block_cycles is the number of erase cycles before littlefs evicts\n    // metadata logs as a part of wear leveling. Suggested values are in the\n    // range of 100-1000, or set block_cycles to -1 to disable block-level\n    // wear-leveling.\n    LFS_ASSERT(lfs->cfg->block_cycles != 0);\n\n    // check that compact_thresh makes sense\n    //\n    // metadata can't be compacted below block_size/2, and metadata can't\n    // exceed a block_size\n    LFS_ASSERT(lfs->cfg->compact_thresh == 0\n            || lfs->cfg->compact_thresh >= lfs->cfg->block_size/2);\n    LFS_ASSERT(lfs->cfg->compact_thresh == (lfs_size_t)-1\n            || lfs->cfg->compact_thresh <= lfs->cfg->block_size);\n\n    // check that metadata_max is a multiple of read_size and prog_size,\n    // and a factor of the block_size\n    LFS_ASSERT(!lfs->cfg->metadata_max\n            || lfs->cfg->metadata_max % lfs->cfg->read_size == 0);\n    LFS_ASSERT(!lfs->cfg->metadata_max\n            || lfs->cfg->metadata_max % lfs->cfg->prog_size == 0);\n    LFS_ASSERT(!lfs->cfg->metadata_max\n            || lfs->cfg->block_size % lfs->cfg->metadata_max == 0);\n\n    // setup read cache\n    if (lfs->cfg->read_buffer) {\n        lfs->rcache.buffer = lfs->cfg->read_buffer;\n    } else {\n        lfs->rcache.buffer = lfs_malloc(lfs->cfg->cache_size);\n        if (!lfs->rcache.buffer) {\n            err = LFS_ERR_NOMEM;\n            goto cleanup;\n        }\n    }\n\n    // setup program cache\n    if (lfs->cfg->prog_buffer) {\n        lfs->pcache.buffer = lfs->cfg->prog_buffer;\n    } else {\n        lfs->pcache.buffer = lfs_malloc(lfs->cfg->cache_size);\n        if (!lfs->pcache.buffer) {\n            err = LFS_ERR_NOMEM;\n            goto cleanup;\n        }\n    }\n\n    // zero to avoid information leaks\n    lfs_cache_zero(lfs, &lfs->rcache);\n    lfs_cache_zero(lfs, &lfs->pcache);\n\n    // setup lookahead buffer, note mount finishes initializing this after\n    // we establish a decent pseudo-random seed\n    LFS_ASSERT(lfs->cfg->lookahead_size > 0);\n    if (lfs->cfg->lookahead_buffer) {\n        lfs->lookahead.buffer = lfs->cfg->lookahead_buffer;\n    } else {\n        lfs->lookahead.buffer = lfs_malloc(lfs->cfg->lookahead_size);\n        if (!lfs->lookahead.buffer) {\n            err = LFS_ERR_NOMEM;\n            goto cleanup;\n        }\n    }\n\n    // check that the size limits are sane\n    LFS_ASSERT(lfs->cfg->name_max <= LFS_NAME_MAX);\n    lfs->name_max = lfs->cfg->name_max;\n    if (!lfs->name_max) {\n        lfs->name_max = LFS_NAME_MAX;\n    }\n\n    LFS_ASSERT(lfs->cfg->file_max <= LFS_FILE_MAX);\n    lfs->file_max = lfs->cfg->file_max;\n    if (!lfs->file_max) {\n        lfs->file_max = LFS_FILE_MAX;\n    }\n\n    LFS_ASSERT(lfs->cfg->attr_max <= LFS_ATTR_MAX);\n    lfs->attr_max = lfs->cfg->attr_max;\n    if (!lfs->attr_max) {\n        lfs->attr_max = LFS_ATTR_MAX;\n    }\n\n    LFS_ASSERT(lfs->cfg->metadata_max <= lfs->cfg->block_size);\n\n    LFS_ASSERT(lfs->cfg->inline_max == (lfs_size_t)-1\n            || lfs->cfg->inline_max <= lfs->cfg->cache_size);\n    LFS_ASSERT(lfs->cfg->inline_max == (lfs_size_t)-1\n            || lfs->cfg->inline_max <= lfs->attr_max);\n    LFS_ASSERT(lfs->cfg->inline_max == (lfs_size_t)-1\n            || lfs->cfg->inline_max <= ((lfs->cfg->metadata_max)\n                ? lfs->cfg->metadata_max\n                : lfs->cfg->block_size)/8);\n    lfs->inline_max = lfs->cfg->inline_max;\n    if (lfs->inline_max == (lfs_size_t)-1) {\n        lfs->inline_max = 0;\n    } else if (lfs->inline_max == 0) {\n        lfs->inline_max = lfs_min(\n                lfs->cfg->cache_size,\n                lfs_min(\n                    lfs->attr_max,\n                    ((lfs->cfg->metadata_max)\n                        ? lfs->cfg->metadata_max\n                        : lfs->cfg->block_size)/8));\n    }\n\n    // setup default state\n    lfs->root[0] = LFS_BLOCK_NULL;\n    lfs->root[1] = LFS_BLOCK_NULL;\n    lfs->mlist = NULL;\n    lfs->seed = 0;\n    lfs->gdisk = (lfs_gstate_t){0};\n    lfs->gstate = (lfs_gstate_t){0};\n    lfs->gdelta = (lfs_gstate_t){0};\n#ifdef LFS_MIGRATE\n    lfs->lfs1 = NULL;\n#endif\n\n    return 0;\n\ncleanup:\n    lfs_deinit(lfs);\n    return err;\n}\n```\n</target_code>\nPlease provide the modified lfs_init code.\n",
  "test_code": "#include <stdio.h>\n#include <stdarg.h>\n#include <stddef.h>\n\n/* Probe logging helper: append formatted logs to /tmp/logs/939.txt */\nstatic void lfs_probe_log(const char *fmt, ...) {\n    FILE *f = fopen(\"/tmp/logs/939.txt\", \"a\");\n    if (!f) {\n        return;\n    }\n    va_list ap;\n    va_start(ap, fmt);\n    vfprintf(f, fmt, ap);\n    va_end(ap);\n    fprintf(f, \"\\n\");\n    fclose(f);\n}\n\n/* More structured log for important state snapshots */\nstatic void lfs_log_state(const char *stage, const lfs_t *lfs, const struct lfs_config *cfg) {\n    if (!cfg || !lfs) {\n        lfs_probe_log(\"[lfs_init] %s: lfs=%p cfg=%p\", stage, (const void*)lfs, (const void*)cfg);\n        return;\n    }\n    lfs_probe_log(\"[lfs_init] %s: lfs=%p cfg=%p\", stage, (const void*)lfs, (const void*)cfg);\n    lfs_probe_log(\"[lfs_init] %s: cfg->cache_size=%zu, cfg->read_buffer=%p, cfg->prog_buffer=%p, cfg->lookahead_buffer=%p\", stage,\n            (size_t)cfg->cache_size,\n            (const void*)cfg->read_buffer,\n            (const void*)cfg->prog_buffer,\n            (const void*)cfg->lookahead_buffer);\n    /* If lfs has caches already set, print them */\n    lfs_probe_log(\"[lfs_init] %s: rcache.buffer=%p pcache.buffer=%p lookahead.buffer=%p\",\n            stage,\n            (const void*)lfs->rcache.buffer,\n            (const void*)lfs->pcache.buffer,\n            (const void*)lfs->lookahead.buffer);\n}\n\nstatic int lfs_init(lfs_t *lfs, const struct lfs_config *cfg) {\n    lfs_probe_log(\"[lfs_init] enter: lfs=%p cfg=%p\", (void*)lfs, (void*)cfg);\n\n    lfs->cfg = cfg;\n    lfs->block_count = cfg->block_count;  // May be 0\n    int err = 0;\n\n#ifdef LFS_MULTIVERSION\n    // this driver only supports minor version < current minor version\n    LFS_ASSERT(!lfs->cfg->disk_version || (\n            (0xffff & (lfs->cfg->disk_version >> 16))\n                    == LFS_DISK_VERSION_MAJOR\n                && (0xffff & (lfs->cfg->disk_version >> 0))\n                    <= LFS_DISK_VERSION_MINOR));\n#endif\n\n    /* Log state after initial assignments */\n    lfs_log_state(\"after_assign\", lfs, cfg);\n\n    // check that bool is a truthy-preserving type\n    //\n    // note the most common reason for this failure is a before-c99 compiler,\n    // which littlefs currently does not support\n    LFS_ASSERT((bool)0x80000000);\n\n    // check that the required io functions are provided\n    LFS_ASSERT(lfs->cfg->read != NULL);\n#ifndef LFS_READONLY\n    LFS_ASSERT(lfs->cfg->prog != NULL);\n    LFS_ASSERT(lfs->cfg->erase != NULL);\n    LFS_ASSERT(lfs->cfg->sync != NULL);\n#endif\n\n    // validate that the lfs-cfg sizes were initiated properly before\n    // performing any arithmetic logics with them\n    LFS_ASSERT(lfs->cfg->read_size != 0);\n    LFS_ASSERT(lfs->cfg->prog_size != 0);\n    LFS_ASSERT(lfs->cfg->cache_size != 0);\n\n    // check that block size is a multiple of cache size is a multiple\n    // of prog and read sizes\n    LFS_ASSERT(lfs->cfg->cache_size % lfs->cfg->read_size == 0);\n    LFS_ASSERT(lfs->cfg->cache_size % lfs->cfg->prog_size == 0);\n    LFS_ASSERT(lfs->cfg->block_size % lfs->cfg->cache_size == 0);\n\n    // check that the block size is large enough to fit all ctz pointers\n    LFS_ASSERT(lfs->cfg->block_size >= 128);\n    // this is the exact calculation for all ctz pointers, if this fails\n    // and the simpler assert above does not, math must be broken\n    LFS_ASSERT(4*lfs_npw2(0xffffffff / (lfs->cfg->block_size-2*4))\n            <= lfs->cfg->block_size);\n\n    // block_cycles = 0 is no longer supported.\n    //\n    // block_cycles is the number of erase cycles before littlefs evicts\n    // metadata logs as a part of wear leveling. Suggested values are in the\n    // range of 100-1000, or set block_cycles to -1 to disable block-level\n    // wear-leveling.\n    LFS_ASSERT(lfs->cfg->block_cycles != 0);\n\n    // check that compact_thresh makes sense\n    //\n    // metadata can't be compacted below block_size/2, and metadata can't\n    // exceed a block_size\n    LFS_ASSERT(lfs->cfg->compact_thresh == 0\n            || lfs->cfg->compact_thresh >= lfs->cfg->block_size/2);\n    LFS_ASSERT(lfs->cfg->compact_thresh == (lfs_size_t)-1\n            || lfs->cfg->compact_thresh <= lfs->cfg->block_size);\n\n    // check that metadata_max is a multiple of read_size and prog_size,\n    // and a factor of the block_size\n    LFS_ASSERT(!lfs->cfg->metadata_max\n            || lfs->cfg->metadata_max % lfs->cfg->read_size == 0);\n    LFS_ASSERT(!lfs->cfg->metadata_max\n            || lfs->cfg->metadata_max % lfs->cfg->prog_size == 0);\n    LFS_ASSERT(!lfs->cfg->metadata_max\n            || lfs->cfg->block_size % lfs->cfg->metadata_max == 0);\n\n    /* Log state before setting up read cache */\n    lfs_log_state(\"before_read_cache\", lfs, cfg);\n\n    // setup read cache\n    if (lfs->cfg->read_buffer) {\n        lfs->rcache.buffer = lfs->cfg->read_buffer;\n        lfs_probe_log(\"[lfs_init] using user-supplied read_buffer=%p for rcache (no size check performed)\", (void*)lfs->rcache.buffer);\n    } else {\n        lfs->rcache.buffer = lfs_malloc(lfs->cfg->cache_size);\n        lfs_probe_log(\"[lfs_init] allocated rcache.buffer=%p of size=%zu\", (void*)lfs->rcache.buffer, (size_t)lfs->cfg->cache_size);\n        if (!lfs->rcache.buffer) {\n            err = LFS_ERR_NOMEM;\n            lfs_probe_log(\"[lfs_init] rcache allocation failed (NOMEM), err=%d\", err);\n            goto cleanup;\n        }\n    }\n\n    /* Log state after read cache setup */\n    lfs_log_state(\"after_read_cache\", lfs, cfg);\n\n    // setup program cache\n    if (lfs->cfg->prog_buffer) {\n        lfs->pcache.buffer = lfs->cfg->prog_buffer;\n        lfs_probe_log(\"[lfs_init] using user-supplied prog_buffer=%p for pcache (no size check performed)\", (void*)lfs->pcache.buffer);\n    } else {\n        lfs->pcache.buffer = lfs_malloc(lfs->cfg->cache_size);\n        lfs_probe_log(\"[lfs_init] allocated pcache.buffer=%p of size=%zu\", (void*)lfs->pcache.buffer, (size_t)lfs->cfg->cache_size);\n        if (!lfs->pcache.buffer) {\n            err = LFS_ERR_NOMEM;\n            lfs_probe_log(\"[lfs_init] pcache allocation failed (NOMEM), err=%d\", err);\n            goto cleanup;\n        }\n    }\n\n    /* Log state after prog cache setup */\n    lfs_log_state(\"after_prog_cache\", lfs, cfg);\n\n    // zero to avoid information leaks\n    lfs_probe_log(\"[lfs_init] calling lfs_cache_zero for rcache (buffer=%p, cache_size=%zu)\", (void*)lfs->rcache.buffer, (size_t)lfs->cfg->cache_size);\n    lfs_cache_zero(lfs, &lfs->rcache);\n    lfs_probe_log(\"[lfs_init] returned from lfs_cache_zero for rcache\");\n\n    lfs_probe_log(\"[lfs_init] calling lfs_cache_zero for pcache (buffer=%p, cache_size=%zu)\", (void*)lfs->pcache.buffer, (size_t)lfs->cfg->cache_size);\n    lfs_cache_zero(lfs, &lfs->pcache);\n    lfs_probe_log(\"[lfs_init] returned from lfs_cache_zero for pcache\");\n\n    /* Log state after zeroing caches */\n    lfs_log_state(\"after_zeroing_caches\", lfs, cfg);\n\n    // setup lookahead buffer, note mount finishes initializing this after\n    // we establish a decent pseudo-random seed\n    LFS_ASSERT(lfs->cfg->lookahead_size > 0);\n    if (lfs->cfg->lookahead_buffer) {\n        lfs->lookahead.buffer = lfs->cfg->lookahead_buffer;\n        lfs_probe_log(\"[lfs_init] using user-supplied lookahead_buffer=%p\", (void*)lfs->lookahead.buffer);\n    } else {\n        lfs->lookahead.buffer = lfs_malloc(lfs->cfg->lookahead_size);\n        lfs_probe_log(\"[lfs_init] allocated lookahead.buffer=%p of size=%zu\", (void*)lfs->lookahead.buffer, (size_t)lfs->cfg->lookahead_size);\n        if (!lfs->lookahead.buffer) {\n            err = LFS_ERR_NOMEM;\n            lfs_probe_log(\"[lfs_init] lookahead allocation failed (NOMEM), err=%d\", err);\n            goto cleanup;\n        }\n    }\n\n    /* Final state log before returning success */\n    lfs_log_state(\"final_before_return\", lfs, cfg);\n\n    // check that the size limits are sane\n    LFS_ASSERT(lfs->cfg->name_max <= LFS_NAME_MAX);\n    lfs->name_max = lfs->cfg->name_max;\n    if (!lfs->name_max) {\n        lfs->name_max = LFS_NAME_MAX;\n    }\n\n    LFS_ASSERT(lfs->cfg->file_max <= LFS_FILE_MAX);\n    lfs->file_max = lfs->cfg->file_max;\n    if (!lfs->file_max) {\n        lfs->file_max = LFS_FILE_MAX;\n    }\n\n    LFS_ASSERT(lfs->cfg->attr_max <= LFS_ATTR_MAX);\n    lfs->attr_max = lfs->cfg->attr_max;\n    if (!lfs->attr_max) {\n        lfs->attr_max = LFS_ATTR_MAX;\n    }\n\n    LFS_ASSERT(lfs->cfg->metadata_max <= lfs->cfg->block_size);\n\n    LFS_ASSERT(lfs->cfg->inline_max == (lfs_size_t)-1\n            || lfs->cfg->inline_max <= lfs->cfg->cache_size);\n    LFS_ASSERT(lfs->cfg->inline_max == (lfs_size_t)-1\n            || lfs->cfg->inline_max <= lfs->attr_max);\n    LFS_ASSERT(lfs->cfg->inline_max == (lfs_size_t)-1\n            || lfs->cfg->inline_max <= ((lfs->cfg->metadata_max)\n                ? lfs->cfg->metadata_max\n                : lfs->cfg->block_size)/8);\n    lfs->inline_max = lfs->cfg->inline_max;\n    if (lfs->inline_max == (lfs_size_t)-1) {\n        lfs->inline_max = 0;\n    } else if (lfs->inline_max == 0) {\n        lfs->inline_max = lfs_min(\n                lfs->cfg->cache_size,\n                lfs_min(\n                    lfs->attr_max,\n                    ((lfs->cfg->metadata_max)\n                        ? lfs->cfg->metadata_max\n                        : lfs->cfg->block_size)/8));\n    }\n\n    // setup default state\n    lfs->root[0] = LFS_BLOCK_NULL;\n    lfs->root[1] = LFS_BLOCK_NULL;\n    lfs->mlist = NULL;\n    lfs->seed = 0;\n    lfs->gdisk = (lfs_gstate_t){0};\n    lfs->gstate = (lfs_gstate_t){0};\n    lfs->gdelta = (lfs_gstate_t){0};\n#ifdef LFS_MIGRATE\n    lfs->lfs1 = NULL;\n#endif\n\n    lfs_probe_log(\"[lfs_init] exit: success (return 0)\");\n    return 0;\n\ncleanup:\n    lfs_probe_log(\"[lfs_init] cleanup: err=%d, calling lfs_deinit(lfs)\", err);\n    lfs_deinit(lfs);\n    return err;\n}\n"
}