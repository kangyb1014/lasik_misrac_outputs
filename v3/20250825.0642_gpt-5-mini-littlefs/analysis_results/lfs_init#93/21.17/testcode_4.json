{
  "user_message": "<misra_rule>\nMISRA C 2023 Rule 21.17 is: Use of the string handling functions from <string.h> shall not result in accesses beyond the bounds of the objects referenced by their pointer parameters.\nThis rule strictly applies to the Standard Library functions in <string.h> such as memcpy, memmove, memset, memcmp, strcpy, strncpy, strcat, strncat, strlen, and strspn.\n</misra_rule>\n\nAnother agent reported that the target code violated the Rule 21.17.\nHere is the comment from the agent.\n<violation scenario>\nThe call memset(pcache->buffer, 0xff, lfs->cfg->cache_size) can write beyond the bounds of pcache->buffer if the buffer provided by the caller (cfg->read_buffer or cfg->prog_buffer) is smaller than cfg->cache_size or is NULL. In lfs_init the code assigns user-supplied buffers directly without validating their actual size (only cache_size itself is asserted), and LFS_ASSERT may be a no-op in some builds. Therefore memset may access out-of-bounds memory and violate Rule 21.17.\n</violation scenario>\n\nYour job is to insert logging code to capture the control flow and state information of the program.\nInsert logging code so that other agents can reproduce and get evidence for the violation scenario.\n<response format>\n- test_code: a modified lfs_init code that contains useful probe functions that print useful logs to a file \"/tmp/logs/939.txt\". The logs should contain the control path and state information of the violation scenario. If test code is not required to validate the scenario, you can leave this blank.\nHere are the constraints for the test code:\n- The test code MUST preserve the original logic of lfs_init as much as possible.\nYou CAN just insert probe functions to the original code.\n- DO NOT introduce new violations to demonstrate your scenario.\n- The test code MUST be compilable and executable.\n- The test code MUST include line breaks.\n- You MUST NOT define the main function.\n- You MUST NOT define macros.\n</response format>\n<target_code>\nHere is the code of lfs_init:\n```c\nstatic int lfs_init(lfs_t *lfs, const struct lfs_config *cfg) {\n    lfs->cfg = cfg;\n    lfs->block_count = cfg->block_count;  // May be 0\n    int err = 0;\n\n#ifdef LFS_MULTIVERSION\n    // this driver only supports minor version < current minor version\n    LFS_ASSERT(!lfs->cfg->disk_version || (\n            (0xffff & (lfs->cfg->disk_version >> 16))\n                    == LFS_DISK_VERSION_MAJOR\n                && (0xffff & (lfs->cfg->disk_version >> 0))\n                    <= LFS_DISK_VERSION_MINOR));\n#endif\n\n    // check that bool is a truthy-preserving type\n    //\n    // note the most common reason for this failure is a before-c99 compiler,\n    // which littlefs currently does not support\n    LFS_ASSERT((bool)0x80000000);\n\n    // check that the required io functions are provided\n    LFS_ASSERT(lfs->cfg->read != NULL);\n#ifndef LFS_READONLY\n    LFS_ASSERT(lfs->cfg->prog != NULL);\n    LFS_ASSERT(lfs->cfg->erase != NULL);\n    LFS_ASSERT(lfs->cfg->sync != NULL);\n#endif\n\n    // validate that the lfs-cfg sizes were initiated properly before\n    // performing any arithmetic logics with them\n    LFS_ASSERT(lfs->cfg->read_size != 0);\n    LFS_ASSERT(lfs->cfg->prog_size != 0);\n    LFS_ASSERT(lfs->cfg->cache_size != 0);\n\n    // check that block size is a multiple of cache size is a multiple\n    // of prog and read sizes\n    LFS_ASSERT(lfs->cfg->cache_size % lfs->cfg->read_size == 0);\n    LFS_ASSERT(lfs->cfg->cache_size % lfs->cfg->prog_size == 0);\n    LFS_ASSERT(lfs->cfg->block_size % lfs->cfg->cache_size == 0);\n\n    // check that the block size is large enough to fit all ctz pointers\n    LFS_ASSERT(lfs->cfg->block_size >= 128);\n    // this is the exact calculation for all ctz pointers, if this fails\n    // and the simpler assert above does not, math must be broken\n    LFS_ASSERT(4*lfs_npw2(0xffffffff / (lfs->cfg->block_size-2*4))\n            <= lfs->cfg->block_size);\n\n    // block_cycles = 0 is no longer supported.\n    //\n    // block_cycles is the number of erase cycles before littlefs evicts\n    // metadata logs as a part of wear leveling. Suggested values are in the\n    // range of 100-1000, or set block_cycles to -1 to disable block-level\n    // wear-leveling.\n    LFS_ASSERT(lfs->cfg->block_cycles != 0);\n\n    // check that compact_thresh makes sense\n    //\n    // metadata can't be compacted below block_size/2, and metadata can't\n    // exceed a block_size\n    LFS_ASSERT(lfs->cfg->compact_thresh == 0\n            || lfs->cfg->compact_thresh >= lfs->cfg->block_size/2);\n    LFS_ASSERT(lfs->cfg->compact_thresh == (lfs_size_t)-1\n            || lfs->cfg->compact_thresh <= lfs->cfg->block_size);\n\n    // check that metadata_max is a multiple of read_size and prog_size,\n    // and a factor of the block_size\n    LFS_ASSERT(!lfs->cfg->metadata_max\n            || lfs->cfg->metadata_max % lfs->cfg->read_size == 0);\n    LFS_ASSERT(!lfs->cfg->metadata_max\n            || lfs->cfg->metadata_max % lfs->cfg->prog_size == 0);\n    LFS_ASSERT(!lfs->cfg->metadata_max\n            || lfs->cfg->block_size % lfs->cfg->metadata_max == 0);\n\n    // setup read cache\n    if (lfs->cfg->read_buffer) {\n        lfs->rcache.buffer = lfs->cfg->read_buffer;\n    } else {\n        lfs->rcache.buffer = lfs_malloc(lfs->cfg->cache_size);\n        if (!lfs->rcache.buffer) {\n            err = LFS_ERR_NOMEM;\n            goto cleanup;\n        }\n    }\n\n    // setup program cache\n    if (lfs->cfg->prog_buffer) {\n        lfs->pcache.buffer = lfs->cfg->prog_buffer;\n    } else {\n        lfs->pcache.buffer = lfs_malloc(lfs->cfg->cache_size);\n        if (!lfs->pcache.buffer) {\n            err = LFS_ERR_NOMEM;\n            goto cleanup;\n        }\n    }\n\n    // zero to avoid information leaks\n    lfs_cache_zero(lfs, &lfs->rcache);\n    lfs_cache_zero(lfs, &lfs->pcache);\n\n    // setup lookahead buffer, note mount finishes initializing this after\n    // we establish a decent pseudo-random seed\n    LFS_ASSERT(lfs->cfg->lookahead_size > 0);\n    if (lfs->cfg->lookahead_buffer) {\n        lfs->lookahead.buffer = lfs->cfg->lookahead_buffer;\n    } else {\n        lfs->lookahead.buffer = lfs_malloc(lfs->cfg->lookahead_size);\n        if (!lfs->lookahead.buffer) {\n            err = LFS_ERR_NOMEM;\n            goto cleanup;\n        }\n    }\n\n    // check that the size limits are sane\n    LFS_ASSERT(lfs->cfg->name_max <= LFS_NAME_MAX);\n    lfs->name_max = lfs->cfg->name_max;\n    if (!lfs->name_max) {\n        lfs->name_max = LFS_NAME_MAX;\n    }\n\n    LFS_ASSERT(lfs->cfg->file_max <= LFS_FILE_MAX);\n    lfs->file_max = lfs->cfg->file_max;\n    if (!lfs->file_max) {\n        lfs->file_max = LFS_FILE_MAX;\n    }\n\n    LFS_ASSERT(lfs->cfg->attr_max <= LFS_ATTR_MAX);\n    lfs->attr_max = lfs->cfg->attr_max;\n    if (!lfs->attr_max) {\n        lfs->attr_max = LFS_ATTR_MAX;\n    }\n\n    LFS_ASSERT(lfs->cfg->metadata_max <= lfs->cfg->block_size);\n\n    LFS_ASSERT(lfs->cfg->inline_max == (lfs_size_t)-1\n            || lfs->cfg->inline_max <= lfs->cfg->cache_size);\n    LFS_ASSERT(lfs->cfg->inline_max == (lfs_size_t)-1\n            || lfs->cfg->inline_max <= lfs->attr_max);\n    LFS_ASSERT(lfs->cfg->inline_max == (lfs_size_t)-1\n            || lfs->cfg->inline_max <= ((lfs->cfg->metadata_max)\n                ? lfs->cfg->metadata_max\n                : lfs->cfg->block_size)/8);\n    lfs->inline_max = lfs->cfg->inline_max;\n    if (lfs->inline_max == (lfs_size_t)-1) {\n        lfs->inline_max = 0;\n    } else if (lfs->inline_max == 0) {\n        lfs->inline_max = lfs_min(\n                lfs->cfg->cache_size,\n                lfs_min(\n                    lfs->attr_max,\n                    ((lfs->cfg->metadata_max)\n                        ? lfs->cfg->metadata_max\n                        : lfs->cfg->block_size)/8));\n    }\n\n    // setup default state\n    lfs->root[0] = LFS_BLOCK_NULL;\n    lfs->root[1] = LFS_BLOCK_NULL;\n    lfs->mlist = NULL;\n    lfs->seed = 0;\n    lfs->gdisk = (lfs_gstate_t){0};\n    lfs->gstate = (lfs_gstate_t){0};\n    lfs->gdelta = (lfs_gstate_t){0};\n#ifdef LFS_MIGRATE\n    lfs->lfs1 = NULL;\n#endif\n\n    return 0;\n\ncleanup:\n    lfs_deinit(lfs);\n    return err;\n}\n```\n</target_code>\nPlease provide the modified lfs_init code.\n",
  "test_code": "#include <stdio.h>\n#include <stdarg.h>\n\nstatic void lfs_logf(const char *fmt, ...) {\n    FILE *f = fopen(\"/tmp/logs/939.txt\", \"a\");\n    if (!f) {\n        return;\n    }\n    va_list ap;\n    va_start(ap, fmt);\n    vfprintf(f, fmt, ap);\n    va_end(ap);\n    fprintf(f, \"\\n\");\n    fclose(f);\n}\n\nstatic int lfs_init(lfs_t *lfs, const struct lfs_config *cfg) {\n    /* Log entry and key configuration values so we can reproduce the\n     * conditions that may lead to an out-of-bounds access during\n     * subsequent memset calls (e.g. inside lfs_cache_zero). */\n    lfs_logf(\"lfs_init: entry: lfs=%p cfg=%p\", (void*)lfs, (void*)cfg);\n    if (cfg) {\n        lfs_logf(\"cfg snapshot: block_count=%llu block_size=%llu cache_size=%llu read_size=%llu prog_size=%llu\",\n                (unsigned long long)cfg->block_count,\n                (unsigned long long)cfg->block_size,\n                (unsigned long long)cfg->cache_size,\n                (unsigned long long)cfg->read_size,\n                (unsigned long long)cfg->prog_size);\n        lfs_logf(\"cfg buffers: read_buffer=%p prog_buffer=%p lookahead_buffer=%p\",\n                (void*)cfg->read_buffer, (void*)cfg->prog_buffer, (void*)cfg->lookahead_buffer);\n        lfs_logf(\"cfg limits: name_max=%llu file_max=%llu attr_max=%llu metadata_max=%llu inline_max=%llu\",\n                (unsigned long long)cfg->name_max,\n                (unsigned long long)cfg->file_max,\n                (unsigned long long)cfg->attr_max,\n                (unsigned long long)cfg->metadata_max,\n                (unsigned long long)cfg->inline_max);\n        lfs_logf(\"cfg other: block_cycles=%lld compact_thresh=%llu\",\n                (long long)cfg->block_cycles,\n                (unsigned long long)cfg->compact_thresh);\n    }\n\n    lfs->cfg = cfg;\n    lfs->block_count = cfg->block_count;  // May be 0\n    int err = 0;\n\n#ifdef LFS_MULTIVERSION\n    // this driver only supports minor version < current minor version\n    LFS_ASSERT(!lfs->cfg->disk_version || (\n            (0xffff & (lfs->cfg->disk_version >> 16))\n                    == LFS_DISK_VERSION_MAJOR\n                && (0xffff & (lfs->cfg->disk_version >> 0))\n                    <= LFS_DISK_VERSION_MINOR));\n#endif\n\n    // check that bool is a truthy-preserving type\n    //\n    // note the most common reason for this failure is a before-c99 compiler,\n    // which littlefs currently does not support\n    LFS_ASSERT((bool)0x80000000);\n\n    // check that the required io functions are provided\n    LFS_ASSERT(lfs->cfg->read != NULL);\n#ifndef LFS_READONLY\n    LFS_ASSERT(lfs->cfg->prog != NULL);\n    LFS_ASSERT(lfs->cfg->erase != NULL);\n    LFS_ASSERT(lfs->cfg->sync != NULL);\n#endif\n\n    // validate that the lfs-cfg sizes were initiated properly before\n    // performing any arithmetic logics with them\n    LFS_ASSERT(lfs->cfg->read_size != 0);\n    LFS_ASSERT(lfs->cfg->prog_size != 0);\n    LFS_ASSERT(lfs->cfg->cache_size != 0);\n\n    // check that block size is a multiple of cache size is a multiple\n    // of prog and read sizes\n    LFS_ASSERT(lfs->cfg->cache_size % lfs->cfg->read_size == 0);\n    LFS_ASSERT(lfs->cfg->cache_size % lfs->cfg->prog_size == 0);\n    LFS_ASSERT(lfs->cfg->block_size % lfs->cfg->cache_size == 0);\n\n    // check that the block size is large enough to fit all ctz pointers\n    LFS_ASSERT(lfs->cfg->block_size >= 128);\n    // this is the exact calculation for all ctz pointers, if this fails\n    // and the simpler assert above does not, math must be broken\n    LFS_ASSERT(4*lfs_npw2(0xffffffff / (lfs->cfg->block_size-2*4))\n            <= lfs->cfg->block_size);\n\n    // block_cycles = 0 is no longer supported.\n    //\n    // block_cycles is the number of erase cycles before littlefs evicts\n    // metadata logs as a part of wear leveling. Suggested values are in the\n    // range of 100-1000, or set block_cycles to -1 to disable block-level\n    // wear-leveling.\n    LFS_ASSERT(lfs->cfg->block_cycles != 0);\n\n    // check that compact_thresh makes sense\n    //\n    // metadata can't be compacted below block_size/2, and metadata can't\n    // exceed a block_size\n    LFS_ASSERT(lfs->cfg->compact_thresh == 0\n            || lfs->cfg->compact_thresh >= lfs->cfg->block_size/2);\n    LFS_ASSERT(lfs->cfg->compact_thresh == (lfs_size_t)-1\n            || lfs->cfg->compact_thresh <= lfs->cfg->block_size);\n\n    // check that metadata_max is a multiple of read_size and prog_size,\n    // and a factor of the block_size\n    LFS_ASSERT(!lfs->cfg->metadata_max\n            || lfs->cfg->metadata_max % lfs->cfg->read_size == 0);\n    LFS_ASSERT(!lfs->cfg->metadata_max\n            || lfs->cfg->metadata_max % lfs->cfg->prog_size == 0);\n    LFS_ASSERT(!lfs->cfg->metadata_max\n            || lfs->cfg->block_size % lfs->cfg->metadata_max == 0);\n\n    /* setup read cache */\n    if (lfs->cfg->read_buffer) {\n        lfs_logf(\"rcache: using user read_buffer=%p cache_size=%llu\",\n                (void*)lfs->cfg->read_buffer,\n                (unsigned long long)lfs->cfg->cache_size);\n        lfs->rcache.buffer = lfs->cfg->read_buffer;\n    } else {\n        lfs_logf(\"rcache: allocating cache_size=%llu\",\n                (unsigned long long)lfs->cfg->cache_size);\n        lfs->rcache.buffer = lfs_malloc(lfs->cfg->cache_size);\n        lfs_logf(\"rcache: allocated buffer=%p\", (void*)lfs->rcache.buffer);\n        if (!lfs->rcache.buffer) {\n            err = LFS_ERR_NOMEM;\n            lfs_logf(\"rcache: allocation failed, err=%d\", err);\n            goto cleanup;\n        }\n    }\n\n    /* setup program cache */\n    if (lfs->cfg->prog_buffer) {\n        lfs_logf(\"pcache: using user prog_buffer=%p cache_size=%llu\",\n                (void*)lfs->cfg->prog_buffer,\n                (unsigned long long)lfs->cfg->cache_size);\n        lfs->pcache.buffer = lfs->cfg->prog_buffer;\n    } else {\n        lfs_logf(\"pcache: allocating cache_size=%llu\",\n                (unsigned long long)lfs->cfg->cache_size);\n        lfs->pcache.buffer = lfs_malloc(lfs->cfg->cache_size);\n        lfs_logf(\"pcache: allocated buffer=%p\", (void*)lfs->pcache.buffer);\n        if (!lfs->pcache.buffer) {\n            err = LFS_ERR_NOMEM;\n            lfs_logf(\"pcache: allocation failed, err=%d\", err);\n            goto cleanup;\n        }\n    }\n\n    /* zero to avoid information leaks */\n    lfs_logf(\"about to zero rcache: buffer=%p cache_size=%llu\",\n            (void*)lfs->rcache.buffer,\n            (unsigned long long)lfs->cfg->cache_size);\n    lfs_cache_zero(lfs, &lfs->rcache);\n    lfs_logf(\"completed zero rcache: buffer=%p\", (void*)lfs->rcache.buffer);\n\n    lfs_logf(\"about to zero pcache: buffer=%p cache_size=%llu\",\n            (void*)lfs->pcache.buffer,\n            (unsigned long long)lfs->cfg->cache_size);\n    lfs_cache_zero(lfs, &lfs->pcache);\n    lfs_logf(\"completed zero pcache: buffer=%p\", (void*)lfs->pcache.buffer);\n\n    /* setup lookahead buffer, note mount finishes initializing this after\n     * we establish a decent pseudo-random seed */\n    LFS_ASSERT(lfs->cfg->lookahead_size > 0);\n    if (lfs->cfg->lookahead_buffer) {\n        lfs_logf(\"lookahead: using user buffer=%p size=%llu\",\n                (void*)lfs->cfg->lookahead_buffer,\n                (unsigned long long)lfs->cfg->lookahead_size);\n        lfs->lookahead.buffer = lfs->cfg->lookahead_buffer;\n    } else {\n        lfs_logf(\"lookahead: allocating size=%llu\",\n                (unsigned long long)lfs->cfg->lookahead_size);\n        lfs->lookahead.buffer = lfs_malloc(lfs->cfg->lookahead_size);\n        lfs_logf(\"lookahead: allocated buffer=%p\", (void*)lfs->lookahead.buffer);\n        if (!lfs->lookahead.buffer) {\n            err = LFS_ERR_NOMEM;\n            lfs_logf(\"lookahead: allocation failed, err=%d\", err);\n            goto cleanup;\n        }\n    }\n\n    /* check that the size limits are sane */\n    LFS_ASSERT(lfs->cfg->name_max <= LFS_NAME_MAX);\n    lfs->name_max = lfs->cfg->name_max;\n    if (!lfs->name_max) {\n        lfs->name_max = LFS_NAME_MAX;\n    }\n\n    LFS_ASSERT(lfs->cfg->file_max <= LFS_FILE_MAX);\n    lfs->file_max = lfs->cfg->file_max;\n    if (!lfs->file_max) {\n        lfs->file_max = LFS_FILE_MAX;\n    }\n\n    LFS_ASSERT(lfs->cfg->attr_max <= LFS_ATTR_MAX);\n    lfs->attr_max = lfs->cfg->attr_max;\n    if (!lfs->attr_max) {\n        lfs->attr_max = LFS_ATTR_MAX;\n    }\n\n    LFS_ASSERT(lfs->cfg->metadata_max <= lfs->cfg->block_size);\n\n    LFS_ASSERT(lfs->cfg->inline_max == (lfs_size_t)-1\n            || lfs->cfg->inline_max <= lfs->cfg->cache_size);\n    LFS_ASSERT(lfs->cfg->inline_max == (lfs_size_t)-1\n            || lfs->cfg->inline_max <= lfs->attr_max);\n    LFS_ASSERT(lfs->cfg->inline_max == (lfs_size_t)-1\n            || lfs->cfg->inline_max <= ((lfs->cfg->metadata_max)\n                ? lfs->cfg->metadata_max\n                : lfs->cfg->block_size)/8);\n    lfs->inline_max = lfs->cfg->inline_max;\n    if (lfs->inline_max == (lfs_size_t)-1) {\n        lfs->inline_max = 0;\n    } else if (lfs->inline_max == 0) {\n        lfs->inline_max = lfs_min(\n                lfs->cfg->cache_size,\n                lfs_min(\n                    lfs->attr_max,\n                    ((lfs->cfg->metadata_max)\n                        ? lfs->cfg->metadata_max\n                        : lfs->cfg->block_size)/8));\n    }\n\n    /* setup default state */\n    lfs->root[0] = LFS_BLOCK_NULL;\n    lfs->root[1] = LFS_BLOCK_NULL;\n    lfs->mlist = NULL;\n    lfs->seed = 0;\n    lfs->gdisk = (lfs_gstate_t){0};\n    lfs->gstate = (lfs_gstate_t){0};\n    lfs->gdelta = (lfs_gstate_t){0};\n#ifdef LFS_MIGRATE\n    lfs->lfs1 = NULL;\n#endif\n\n    lfs_logf(\"lfs_init: success returning 0 lfs=%p\", (void*)lfs);\n    return 0;\n\ncleanup:\n    lfs_logf(\"lfs_init: cleanup called err=%d\", err);\n    lfs_deinit(lfs);\n    return err;\n}\n"
}