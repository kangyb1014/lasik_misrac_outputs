{
  "user_message": "<misra_rule>\nMISRA C 2023 Rule 21.17 is: Use of the string handling functions from <string.h> shall not result in accesses beyond the bounds of the objects referenced by their pointer parameters.\nThis rule strictly applies to the Standard Library functions in <string.h> such as memcpy, memmove, memset, memcmp, strcpy, strncpy, strcat, strncat, strlen, and strspn.\n</misra_rule>\n<response format>\nProvide your answer with these fields.\n- is_rule_violated: whether the rule is violated or not (true/false),\n- scenario: a specific violation scenario.\n</response format>\n<target_code>\nHere is the code of lfs_file_truncate:\n```c\nint lfs_file_truncate(lfs_t *lfs, lfs_file_t *file, lfs_off_t size) {\n    int err = LFS_LOCK(lfs->cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_file_truncate(%p, %p, %\"PRIu32\")\",\n            (void*)lfs, (void*)file, size);\n    LFS_ASSERT(lfs_mlist_isopen(lfs->mlist, (struct lfs_mlist*)file));\n\n    err = lfs_file_truncate_(lfs, file, size);\n\n    LFS_TRACE(\"lfs_file_truncate -> %d\", err);\n    LFS_UNLOCK(lfs->cfg);\n    return err;\n}\n```\n</target_code>\n<additional code>Here are the definitions of symbols that are close to the target function lfs_file_truncate:\nstatic int lfs_file_truncate_(lfs_t *lfs, lfs_file_t *file, lfs_off_t size) {\n    LFS_ASSERT((file->flags & LFS_O_WRONLY) == LFS_O_WRONLY);\n\n    if (size > LFS_FILE_MAX) {\n        return LFS_ERR_INVAL;\n    }\n\n    lfs_off_t pos = file->pos;\n    lfs_off_t oldsize = lfs_file_size_(lfs, file);\n    if (size < oldsize) {\n        // revert to inline file?\n        if (size <= lfs->inline_max) {\n            // flush+seek to head\n            lfs_soff_t res = lfs_file_seek_(lfs, file, 0, LFS_SEEK_SET);\n            if (res < 0) {\n                return (int)res;\n            }\n\n            // read our data into rcache temporarily\n            lfs_cache_drop(lfs, &lfs->rcache);\n            res = lfs_file_flushedread(lfs, file,\n                    lfs->rcache.buffer, size);\n            if (res < 0) {\n                return (int)res;\n            }\n\n            file->ctz.head = LFS_BLOCK_INLINE;\n            file->ctz.size = size;\n            file->flags |= LFS_F_DIRTY | LFS_F_READING | LFS_F_INLINE;\n            file->cache.block = file->ctz.head;\n            file->cache.off = 0;\n            file->cache.size = lfs->cfg->cache_size;\n            memcpy(file->cache.buffer, lfs->rcache.buffer, size);\n\n        } else {\n            // need to flush since directly changing metadata\n            int err = lfs_file_flush(lfs, file);\n            if (err) {\n                return err;\n            }\n\n            // lookup new head in ctz skip list\n            err = lfs_ctz_find(lfs, NULL, &file->cache,\n                    file->ctz.head, file->ctz.size,\n                    size-1, &file->block, &(lfs_off_t){0});\n            if (err) {\n                return err;\n            }\n\n            // need to set pos/block/off consistently so seeking back to\n            // the old position does not get confused\n            file->pos = size;\n            file->ctz.head = file->block;\n            file->ctz.size = size;\n            file->flags |= LFS_F_DIRTY | LFS_F_READING;\n        }\n    } else if (size > oldsize) {\n        // flush+seek if not already at end\n        lfs_soff_t res = lfs_file_seek_(lfs, file, 0, LFS_SEEK_END);\n        if (res < 0) {\n            return (int)res;\n        }\n\n        // fill with zeros\n        while (file->pos < size) {\n            res = lfs_file_write_(lfs, file, &(uint8_t){0}, 1);\n            if (res < 0) {\n                return (int)res;\n            }\n        }\n    }\n\n    // restore pos\n    lfs_soff_t res = lfs_file_seek_(lfs, file, pos, LFS_SEEK_SET);\n    if (res < 0) {\n      return (int)res;\n    }\n\n    return 0;\n}\n...\nstatic lfs_soff_t lfs_file_size_(lfs_t *lfs, lfs_file_t *file) {\n    (void)lfs;\n\n#ifndef LFS_READONLY\n    if (file->flags & LFS_F_WRITING) {\n        return lfs_max(file->pos, file->ctz.size);\n    }\n#endif\n\n    return file->ctz.size;\n}\n...\nstatic lfs_soff_t lfs_file_seek_(lfs_t *lfs, lfs_file_t *file,\n        lfs_soff_t off, int whence) {\n    // find new pos\n    //\n    // fortunately for us, littlefs is limited to 31-bit file sizes, so we\n    // don't have to worry too much about integer overflow\n    lfs_off_t npos = file->pos;\n    if (whence == LFS_SEEK_SET) {\n        npos = off;\n    } else if (whence == LFS_SEEK_CUR) {\n        npos = file->pos + (lfs_off_t)off;\n    } else if (whence == LFS_SEEK_END) {\n        npos = (lfs_off_t)lfs_file_size_(lfs, file) + (lfs_off_t)off;\n    }\n\n    if (npos > lfs->file_max) {\n        // file position out of range\n        return LFS_ERR_INVAL;\n    }\n\n    if (file->pos == npos) {\n        // noop - position has not changed\n        return npos;\n    }\n\n    // if we're only reading and our new offset is still in the file's cache\n    // we can avoid flushing and needing to reread the data\n    if ((file->flags & LFS_F_READING)\n            && file->off != lfs->cfg->block_size) {\n        int oindex = lfs_ctz_index(lfs, &(lfs_off_t){file->pos});\n        lfs_off_t noff = npos;\n        int nindex = lfs_ctz_index(lfs, &noff);\n        if (oindex == nindex\n                && noff >= file->cache.off\n                && noff < file->cache.off + file->cache.size) {\n            file->pos = npos;\n            file->off = noff;\n            return npos;\n        }\n    }\n\n    // write out everything beforehand, may be noop if rdonly\n    int err = lfs_file_flush(lfs, file);\n    if (err) {\n        return err;\n    }\n\n    // update pos\n    file->pos = npos;\n    return npos;\n}\n...\nstatic inline void lfs_cache_drop(lfs_t *lfs, lfs_cache_t *rcache) {\n    // do not zero, cheaper if cache is readonly or only going to be\n    // written with identical data (during relocates)\n    (void)lfs;\n    rcache->block = LFS_BLOCK_NULL;\n}\n...\nstatic lfs_ssize_t lfs_file_flushedread(lfs_t *lfs, lfs_file_t *file,\n        void *buffer, lfs_size_t size) {\n    uint8_t *data = buffer;\n    lfs_size_t nsize = size;\n\n    if (file->pos >= file->ctz.size) {\n        // eof if past end\n        return 0;\n    }\n\n    size = lfs_min(size, file->ctz.size - file->pos);\n    nsize = size;\n\n    while (nsize > 0) {\n        // check if we need a new block\n        if (!(file->flags & LFS_F_READING) ||\n                file->off == lfs->cfg->block_size) {\n            if (!(file->flags & LFS_F_INLINE)) {\n                int err = lfs_ctz_find(lfs, NULL, &file->cache,\n                        file->ctz.head, file->ctz.size,\n                        file->pos, &file->block, &file->off);\n                if (err) {\n                    return err;\n                }\n            } else {\n                file->block = LFS_BLOCK_INLINE;\n                file->off = file->pos;\n            }\n\n            file->flags |= LFS_F_READING;\n        }\n\n        // read as much as we can in current block\n        lfs_size_t diff = lfs_min(nsize, lfs->cfg->block_size - file->off);\n        if (file->flags & LFS_F_INLINE) {\n            int err = lfs_dir_getread(lfs, &file->m,\n                    NULL, &file->cache, lfs->cfg->block_size,\n                    LFS_MKTAG(0xfff, 0x1ff, 0),\n                    LFS_MKTAG(LFS_TYPE_INLINESTRUCT, file->id, 0),\n                    file->off, data, diff);\n            if (err) {\n                return err;\n            }\n        } else {\n            int err = lfs_bd_read(lfs,\n                    NULL, &file->cache, lfs->cfg->block_size,\n                    file->block, file->off, data, diff);\n            if (err) {\n                return err;\n            }\n        }\n\n        file->pos += diff;\n        file->off += diff;\n        data += diff;\n        nsize -= diff;\n    }\n\n    return size;\n}\n...\nstatic int lfs_file_flush(lfs_t *lfs, lfs_file_t *file) {\n    if (file->flags & LFS_F_READING) {\n        if (!(file->flags & LFS_F_INLINE)) {\n            lfs_cache_drop(lfs, &file->cache);\n        }\n        file->flags &= ~LFS_F_READING;\n    }\n\n#ifndef LFS_READONLY\n    if (file->flags & LFS_F_WRITING) {\n        lfs_off_t pos = file->pos;\n\n        if (!(file->flags & LFS_F_INLINE)) {\n            // copy over anything after current branch\n            lfs_file_t orig = {\n                .ctz.head = file->ctz.head,\n                .ctz.size = file->ctz.size,\n                .flags = LFS_O_RDONLY,\n                .pos = file->pos,\n                .cache = lfs->rcache,\n            };\n            lfs_cache_drop(lfs, &lfs->rcache);\n\n            while (file->pos < file->ctz.size) {\n                // copy over a byte at a time, leave it up to caching\n                // to make this efficient\n                uint8_t data;\n                lfs_ssize_t res = lfs_file_flushedread(lfs, &orig, &data, 1);\n                if (res < 0) {\n                    return res;\n                }\n\n                res = lfs_file_flushedwrite(lfs, file, &data, 1);\n                if (res < 0) {\n                    return res;\n                }\n\n                // keep our reference to the rcache in sync\n                if (lfs->rcache.block != LFS_BLOCK_NULL) {\n                    lfs_cache_drop(lfs, &orig.cache);\n                    lfs_cache_drop(lfs, &lfs->rcache);\n                }\n            }\n\n            // write out what we have\n            while (true) {\n                int err = lfs_bd_flush(lfs, &file->cache, &lfs->rcache, true);\n                if (err) {\n                    if (err == LFS_ERR_CORRUPT) {\n                        goto relocate;\n                    }\n                    return err;\n                }\n\n                break;\n\nrelocate:\n                LFS_DEBUG(\"Bad block at 0x%\"PRIx32, file->block);\n                err = lfs_file_relocate(lfs, file);\n                if (err) {\n                    return err;\n                }\n            }\n        } else {\n            file->pos = lfs_max(file->pos, file->ctz.size);\n        }\n\n        // actual file updates\n        file->ctz.head = file->block;\n        file->ctz.size = file->pos;\n        file->flags &= ~LFS_F_WRITING;\n        file->flags |= LFS_F_DIRTY;\n\n        file->pos = pos;\n    }\n#endif\n\n    return 0;\n}\n...\nstatic int lfs_ctz_find(lfs_t *lfs,\n        const lfs_cache_t *pcache, lfs_cache_t *rcache,\n        lfs_block_t head, lfs_size_t size,\n        lfs_size_t pos, lfs_block_t *block, lfs_off_t *off) {\n    if (size == 0) {\n        *block = LFS_BLOCK_NULL;\n        *off = 0;\n        return 0;\n    }\n\n    lfs_off_t current = lfs_ctz_index(lfs, &(lfs_off_t){size-1});\n    lfs_off_t target = lfs_ctz_index(lfs, &pos);\n\n    while (current > target) {\n        lfs_size_t skip = lfs_min(\n                lfs_npw2(current-target+1) - 1,\n                lfs_ctz(current));\n\n        int err = lfs_bd_read(lfs,\n                pcache, rcache, sizeof(head),\n                head, 4*skip, &head, sizeof(head));\n        head = lfs_fromle32(head);\n        if (err) {\n            return err;\n        }\n\n        current -= 1 << skip;\n    }\n\n    *block = head;\n    *off = pos;\n    return 0;\n}\n...\nstatic lfs_ssize_t lfs_file_write_(lfs_t *lfs, lfs_file_t *file,\n        const void *buffer, lfs_size_t size) {\n    LFS_ASSERT((file->flags & LFS_O_WRONLY) == LFS_O_WRONLY);\n\n    if (file->flags & LFS_F_READING) {\n        // drop any reads\n        int err = lfs_file_flush(lfs, file);\n        if (err) {\n            return err;\n        }\n    }\n\n    if ((file->flags & LFS_O_APPEND) && file->pos < file->ctz.size) {\n        file->pos = file->ctz.size;\n    }\n\n    if (file->pos + size > lfs->file_max) {\n        // Larger than file limit?\n        return LFS_ERR_FBIG;\n    }\n\n    if (!(file->flags & LFS_F_WRITING) && file->pos > file->ctz.size) {\n        // fill with zeros\n        lfs_off_t pos = file->pos;\n        file->pos = file->ctz.size;\n\n        while (file->pos < pos) {\n            lfs_ssize_t res = lfs_file_flushedwrite(lfs, file, &(uint8_t){0}, 1);\n            if (res < 0) {\n                return res;\n            }\n        }\n    }\n\n    lfs_ssize_t nsize = lfs_file_flushedwrite(lfs, file, buffer, size);\n    if (nsize < 0) {\n        return nsize;\n    }\n\n    file->flags &= ~LFS_F_ERRED;\n    return nsize;\n}\n...\nstatic bool lfs_mlist_isopen(struct lfs_mlist *head,\n        struct lfs_mlist *node) {\n    for (struct lfs_mlist **p = &head; *p; p = &(*p)->next) {\n        if (*p == (struct lfs_mlist*)node) {\n            return true;\n        }\n    }\n\n    return false;\n}\n...\ntypedef struct lfs_file {\n    struct lfs_file *next;\n    uint16_t id;\n    uint8_t type;\n    lfs_mdir_t m;\n\n    struct lfs_ctz {\n        lfs_block_t head;\n        lfs_size_t size;\n    } ctz;\n\n    uint32_t flags;\n    lfs_off_t pos;\n    lfs_block_t block;\n    lfs_off_t off;\n    lfs_cache_t cache;\n\n    const struct lfs_file_config *cfg;\n} lfs_file_t\n...\ntypedef struct lfs {\n    lfs_cache_t rcache;\n    lfs_cache_t pcache;\n\n    lfs_block_t root[2];\n    struct lfs_mlist {\n        struct lfs_mlist *next;\n        uint16_t id;\n        uint8_t type;\n        lfs_mdir_t m;\n    } *mlist;\n    uint32_t seed;\n\n    lfs_gstate_t gstate;\n    lfs_gstate_t gdisk;\n    lfs_gstate_t gdelta;\n\n    struct lfs_lookahead {\n        lfs_block_t start;\n        lfs_block_t size;\n        lfs_block_t next;\n        lfs_block_t ckpoint;\n        uint8_t *buffer;\n    } lookahead;\n\n    const struct lfs_config *cfg;\n    lfs_size_t block_count;\n    lfs_size_t name_max;\n    lfs_size_t file_max;\n    lfs_size_t attr_max;\n    lfs_size_t inline_max;\n\n#ifdef LFS_MIGRATE\n    struct lfs1 *lfs1;\n#endif\n} lfs_t\n...\nstruct lfs_config {\n    // Opaque user provided context that can be used to pass\n    // information to the block device operations\n    void *context;\n\n    // Read a region in a block. Negative error codes are propagated\n    // to the user.\n    int (*read)(const struct lfs_config *c, lfs_block_t block,\n            lfs_off_t off, void *buffer, lfs_size_t size);\n\n    // Program a region in a block. The block must have previously\n    // been erased. Negative error codes are propagated to the user.\n    // May return LFS_ERR_CORRUPT if the block should be considered bad.\n    int (*prog)(const struct lfs_config *c, lfs_block_t block,\n            lfs_off_t off, const void *buffer, lfs_size_t size);\n\n    // Erase a block. A block must be erased before being programmed.\n    // The state of an erased block is undefined. Negative error codes\n    // are propagated to the user.\n    // May return LFS_ERR_CORRUPT if the block should be considered bad.\n    int (*erase)(const struct lfs_config *c, lfs_block_t block);\n\n    // Sync the state of the underlying block device. Negative error codes\n    // are propagated to the user.\n    int (*sync)(const struct lfs_config *c);\n\n#ifdef LFS_THREADSAFE\n    // Lock the underlying block device. Negative error codes\n    // are propagated to the user.\n    int (*lock)(const struct lfs_config *c);\n\n    // Unlock the underlying block device. Negative error codes\n    // are propagated to the user.\n    int (*unlock)(const struct lfs_config *c);\n#endif\n\n    // Minimum size of a block read in bytes. All read operations will be a\n    // multiple of this value.\n    lfs_size_t read_size;\n\n    // Minimum size of a block program in bytes. All program operations will be\n    // a multiple of this value.\n    lfs_size_t prog_size;\n\n    // Size of an erasable block in bytes. This does not impact ram consumption\n    // and may be larger than the physical erase size. However, non-inlined\n    // files take up at minimum one block. Must be a multiple of the read and\n    // program sizes.\n    lfs_size_t block_size;\n\n    // Number of erasable blocks on the device. Defaults to block_count stored\n    // on disk when zero.\n    lfs_size_t block_count;\n\n    // Number of erase cycles before littlefs evicts metadata logs and moves\n    // the metadata to another block. Suggested values are in the\n    // range 100-1000, with large values having better performance at the cost\n    // of less consistent wear distribution.\n    //\n    // Set to -1 to disable block-level wear-leveling.\n    int32_t block_cycles;\n\n    // Size of block caches in bytes. Each cache buffers a portion of a block in\n    // RAM. The littlefs needs a read cache, a program cache, and one additional\n    // cache per file. Larger caches can improve performance by storing more\n    // data and reducing the number of disk accesses. Must be a multiple of the\n    // read and program sizes, and a factor of the block size.\n    lfs_size_t cache_size;\n\n    // Size of the lookahead buffer in bytes. A larger lookahead buffer\n    // increases the number of blocks found during an allocation pass. The\n    // lookahead buffer is stored as a compact bitmap, so each byte of RAM\n    // can track 8 blocks.\n    lfs_size_t lookahead_size;\n\n    // Threshold for metadata compaction during lfs_fs_gc in bytes. Metadata\n    // pairs that exceed this threshold will be compacted during lfs_fs_gc.\n    // Defaults to ~88% block_size when zero, though the default may change\n    // in the future.\n    //\n    // Note this only affects lfs_fs_gc. Normal compactions still only occur\n    // when full.\n    //\n    // Set to -1 to disable metadata compaction during lfs_fs_gc.\n    lfs_size_t compact_thresh;\n\n    // Optional statically allocated read buffer. Must be cache_size.\n    // By default lfs_malloc is used to allocate this buffer.\n    void *read_buffer;\n\n    // Optional statically allocated program buffer. Must be cache_size.\n    // By default lfs_malloc is used to allocate this buffer.\n    void *prog_buffer;\n\n    // Optional statically allocated lookahead buffer. Must be lookahead_size.\n    // By default lfs_malloc is used to allocate this buffer.\n    void *lookahead_buffer;\n\n    // Optional upper limit on length of file names in bytes. No downside for\n    // larger names except the size of the info struct which is controlled by\n    // the LFS_NAME_MAX define. Defaults to LFS_NAME_MAX or name_max stored on\n    // disk when zero.\n    lfs_size_t name_max;\n\n    // Optional upper limit on files in bytes. No downside for larger files\n    // but must be <= LFS_FILE_MAX. Defaults to LFS_FILE_MAX or file_max stored\n    // on disk when zero.\n    lfs_size_t file_max;\n\n    // Optional upper limit on custom attributes in bytes. No downside for\n    // larger attributes size but must be <= LFS_ATTR_MAX. Defaults to\n    // LFS_ATTR_MAX or attr_max stored on disk when zero.\n    lfs_size_t attr_max;\n\n    // Optional upper limit on total space given to metadata pairs in bytes. On\n    // devices with large blocks (e.g. 128kB) setting this to a low size (2-8kB)\n    // can help bound the metadata compaction time. Must be <= block_size.\n    // Defaults to block_size when zero.\n    lfs_size_t metadata_max;\n\n    // Optional upper limit on inlined files in bytes. Inlined files live in\n    // metadata and decrease storage requirements, but may be limited to\n    // improve metadata-related performance. Must be <= cache_size, <=\n    // attr_max, and <= block_size/8. Defaults to the largest possible\n    // inline_max when zero.\n    //\n    // Set to -1 to disable inlined files.\n    lfs_size_t inline_max;\n\n#ifdef LFS_MULTIVERSION\n    // On-disk version to use when writing in the form of 16-bit major version\n    // + 16-bit minor version. This limiting metadata to what is supported by\n    // older minor versions. Note that some features will be lost. Defaults to \n    // to the most recent minor version when zero.\n    uint32_t disk_version;\n#endif\n}\n...\ntypedef uint32_t lfs_off_t\n</additional code>\n<target_code>\nHere is the code fragment that you need to analyze:\n```c\n            // read our data into rcache temporarily\n            lfs_cache_drop(lfs, &lfs->rcache);\n            res = lfs_file_flushedread(lfs, file,\n                    lfs->rcache.buffer, size);\n            if (res < 0) {\n                return (int)res;\n            }\n\n            file->ctz.head = LFS_BLOCK_INLINE;\n            file->ctz.size = size;\n            file->flags |= LFS_F_DIRTY | LFS_F_READING | LFS_F_INLINE;\n            file->cache.block = file->ctz.head;\n            file->cache.off = 0;\n            file->cache.size = lfs->cfg->cache_size;\n            memcpy(file->cache.buffer, lfs->rcache.buffer, size);\n```\nFocus on the above code fragment and judge whether it violates the rule 21.17 or not.\n</target_code>\n",
  "is_rule_violated": false,
  "scenario": "Under the documented configuration constraints (lfs->cfg->inline_max <= lfs->cfg->cache_size and both rcache.buffer and file->cache.buffer are allocated at least cache_size bytes), there is no out-of-bounds access: size is tested to be <= inline_max before copying, and lfs_file_flushedread writes at most size bytes into lfs->rcache.buffer. A violation could occur if the configuration/allocations are inconsistent \u2014 e.g. inline_max > cache_size or either cache.buffer (rcache.buffer or file->cache.buffer) is smaller than cache_size, allowing memcpy(..., size) to copy more bytes than the destination or source buffer actually holds."
}