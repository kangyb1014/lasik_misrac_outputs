{
  "user_message": "<misra_rule>\nMISRA C 2023 Rule 2.2 is: A project shall not contain dead code.\nAny operation that is executed but whose removal would not affect program behaviour constitutes dead code. Notes:\n1. The behaviour of an embedded sytem is often determined not just by the nature of its actions, but also by the time at which they occur.\n2. unreachable code is not dead code, as it cannot be executed.\n3.Initialization is not the same as an assignment operation and is therfore not a candidate for dead code.\n</misra_rule>\n<response format>\nProvide your answer with these fields.\n- is_rule_violated: whether the rule is violated or not (true/false),\n- scenario: a specific violation scenario.\n</response format>\n<target_code>\nHere is the code of metal_linux_irq_set_enable:\n```c\nstatic void metal_linux_irq_set_enable(struct metal_irq_controller *irq_cntr,\n\t\t\t\t       int irq, unsigned int state)\n{\n\tint offset, ret;\n\n\tif (irq < irq_cntr->irq_base ||\n\t    irq >= irq_cntr->irq_base + irq_cntr->irq_num) {\n\t\tmetal_log(METAL_LOG_ERROR, \"%s: invalid irq %d\\n\",\n\t\t\t  __func__, irq);\n\t\treturn;\n\t}\n\toffset = irq - linux_irq_cntr.irq_base;\n\tmetal_mutex_acquire(&irq_lock);\n\tif (state == METAL_IRQ_ENABLE)\n\t\tmetal_bitmap_set_bit(irqs_enabled, offset);\n\telse\n\t\tmetal_bitmap_clear_bit(irqs_enabled, offset);\n\tmetal_mutex_release(&irq_lock);\n\t/* Notify IRQ thread that IRQ state has changed */\n\tret = metal_linux_irq_notify();\n\tif (ret < 0) {\n\t\tmetal_log(METAL_LOG_ERROR,\n\t\t\t  \"%s: failed to notify set %d enable\\n\",\n\t\t\t  __func__, irq);\n\t}\n}\n```\n</target_code>\n<additional code>Here are the definitions of symbols that are close to the target function metal_linux_irq_set_enable:\nstatic METAL_IRQ_CONTROLLER_DECLARE(linux_irq_cntr,\n\t\t\t\t    0, MAX_IRQS,\n\t\t\t\t    NULL,\n\t\t\t\t    metal_linux_irq_set_enable, NULL,\n\t\t\t\t    irqs)\n...\nstatic unsigned long\nirqs_enabled[metal_div_round_up(MAX_IRQS, METAL_BITS_PER_ULONG)]\n...\nstatic metal_mutex_t irq_lock\n...\n#define METAL_IRQ_ENABLE 1U\n...\nstatic int metal_linux_irq_notify(void)\n{\n\tuint64_t val = 1;\n\tint ret;\n\n\tret = write(irq_notify_fd, &val, sizeof(val));\n\tif (ret < 0) {\n\t\tmetal_log(METAL_LOG_ERROR, \"%s failed\\n\", __func__);\n\t}\n\treturn ret;\n}\n...\n#define metal_log(level, fmt, __VA_ARGS__) ({if(_metal.common.log_handler&&level<=_metal.common.log_level)_metal.common.log_handler(level,metal_fmt(fmt),##__VA_ARGS__);\\\n})\n...\nstatic void *metal_linux_irq_handling(void *args)\n{\n\tstruct sched_param param;\n\tuint64_t val;\n\tint ret;\n\tint i, j, pfds_total;\n\tstruct pollfd *pfds;\n\n\t(void)args;\n\n\tpfds = (struct pollfd *)malloc(FD_SETSIZE * sizeof(struct pollfd));\n\tif (!pfds) {\n\t\tmetal_log(METAL_LOG_ERROR,\n\t\t\t  \"%s: failed to allocate irq fds mem.\\n\", __func__);\n\t\treturn NULL;\n\t}\n\n\tparam.sched_priority = sched_get_priority_max(SCHED_FIFO);\n\t/* Ignore the set scheduler error */\n\tret = sched_setscheduler(0, SCHED_FIFO, &param);\n\tif (ret) {\n\t\tmetal_log(METAL_LOG_WARNING,\n\t\t\t  \"%s: Failed to set scheduler: %s.\\n\", __func__,\n\t\t\t  strerror(ret));\n\t}\n\n\twhile (1) {\n\t\tmetal_mutex_acquire(&irq_lock);\n\t\tif (irq_handling_stop) {\n\t\t\t/* Killing this IRQ handling thread */\n\t\t\tmetal_mutex_release(&irq_lock);\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Get the fdset */\n\t\tmemset(pfds, 0, MAX_IRQS * sizeof(struct pollfd));\n\t\tpfds[0].fd = irq_notify_fd;\n\t\tpfds[0].events = POLLIN;\n\t\tj = 1;\n\t\tmetal_bitmap_for_each_set_bit(irqs_enabled, i,\n\t\t\t\t\t      linux_irq_cntr.irq_num) {\n\t\t\tpfds[j].fd = i;\n\t\t\tpfds[j].events = POLLIN;\n\t\t\tj++;\n\t\t}\n\t\tmetal_mutex_release(&irq_lock);\n\t\t/* Wait for interrupt */\n\t\tret = poll(pfds, j, -1);\n\t\tif (ret < 0) {\n\t\t\tmetal_log(METAL_LOG_ERROR, \"%s: poll() failed: %s.\\n\",\n\t\t\t\t  __func__, strerror(errno));\n\t\t\tbreak;\n\t\t}\n\t\t/* Waken up from interrupt */\n\t\tpfds_total = j;\n\t\tfor (i = 0; i < pfds_total; i++) {\n\t\t\tif ((pfds[i].fd == irq_notify_fd) &&\n\t\t\t    (pfds[i].revents & (POLLIN | POLLRDNORM))) {\n\t\t\t\t/* IRQ registration change notification */\n\t\t\t\tif (read(pfds[i].fd,\n\t\t\t\t\t (void *)&val, sizeof(uint64_t)) < 0)\n\t\t\t\t\tmetal_log(METAL_LOG_ERROR,\n\t\t\t\t\t\t  \"%s, read irq fd %d failed\\n\",\n\t\t\t\t\t\t  __func__, pfds[i].fd);\n\t\t\t} else if ((pfds[i].revents & (POLLIN | POLLRDNORM))) {\n\t\t\t\tstruct metal_device *dev = NULL;\n\t\t\t\tint irq_handled = 0;\n\t\t\t\tint fd;\n\n\t\t\t\tfd = pfds[i].fd;\n\t\t\t\tdev = irqs_devs[fd];\n\t\t\t\tmetal_mutex_acquire(&irq_lock);\n\t\t\t\tif (metal_irq_handle(&irqs[fd], fd)\n\t\t\t\t    == METAL_IRQ_HANDLED)\n\t\t\t\t\tirq_handled = 1;\n\t\t\t\tif (irq_handled) {\n\t\t\t\t\tif (dev && dev->bus->ops.dev_irq_ack)\n\t\t\t\t\t\tdev->bus->ops.dev_irq_ack(\n\t\t\t\t\t\t\tdev->bus, dev, fd);\n\t\t\t\t}\n\t\t\t\tmetal_mutex_release(&irq_lock);\n\t\t\t} else if (pfds[i].revents) {\n\t\t\t\tmetal_log(METAL_LOG_DEBUG,\n\t\t\t\t\t  \"%s: poll unexpected. fd %d: %d\\n\",\n\t\t\t\t\t  __func__,\n\t\t\t\t\t  pfds[i].fd, pfds[i].revents);\n\t\t\t}\n\t\t}\n\t}\n\tfree(pfds);\n\treturn NULL;\n}\n</additional code>\n<target_code>\nHere is the code fragment that you need to analyze:\n```c\nmetal_bitmap_clear_bit(irqs_enabled, offset);\n```\nFocus on the above code fragment and judge whether it violates the rule 2.2 or not.\n</target_code>\n",
  "is_rule_violated": false,
  "scenario": "Not violated. The call metal_bitmap_clear_bit(irqs_enabled, offset) updates the bitmap used by the IRQ handling thread (metal_bitmap_for_each_set_bit(irqs_enabled, ...)) to decide which IRQ file descriptors are polled and handled. Removing this call would leave a disabled IRQ marked enabled, changing runtime behaviour (the IRQ would continue to be polled/handled). The notify call (metal_linux_irq_notify) and the mutex-protected access confirm this operation is effective and not dead code."
}