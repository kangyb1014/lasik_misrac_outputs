{
  "user_message": "<misra_rule>\nThe target MISRA C 2023 Rule 17.2 is: Functions shall not call themselves, either directly or indirectly.\n\n</misra_rule>\n<instruction>\nOther agents will judge whether the code follows the MISRA C 2023 guidelines.\nThey will investigate the code fragments you give.\nYour job is to find code fragments in the code that should be investigated to check whether the code follows the MISRA C rule.\n</instruction>\n<response format>\nProvide your answer with these fields.\n- suspicious_frags: The list of suspicious code fragments in the code.\nIt should contain only the code fragments exists in the code. If you do not find any suspicious code fragments, return an empty list for suspicious_frags\n- explanation: The explanation of why other code fragments should NOT be investigated.\nIt is very important to not miss any suspicious code fragments, so please give a sufficient explanation why other code fragments should not be investigated.\nDO NOT give any explanation for the selected suspicious code fragments.\n</response format>\n<target_code>\nHere is the code of metal_linux_irq_init:\n```c\nint metal_linux_irq_init(void)\n{\n\tint ret;\n\n\tmemset(&irqs, 0, sizeof(irqs));\n\n\tirq_notify_fd = eventfd(0, EFD_CLOEXEC);\n\tif (irq_notify_fd < 0) {\n\t\tmetal_log(METAL_LOG_ERROR,\n\t\t\t  \"Failed to create eventfd for IRQ handling.\\n\");\n\t\treturn  -EAGAIN;\n\t}\n\n\tmetal_mutex_init(&irq_lock);\n\tirq_handling_stop = false;\n\tret = metal_irq_register_controller(&linux_irq_cntr);\n\tif (ret < 0) {\n\t\tmetal_log(METAL_LOG_ERROR,\n\t\t\t  \"Linux IRQ controller failed to register.\\n\");\n\t\treturn -EINVAL;\n\t}\n\tret = pthread_create(&irq_pthread, NULL,\n\t\t\t     metal_linux_irq_handling, NULL);\n\tif (ret != 0) {\n\t\tmetal_log(METAL_LOG_ERROR, \"Failed to create IRQ thread: %d.\\n\",\n\t\t\t  ret);\n\t\treturn -EAGAIN;\n\t}\n\n\treturn 0;\n}\n```\n</target_code>\n<additional code>Here are the definitions of symbols that are related to the target function metal_linux_irq_init:\nint metal_irq_register_controller(struct metal_irq_controller *cntr)\n{\n\tint irq_base;\n\tstruct metal_list *node;\n\n\tif (cntr == NULL) {\n\t\treturn -EINVAL;\n\t}\n\tmetal_list_for_each(&irq_cntrs, node) {\n\t\tif (node == &cntr->node) {\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\t/*\n\t * Allocate IRQ numbers which are not yet used by any IRQ\n\t * controllers.\n\t */\n\tirq_base = metal_irq_allocate(cntr->irq_base, cntr->irq_num);\n\tif (irq_base == METAL_IRQ_ANY) {\n\t\treturn -EINVAL;\n\t}\n\tcntr->irq_base = irq_base;\n\n\tmetal_list_add_tail(&irq_cntrs, &cntr->node);\n\treturn 0;\n}\n...\nstatic int metal_irq_allocate(int irq_base, int irq_num)\n{\n\tstruct metal_list *node;\n\tstruct metal_irq_controller *cntr;\n\tint irq_tocheck = irq_base, irq_end_tocheck;\n\n\tif (irq_num == 0) {\n\t\treturn METAL_IRQ_ANY;\n\t}\n\tif (irq_tocheck == METAL_IRQ_ANY) {\n\t\tirq_tocheck = 0;\n\t}\n\tirq_end_tocheck = irq_tocheck + irq_num;\n\n\tmetal_list_for_each(&irq_cntrs, node) {\n\t\tint cntr_irq_base, cntr_irq_end;\n\n\t\tcntr = metal_container_of(node,\n\t\t\t\t\t  struct metal_irq_controller, node);\n\t\tcntr_irq_base = cntr->irq_base;\n\t\tcntr_irq_end = cntr_irq_base + cntr->irq_num;\n\t\tif (irq_tocheck < cntr_irq_end &&\n\t\t    irq_end_tocheck > cntr_irq_base) {\n\t\t\tif (irq_base != METAL_IRQ_ANY) {\n\t\t\t\t/* IRQ has been allocated */\n\t\t\t\treturn METAL_IRQ_ANY;\n\t\t\t}\n\t\t\tirq_tocheck = cntr_irq_end;\n\t\t\tirq_end_tocheck = irq_tocheck + irq_num;\n\t\t}\n\t}\n\treturn irq_tocheck;\n}\n...\nstatic void *metal_linux_irq_handling(void *args)\n{\n\tstruct sched_param param;\n\tuint64_t val;\n\tint ret;\n\tint i, j, pfds_total;\n\tstruct pollfd *pfds;\n\n\t(void)args;\n\n\tpfds = (struct pollfd *)malloc(FD_SETSIZE * sizeof(struct pollfd));\n\tif (!pfds) {\n\t\tmetal_log(METAL_LOG_ERROR,\n\t\t\t  \"%s: failed to allocate irq fds mem.\\n\", __func__);\n\t\treturn NULL;\n\t}\n\n\tparam.sched_priority = sched_get_priority_max(SCHED_FIFO);\n\t/* Ignore the set scheduler error */\n\tret = sched_setscheduler(0, SCHED_FIFO, &param);\n\tif (ret) {\n\t\tmetal_log(METAL_LOG_WARNING,\n\t\t\t  \"%s: Failed to set scheduler: %s.\\n\", __func__,\n\t\t\t  strerror(ret));\n\t}\n\n\twhile (1) {\n\t\tmetal_mutex_acquire(&irq_lock);\n\t\tif (irq_handling_stop) {\n\t\t\t/* Killing this IRQ handling thread */\n\t\t\tmetal_mutex_release(&irq_lock);\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Get the fdset */\n\t\tmemset(pfds, 0, MAX_IRQS * sizeof(struct pollfd));\n\t\tpfds[0].fd = irq_notify_fd;\n\t\tpfds[0].events = POLLIN;\n\t\tj = 1;\n\t\tmetal_bitmap_for_each_set_bit(irqs_enabled, i,\n\t\t\t\t\t      linux_irq_cntr.irq_num) {\n\t\t\tpfds[j].fd = i;\n\t\t\tpfds[j].events = POLLIN;\n\t\t\tj++;\n\t\t}\n\t\tmetal_mutex_release(&irq_lock);\n\t\t/* Wait for interrupt */\n\t\tret = poll(pfds, j, -1);\n\t\tif (ret < 0) {\n\t\t\tmetal_log(METAL_LOG_ERROR, \"%s: poll() failed: %s.\\n\",\n\t\t\t\t  __func__, strerror(errno));\n\t\t\tbreak;\n\t\t}\n\t\t/* Waken up from interrupt */\n\t\tpfds_total = j;\n\t\tfor (i = 0; i < pfds_total; i++) {\n\t\t\tif ((pfds[i].fd == irq_notify_fd) &&\n\t\t\t    (pfds[i].revents & (POLLIN | POLLRDNORM))) {\n\t\t\t\t/* IRQ registration change notification */\n\t\t\t\tif (read(pfds[i].fd,\n\t\t\t\t\t (void *)&val, sizeof(uint64_t)) < 0)\n\t\t\t\t\tmetal_log(METAL_LOG_ERROR,\n\t\t\t\t\t\t  \"%s, read irq fd %d failed\\n\",\n\t\t\t\t\t\t  __func__, pfds[i].fd);\n\t\t\t} else if ((pfds[i].revents & (POLLIN | POLLRDNORM))) {\n\t\t\t\tstruct metal_device *dev = NULL;\n\t\t\t\tint irq_handled = 0;\n\t\t\t\tint fd;\n\n\t\t\t\tfd = pfds[i].fd;\n\t\t\t\tdev = irqs_devs[fd];\n\t\t\t\tmetal_mutex_acquire(&irq_lock);\n\t\t\t\tif (metal_irq_handle(&irqs[fd], fd)\n\t\t\t\t    == METAL_IRQ_HANDLED)\n\t\t\t\t\tirq_handled = 1;\n\t\t\t\tif (irq_handled) {\n\t\t\t\t\tif (dev && dev->bus->ops.dev_irq_ack)\n\t\t\t\t\t\tdev->bus->ops.dev_irq_ack(\n\t\t\t\t\t\t\tdev->bus, dev, fd);\n\t\t\t\t}\n\t\t\t\tmetal_mutex_release(&irq_lock);\n\t\t\t} else if (pfds[i].revents) {\n\t\t\t\tmetal_log(METAL_LOG_DEBUG,\n\t\t\t\t\t  \"%s: poll unexpected. fd %d: %d\\n\",\n\t\t\t\t\t  __func__,\n\t\t\t\t\t  pfds[i].fd, pfds[i].revents);\n\t\t\t}\n\t\t}\n\t}\n\tfree(pfds);\n\treturn NULL;\n}\n...\nint metal_sys_init(const struct metal_init_params *params)\n{\n\tconst char *tmp_path;\n\tunsigned int seed;\n\tFILE *urandom;\n\tint result;\n\n\t/* Find the temporary directory location. */\n\ttmp_path = getenv(\"TMPDIR\");\n\tif (!tmp_path)\n\t\ttmp_path = \"/tmp\";\n\t_metal.tmp_path = tmp_path;\n\n\t/* Initialize the pseudo-random number generator. */\n\turandom = fopen(\"/dev/urandom\", \"r\");\n\tif (!urandom) {\n\t\tmetal_log(METAL_LOG_ERROR, \"failed to open /dev/urandom (%s)\\n\",\n\t\t\t  strerror(errno));\n\t\treturn -errno;\n\t}\n\tif (fread(&seed, 1, sizeof(seed), urandom) <= 0) {\n\t\tmetal_log(METAL_LOG_DEBUG, \"Failed fread /dev/urandom\\n\");\n\t}\n\tfclose(urandom);\n\tsrand(seed);\n\n\tresult = metal_init_page_sizes();\n\tif (result < 0)\n\t\treturn result;\n\n\tresult = metal_linux_bus_init();\n\tif (result < 0)\n\t\treturn result;\n\n\tresult = open(\"/proc/self/pagemap\", O_RDONLY | O_CLOEXEC);\n\tif (result < 0) {\n\t\tmetal_log(METAL_LOG_DEBUG, \"Failed pagemap open - %s\\n\",\n\t\t\t  strerror(errno));\n\t}\n\t_metal.pagemap_fd = result;\n\n\tmetal_unused(params);\n\n\t/* Initialize IRQ handling */\n\tmetal_linux_irq_init();\n\treturn 0;\n}\n...\nint metal_init(const struct metal_init_params *params)\n{\n\tint error = 0;\n\n\tif (_metal.common.ref_count++ != 0)\n\t\treturn 0;\n\n\tmemset(&_metal, 0, sizeof(_metal));\n\n\t_metal.common.log_handler   = params->log_handler;\n\t_metal.common.log_level     = params->log_level;\n\n\tmetal_list_init(&_metal.common.bus_list);\n\tmetal_list_init(&_metal.common.generic_shmem_list);\n\tmetal_list_init(&_metal.common.generic_device_list);\n\n\terror = metal_sys_init(params);\n\tif (error)\n\t\treturn error;\n\n\t++_metal.common.ref_count;\n\treturn error;\n}\n</additional code>\nPlease find suspicious code fragments in the code and report them. Other agents can not investigate other fragments that you do not report, so it is very important to find all suspicious fragments without missing any. Report the suspicious fragments AS MUCH AS POSSIBLE.",
  "suspicious_frags": [
    "metal_list_add_tail(&irq_cntrs, &cntr->node);",
    "if (metal_irq_handle(&irqs[fd], fd)\n\t\t\t    == METAL_IRQ_HANDLED)",
    "irq_base = metal_irq_allocate(cntr->irq_base, cntr->irq_num);",
    "ret = metal_irq_register_controller(&linux_irq_cntr);",
    "result = metal_linux_irq_init();",
    "metal_list_for_each(&irq_cntrs, node) {",
    "ret = pthread_create(&irq_pthread, NULL,\n\t\t\t     metal_linux_irq_handling, NULL);",
    "if (dev && dev->bus->ops.dev_irq_ack)\n\t\t\t\tdev->bus->ops.dev_irq_ack(\n\t\t\t\t\tdev->bus, dev, fd);"
  ],
  "explanation": "Fragments NOT listed were excluded because they do not introduce direct or indirect function-call paths that could create recursion: simple library calls (memset, malloc, fopen, fread, fclose, srand, open, eventfd, read, poll, sched_setscheduler), logging calls (metal_log), basic mutex operations (metal_mutex_init/metal_mutex_acquire/metal_mutex_release), bitmap/list iteration macros used only for traversal, and allocations/free are not recursive by themselves. The listed fragments are the call sites and callback invocation points that can initiate indirect control flows (registration, allocation, thread start, IRQ handling callback and device-provided dev_irq_ack). Those should be investigated to determine whether any of those targets (or their implementations) call back \u2014 directly or indirectly \u2014 into the calling functions, which would violate MISRA C:2012 Rule 17.2 (no direct or indirect recursion)."
}