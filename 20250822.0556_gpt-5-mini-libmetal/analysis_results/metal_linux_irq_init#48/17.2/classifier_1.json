{
  "user_message": "<misra_rule>\nMISRA C 2023 Rule 17.2 is: Functions shall not call themselves, either directly or indirectly.\n\n</misra_rule>\n<response format>\nProvide your answer with these fields.\n- is_rule_violated: whether the rule is violated or not (true/false),\n- scenario: a specific violation scenario.\n</response format>\n<target_code>\nHere is the code of metal_linux_irq_init:\n```c\nint metal_linux_irq_init(void)\n{\n\tint ret;\n\n\tmemset(&irqs, 0, sizeof(irqs));\n\n\tirq_notify_fd = eventfd(0, EFD_CLOEXEC);\n\tif (irq_notify_fd < 0) {\n\t\tmetal_log(METAL_LOG_ERROR,\n\t\t\t  \"Failed to create eventfd for IRQ handling.\\n\");\n\t\treturn  -EAGAIN;\n\t}\n\n\tmetal_mutex_init(&irq_lock);\n\tirq_handling_stop = false;\n\tret = metal_irq_register_controller(&linux_irq_cntr);\n\tif (ret < 0) {\n\t\tmetal_log(METAL_LOG_ERROR,\n\t\t\t  \"Linux IRQ controller failed to register.\\n\");\n\t\treturn -EINVAL;\n\t}\n\tret = pthread_create(&irq_pthread, NULL,\n\t\t\t     metal_linux_irq_handling, NULL);\n\tif (ret != 0) {\n\t\tmetal_log(METAL_LOG_ERROR, \"Failed to create IRQ thread: %d.\\n\",\n\t\t\t  ret);\n\t\treturn -EAGAIN;\n\t}\n\n\treturn 0;\n}\n```\n</target_code>\n<additional code>Here are the definitions of symbols that are close to the target function metal_linux_irq_init:\nint metal_irq_register_controller(struct metal_irq_controller *cntr)\n{\n\tint irq_base;\n\tstruct metal_list *node;\n\n\tif (cntr == NULL) {\n\t\treturn -EINVAL;\n\t}\n\tmetal_list_for_each(&irq_cntrs, node) {\n\t\tif (node == &cntr->node) {\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\t/*\n\t * Allocate IRQ numbers which are not yet used by any IRQ\n\t * controllers.\n\t */\n\tirq_base = metal_irq_allocate(cntr->irq_base, cntr->irq_num);\n\tif (irq_base == METAL_IRQ_ANY) {\n\t\treturn -EINVAL;\n\t}\n\tcntr->irq_base = irq_base;\n\n\tmetal_list_add_tail(&irq_cntrs, &cntr->node);\n\treturn 0;\n}\n...\nstatic int metal_irq_allocate(int irq_base, int irq_num)\n{\n\tstruct metal_list *node;\n\tstruct metal_irq_controller *cntr;\n\tint irq_tocheck = irq_base, irq_end_tocheck;\n\n\tif (irq_num == 0) {\n\t\treturn METAL_IRQ_ANY;\n\t}\n\tif (irq_tocheck == METAL_IRQ_ANY) {\n\t\tirq_tocheck = 0;\n\t}\n\tirq_end_tocheck = irq_tocheck + irq_num;\n\n\tmetal_list_for_each(&irq_cntrs, node) {\n\t\tint cntr_irq_base, cntr_irq_end;\n\n\t\tcntr = metal_container_of(node,\n\t\t\t\t\t  struct metal_irq_controller, node);\n\t\tcntr_irq_base = cntr->irq_base;\n\t\tcntr_irq_end = cntr_irq_base + cntr->irq_num;\n\t\tif (irq_tocheck < cntr_irq_end &&\n\t\t    irq_end_tocheck > cntr_irq_base) {\n\t\t\tif (irq_base != METAL_IRQ_ANY) {\n\t\t\t\t/* IRQ has been allocated */\n\t\t\t\treturn METAL_IRQ_ANY;\n\t\t\t}\n\t\t\tirq_tocheck = cntr_irq_end;\n\t\t\tirq_end_tocheck = irq_tocheck + irq_num;\n\t\t}\n\t}\n\treturn irq_tocheck;\n}\n...\nstatic void *metal_linux_irq_handling(void *args)\n{\n\tstruct sched_param param;\n\tuint64_t val;\n\tint ret;\n\tint i, j, pfds_total;\n\tstruct pollfd *pfds;\n\n\t(void)args;\n\n\tpfds = (struct pollfd *)malloc(FD_SETSIZE * sizeof(struct pollfd));\n\tif (!pfds) {\n\t\tmetal_log(METAL_LOG_ERROR,\n\t\t\t  \"%s: failed to allocate irq fds mem.\\n\", __func__);\n\t\treturn NULL;\n\t}\n\n\tparam.sched_priority = sched_get_priority_max(SCHED_FIFO);\n\t/* Ignore the set scheduler error */\n\tret = sched_setscheduler(0, SCHED_FIFO, &param);\n\tif (ret) {\n\t\tmetal_log(METAL_LOG_WARNING,\n\t\t\t  \"%s: Failed to set scheduler: %s.\\n\", __func__,\n\t\t\t  strerror(ret));\n\t}\n\n\twhile (1) {\n\t\tmetal_mutex_acquire(&irq_lock);\n\t\tif (irq_handling_stop) {\n\t\t\t/* Killing this IRQ handling thread */\n\t\t\tmetal_mutex_release(&irq_lock);\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Get the fdset */\n\t\tmemset(pfds, 0, MAX_IRQS * sizeof(struct pollfd));\n\t\tpfds[0].fd = irq_notify_fd;\n\t\tpfds[0].events = POLLIN;\n\t\tj = 1;\n\t\tmetal_bitmap_for_each_set_bit(irqs_enabled, i,\n\t\t\t\t\t      linux_irq_cntr.irq_num) {\n\t\t\tpfds[j].fd = i;\n\t\t\tpfds[j].events = POLLIN;\n\t\t\tj++;\n\t\t}\n\t\tmetal_mutex_release(&irq_lock);\n\t\t/* Wait for interrupt */\n\t\tret = poll(pfds, j, -1);\n\t\tif (ret < 0) {\n\t\t\tmetal_log(METAL_LOG_ERROR, \"%s: poll() failed: %s.\\n\",\n\t\t\t\t  __func__, strerror(errno));\n\t\t\tbreak;\n\t\t}\n\t\t/* Waken up from interrupt */\n\t\tpfds_total = j;\n\t\tfor (i = 0; i < pfds_total; i++) {\n\t\t\tif ((pfds[i].fd == irq_notify_fd) &&\n\t\t\t    (pfds[i].revents & (POLLIN | POLLRDNORM))) {\n\t\t\t\t/* IRQ registration change notification */\n\t\t\t\tif (read(pfds[i].fd,\n\t\t\t\t\t (void *)&val, sizeof(uint64_t)) < 0)\n\t\t\t\t\tmetal_log(METAL_LOG_ERROR,\n\t\t\t\t\t\t  \"%s, read irq fd %d failed\\n\",\n\t\t\t\t\t\t  __func__, pfds[i].fd);\n\t\t\t} else if ((pfds[i].revents & (POLLIN | POLLRDNORM))) {\n\t\t\t\tstruct metal_device *dev = NULL;\n\t\t\t\tint irq_handled = 0;\n\t\t\t\tint fd;\n\n\t\t\t\tfd = pfds[i].fd;\n\t\t\t\tdev = irqs_devs[fd];\n\t\t\t\tmetal_mutex_acquire(&irq_lock);\n\t\t\t\tif (metal_irq_handle(&irqs[fd], fd)\n\t\t\t\t    == METAL_IRQ_HANDLED)\n\t\t\t\t\tirq_handled = 1;\n\t\t\t\tif (irq_handled) {\n\t\t\t\t\tif (dev && dev->bus->ops.dev_irq_ack)\n\t\t\t\t\t\tdev->bus->ops.dev_irq_ack(\n\t\t\t\t\t\t\tdev->bus, dev, fd);\n\t\t\t\t}\n\t\t\t\tmetal_mutex_release(&irq_lock);\n\t\t\t} else if (pfds[i].revents) {\n\t\t\t\tmetal_log(METAL_LOG_DEBUG,\n\t\t\t\t\t  \"%s: poll unexpected. fd %d: %d\\n\",\n\t\t\t\t\t  __func__,\n\t\t\t\t\t  pfds[i].fd, pfds[i].revents);\n\t\t\t}\n\t\t}\n\t}\n\tfree(pfds);\n\treturn NULL;\n}\n...\nint metal_sys_init(const struct metal_init_params *params)\n{\n\tconst char *tmp_path;\n\tunsigned int seed;\n\tFILE *urandom;\n\tint result;\n\n\t/* Find the temporary directory location. */\n\ttmp_path = getenv(\"TMPDIR\");\n\tif (!tmp_path)\n\t\ttmp_path = \"/tmp\";\n\t_metal.tmp_path = tmp_path;\n\n\t/* Initialize the pseudo-random number generator. */\n\turandom = fopen(\"/dev/urandom\", \"r\");\n\tif (!urandom) {\n\t\tmetal_log(METAL_LOG_ERROR, \"failed to open /dev/urandom (%s)\\n\",\n\t\t\t  strerror(errno));\n\t\treturn -errno;\n\t}\n\tif (fread(&seed, 1, sizeof(seed), urandom) <= 0) {\n\t\tmetal_log(METAL_LOG_DEBUG, \"Failed fread /dev/urandom\\n\");\n\t}\n\tfclose(urandom);\n\tsrand(seed);\n\n\tresult = metal_init_page_sizes();\n\tif (result < 0)\n\t\treturn result;\n\n\tresult = metal_linux_bus_init();\n\tif (result < 0)\n\t\treturn result;\n\n\tresult = open(\"/proc/self/pagemap\", O_RDONLY | O_CLOEXEC);\n\tif (result < 0) {\n\t\tmetal_log(METAL_LOG_DEBUG, \"Failed pagemap open - %s\\n\",\n\t\t\t  strerror(errno));\n\t}\n\t_metal.pagemap_fd = result;\n\n\tmetal_unused(params);\n\n\t/* Initialize IRQ handling */\n\tmetal_linux_irq_init();\n\treturn 0;\n}\n...\nint metal_init(const struct metal_init_params *params)\n{\n\tint error = 0;\n\n\tif (_metal.common.ref_count++ != 0)\n\t\treturn 0;\n\n\tmemset(&_metal, 0, sizeof(_metal));\n\n\t_metal.common.log_handler   = params->log_handler;\n\t_metal.common.log_level     = params->log_level;\n\n\tmetal_list_init(&_metal.common.bus_list);\n\tmetal_list_init(&_metal.common.generic_shmem_list);\n\tmetal_list_init(&_metal.common.generic_device_list);\n\n\terror = metal_sys_init(params);\n\tif (error)\n\t\treturn error;\n\n\t++_metal.common.ref_count;\n\treturn error;\n}\n</additional code>\n<target_code>\nHere is the code fragment that you need to analyze:\n```c\nif (metal_irq_handle(&irqs[fd], fd)\n\t\t\t    == METAL_IRQ_HANDLED)\n```\nFocus on the above code fragment and judge whether it violates the rule 17.2 or not.\n</target_code>\n",
  "is_rule_violated": false,
  "scenario": "No violation in the provided code. The fragment calls metal_irq_handle(&irqs[fd], fd) from metal_linux_irq_handling, and there is no definition in the supplied code showing metal_irq_handle calling metal_linux_irq_handling or itself. Thus there is no direct or indirect recursive call shown. (A violation would occur if metal_irq_handle were implemented to call metal_linux_irq_handling or otherwise call back into metal_irq_handle through a chain of calls, producing recursion.)"
}