{
  "user_message": "<misra_rule>\nMISRA C 2023 Rule 17.2 is: Functions shall not call themselves, either directly or indirectly.\n\n</misra_rule>\n<response format>\nProvide your answer with these fields.\n- is_rule_violated: whether the rule is violated or not (true/false),\n- scenario: a specific violation scenario.\n</response format>\n<target_code>\nHere is the code of MHD_get_timeout64:\n```c\n_MHD_EXTERN enum MHD_Result\nMHD_get_timeout64 (struct MHD_Daemon *daemon,\n                   uint64_t *timeout64)\n{\n  uint64_t earliest_deadline;\n  struct MHD_Connection *pos;\n  struct MHD_Connection *earliest_tmot_conn; /**< the connection with earliest timeout */\n\n#ifdef MHD_USE_THREADS\n  mhd_assert ( (! MHD_D_IS_USING_THREADS_ (daemon)) || \\\n               MHD_thread_handle_ID_is_current_thread_ (daemon->tid) );\n#endif /* MHD_USE_THREADS */\n\n  if (MHD_D_IS_USING_THREAD_PER_CONN_ (daemon))\n  {\n#ifdef HAVE_MESSAGES\n    MHD_DLOG (daemon,\n              _ (\"Illegal call to MHD_get_timeout.\\n\"));\n#endif\n    return MHD_NO;\n  }\n  if (daemon->data_already_pending\n      || (NULL != daemon->cleanup_head)\n      || daemon->resuming\n      || daemon->have_new\n      || daemon->shutdown)\n  {\n    /* Some data or connection statuses already waiting to be processed. */\n    *timeout64 = 0;\n    return MHD_YES;\n  }\n#ifdef EPOLL_SUPPORT\n  if (MHD_D_IS_USING_EPOLL_ (daemon) &&\n      ((NULL != daemon->eready_head)\n#if defined(UPGRADE_SUPPORT) && defined(HTTPS_SUPPORT)\n       || (NULL != daemon->eready_urh_head)\n#endif /* UPGRADE_SUPPORT && HTTPS_SUPPORT */\n      ) )\n  {\n    /* Some connection(s) already have some data pending. */\n    *timeout64 = 0;\n    return MHD_YES;\n  }\n#endif /* EPOLL_SUPPORT */\n\n  earliest_tmot_conn = NULL;\n  earliest_deadline = 0; /* mute compiler warning */\n  /* normal timeouts are sorted, so we only need to look at the 'tail' (oldest) */\n  pos = daemon->normal_timeout_tail;\n  if ( (NULL != pos) &&\n       (0 != pos->connection_timeout_ms) )\n  {\n    earliest_tmot_conn = pos;\n    earliest_deadline = pos->last_activity + pos->connection_timeout_ms;\n  }\n\n  for (pos = daemon->manual_timeout_tail; NULL != pos; pos = pos->prevX)\n  {\n    if (0 != pos->connection_timeout_ms)\n    {\n      if ( (NULL == earliest_tmot_conn) ||\n           (earliest_deadline - pos->last_activity >\n            pos->connection_timeout_ms) )\n      {\n        earliest_tmot_conn = pos;\n        earliest_deadline = pos->last_activity + pos->connection_timeout_ms;\n      }\n    }\n  }\n\n  if (NULL != earliest_tmot_conn)\n  {\n    *timeout64 = connection_get_wait (earliest_tmot_conn);\n    return MHD_YES;\n  }\n  return MHD_NO;\n}\n```\n</target_code>\n<additional code>Here are the definitions of symbols that are close to the target function MHD_get_timeout64:\nvoid\nMHD_DLOG (const struct MHD_Daemon *daemon,\n          const char *format,\n          ...)\n{\n  va_list va;\n\n  if (0 == (daemon->options & MHD_USE_ERROR_LOG))\n    return;\n  va_start (va, format);\n  daemon->custom_error_log (daemon->custom_error_log_cls,\n                            format,\n                            va);\n  va_end (va);\n}\n...\nstatic uint64_t\nconnection_get_wait (struct MHD_Connection *c)\n{\n  const uint64_t now = MHD_monotonic_msec_counter ();\n  const uint64_t since_actv = now - c->last_activity;\n  const uint64_t timeout = c->connection_timeout_ms;\n  uint64_t mseconds_left;\n\n  mhd_assert (0 != timeout);\n  /* Keep the next lines in sync with #connection_check_timedout() to avoid\n   * undesired side-effects like busy-waiting. */\n  if (timeout < since_actv)\n  {\n    if (UINT64_MAX / 2 < since_actv)\n    {\n      const uint64_t jump_back = c->last_activity - now;\n      /* Very unlikely that it is more than quarter-million years pause.\n       * More likely that system clock jumps back. */\n      if (5000 >= jump_back)\n      { /* Jump back is less than 5 seconds, try to recover. */\n        return 100; /* Set wait time to 0.1 seconds */\n      }\n      /* Too large jump back */\n    }\n    return 0; /* Connection has timed out */\n  }\n  else if (since_actv == timeout)\n  {\n    /* Exact match for timeout and time from last activity.\n     * Maybe this is just a precise match or this happens because the timer\n     * resolution is too low.\n     * Set wait time to 0.1 seconds to avoid busy-waiting with low\n     * timer resolution as connection is not timed-out yet. */\n    return 100;\n  }\n  mseconds_left = timeout - since_actv;\n\n  return mseconds_left;\n}\n...\nuint64_t\nMHD_monotonic_msec_counter (void)\n{\n#if defined(HAVE_CLOCK_GETTIME) || defined(HAVE_TIMESPEC_GET)\n  struct timespec ts;\n#endif /* HAVE_CLOCK_GETTIME || HAVE_TIMESPEC_GET */\n\n#ifdef HAVE_CLOCK_GETTIME\n  if ( (_MHD_UNWANTED_CLOCK != mono_clock_id) &&\n       (0 == clock_gettime (mono_clock_id,\n                            &ts)) )\n    return (uint64_t) (((uint64_t) (ts.tv_sec - mono_clock_start)) * 1000\n                       + (uint64_t) (ts.tv_nsec / 1000000));\n#endif /* HAVE_CLOCK_GETTIME */\n#ifdef HAVE_CLOCK_GET_TIME\n  if (_MHD_INVALID_CLOCK_SERV != mono_clock_service)\n  {\n    mach_timespec_t cur_time;\n\n    if (KERN_SUCCESS == clock_get_time (mono_clock_service,\n                                        &cur_time))\n      return (uint64_t) (((uint64_t) (cur_time.tv_sec - mono_clock_start))\n                         * 1000 + (uint64_t) (cur_time.tv_nsec / 1000000));\n  }\n#endif /* HAVE_CLOCK_GET_TIME */\n#if defined(_WIN32)\n#if _WIN32_WINNT >= 0x0600\n  if (1)\n    return (uint64_t) (GetTickCount64 () - tick_start);\n#else  /* _WIN32_WINNT < 0x0600 */\n  if (0 != perf_freq)\n  {\n    LARGE_INTEGER perf_counter;\n    uint64_t num_ticks;\n\n    QueryPerformanceCounter (&perf_counter);   /* never fail on XP and later */\n    num_ticks = (uint64_t) (perf_counter.QuadPart - perf_start);\n    return ((num_ticks / perf_freq) * 1000)\n           + ((num_ticks % perf_freq) / (perf_freq / 1000));\n  }\n#endif /* _WIN32_WINNT < 0x0600 */\n#endif /* _WIN32 */\n#ifdef HAVE_GETHRTIME\n  if (1)\n    return ((uint64_t) (gethrtime () - hrtime_start)) / 1000000;\n#endif /* HAVE_GETHRTIME */\n\n  /* Fallbacks, affected by system time change */\n#ifdef HAVE_TIMESPEC_GET\n  if (TIME_UTC == timespec_get (&ts, TIME_UTC))\n    return (uint64_t) (((uint64_t) (ts.tv_sec - gettime_start)) * 1000\n                       + (uint64_t) (ts.tv_nsec / 1000000));\n#elif defined(HAVE_GETTIMEOFDAY)\n  if (1)\n  {\n    struct timeval tv;\n    if (0 == gettimeofday (&tv, NULL))\n      return (uint64_t) (((uint64_t) (tv.tv_sec - gettime_start)) * 1000\n                         + (uint64_t) (tv.tv_usec / 1000));\n  }\n#endif /* HAVE_GETTIMEOFDAY */\n\n  /* The last resort fallback with very low resolution */\n  return (uint64_t) (time (NULL) - sys_clock_start) * 1000;\n}\n</additional code>\n<target_code>\nHere is the code fragment that you need to analyze:\n```c\n#if defined(_WIN32)\n#if _WIN32_WINNT >= 0x0600\n  if (1)\n    return (uint64_t) (GetTickCount64 () - tick_start);\n#else  /* _WIN32_WINNT < 0x0600 */\n  if (0 != perf_freq)\n  {\n    LARGE_INTEGER perf_counter;\n    uint64_t num_ticks;\n\n    QueryPerformanceCounter (&perf_counter);   /* never fail on XP and later */\n    num_ticks = (uint64_t) (perf_counter.QuadPart - perf_start);\n    return ((num_ticks / perf_freq) * 1000)\n           + ((num_ticks % perf_freq) / (perf_freq / 1000));\n  }\n#endif\n#endif\n```\nFocus on the above code fragment and judge whether it violates the rule 17.2 or not.\n</target_code>\n",
  "is_rule_violated": false,
  "scenario": "No violation: the fragment calls OS APIs (GetTickCount64, QueryPerformanceCounter) and performs no call to MHD_monotonic_msec_counter or any function that would lead back to it. The call graph shown is MHD_get_timeout64 -> connection_get_wait -> MHD_monotonic_msec_counter, with no path returning to MHD_get_timeout64 or any function calling itself. Therefore there is no direct or indirect self-call."
}