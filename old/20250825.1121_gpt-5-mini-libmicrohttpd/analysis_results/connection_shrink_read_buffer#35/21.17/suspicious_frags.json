{
  "user_message": "<misra_rule>\nThe target MISRA C 2023 Rule 21.17 is: Use of the string handling functions from <string.h> shall not result in accesses beyond the bounds of the objects referenced by their pointer parameters.\nThis rule strictly applies to the Standard Library functions in <string.h> such as memcpy, memmove, memset, memcmp, strcpy, strncpy, strcat, strncat, strlen, and strspn.\n</misra_rule>\n<instruction>\nOther agents will judge whether the code follows the MISRA C 2023 guidelines.\nThey will investigate the code fragments you give.\nYour job is to find code fragments in the code that should be investigated to check whether the code follows the MISRA C rule.\n</instruction>\n<response format>\nProvide your answer with these fields.\n- suspicious_frags: The list of suspicious code fragments in the code.\nIt should contain only the code fragments exists in the code. If you do not find any suspicious code fragments, return an empty list for suspicious_frags\n- explanation: The explanation of why other code fragments should NOT be investigated.\nIt is very important to not miss any suspicious code fragments, so please give a sufficient explanation why other code fragments should not be investigated.\nDO NOT give any explanation for the selected suspicious code fragments.\n</response format>\n<target_code>\nHere is the code of connection_shrink_read_buffer:\n```c\nstatic void\nconnection_shrink_read_buffer (struct MHD_Connection *connection)\n{\n  struct MHD_Connection *const c = connection; /**< a short alias */\n  void *new_buf;\n\n  if ((NULL == c->read_buffer) || (0 == c->read_buffer_size))\n  {\n    mhd_assert (0 == c->read_buffer_size);\n    mhd_assert (0 == c->read_buffer_offset);\n    return;\n  }\n\n  mhd_assert (c->read_buffer_offset <= c->read_buffer_size);\n  if (0 == c->read_buffer_offset)\n  {\n    MHD_pool_deallocate (c->pool, c->read_buffer, c->read_buffer_size);\n    c->read_buffer = NULL;\n    c->read_buffer_size = 0;\n  }\n  else\n  {\n    mhd_assert (MHD_pool_is_resizable_inplace (c->pool, c->read_buffer, \\\n                                               c->read_buffer_size));\n    new_buf = MHD_pool_reallocate (c->pool, c->read_buffer, c->read_buffer_size,\n                                   c->read_buffer_offset);\n    mhd_assert (c->read_buffer == new_buf);\n    c->read_buffer = new_buf;\n    c->read_buffer_size = c->read_buffer_offset;\n  }\n}\n```\n</target_code>\n<additional code>Here are the definitions of symbols that are related to the target function connection_shrink_read_buffer:\nstruct MHD_Connection\n{\n\n#ifdef EPOLL_SUPPORT\n  /**\n   * Next pointer for the EDLL listing connections that are epoll-ready.\n   */\n  struct MHD_Connection *nextE;\n\n  /**\n   * Previous pointer for the EDLL listing connections that are epoll-ready.\n   */\n  struct MHD_Connection *prevE;\n#endif\n\n  /**\n   * Next pointer for the DLL describing our IO state.\n   */\n  struct MHD_Connection *next;\n\n  /**\n   * Previous pointer for the DLL describing our IO state.\n   */\n  struct MHD_Connection *prev;\n\n  /**\n   * Next pointer for the XDLL organizing connections by timeout.\n   * This DLL can be either the\n   * 'manual_timeout_head/manual_timeout_tail' or the\n   * 'normal_timeout_head/normal_timeout_tail', depending on whether a\n   * custom timeout is set for the connection.\n   */\n  struct MHD_Connection *nextX;\n\n  /**\n   * Previous pointer for the XDLL organizing connections by timeout.\n   */\n  struct MHD_Connection *prevX;\n\n  /**\n   * Reference to the MHD_Daemon struct.\n   */\n  struct MHD_Daemon *daemon;\n\n  /**\n   * Request-specific data\n   */\n  struct MHD_Request rq;\n\n  /**\n   * Reply-specific data\n   */\n  struct MHD_Reply rp;\n\n  /**\n   * The memory pool is created whenever we first read from the TCP\n   * stream and destroyed at the end of each request (and re-created\n   * for the next request).  In the meantime, this pointer is NULL.\n   * The pool is used for all connection-related data except for the\n   * response (which maybe shared between connections) and the IP\n   * address (which persists across individual requests).\n   */\n  struct MemoryPool *pool;\n\n  /**\n   * We allow the main application to associate some pointer with the\n   * TCP connection (which may span multiple HTTP requests).  Here is\n   * where we store it.  (MHD does not know or care what it is).\n   * The location is given to the #MHD_NotifyConnectionCallback and\n   * also accessible via #MHD_CONNECTION_INFO_SOCKET_CONTEXT.\n   */\n  void *socket_context;\n\n  /**\n   * Close connection after sending response?\n   * Functions may change value from \"Unknown\" or \"KeepAlive\" to \"Must close\",\n   * but no functions reset value \"Must Close\" to any other value.\n   */\n  enum MHD_ConnKeepAlive keepalive;\n\n  /**\n   * Buffer for reading requests.  Allocated in pool.  Actually one\n   * byte larger than @e read_buffer_size (if non-NULL) to allow for\n   * 0-termination.\n   */\n  char *read_buffer;\n\n  /**\n   * Buffer for writing response (headers only).  Allocated\n   * in pool.\n   */\n  char *write_buffer;\n\n  /**\n   * Foreign address (of length @e addr_len).  MALLOCED (not\n   * in pool!).\n   */\n  struct sockaddr_storage *addr;\n\n#if defined(MHD_USE_POSIX_THREADS) || defined(MHD_USE_W32_THREADS)\n  /**\n   * Thread handle for this connection (if we are using\n   * one thread per connection).\n   */\n  MHD_thread_handle_ID_ tid;\n#endif\n\n  /**\n   * Size of @e read_buffer (in bytes).\n   * This value indicates how many bytes we're willing to read\n   * into the buffer.\n   */\n  size_t read_buffer_size;\n\n  /**\n   * Position where we currently append data in @e read_buffer (the\n   * next char after the last valid position).\n   */\n  size_t read_buffer_offset;\n\n  /**\n   * Size of @e write_buffer (in bytes).\n   */\n  size_t write_buffer_size;\n\n  /**\n   * Offset where we are with sending from @e write_buffer.\n   */\n  size_t write_buffer_send_offset;\n\n  /**\n   * Last valid location in write_buffer (where do we\n   * append and up to where is it safe to send?)\n   */\n  size_t write_buffer_append_offset;\n\n  /**\n   * Position in the 100 CONTINUE message that\n   * we need to send when receiving http 1.1 requests.\n   */\n  size_t continue_message_write_offset;\n\n  /**\n   * Length of the foreign address.\n   */\n  socklen_t addr_len;\n\n  /**\n   * Last time this connection had any activity\n   * (reading or writing).\n   */\n  uint64_t last_activity;\n\n  /**\n   * After how many milliseconds of inactivity should\n   * this connection time out?\n   * Zero for no timeout.\n   */\n  uint64_t connection_timeout_ms;\n\n  /**\n   * Socket for this connection.  Set to #MHD_INVALID_SOCKET if\n   * this connection has died (daemon should clean\n   * up in that case).\n   */\n  MHD_socket socket_fd;\n\n  /**\n   * true if @e socket_fd is not TCP/IP (a UNIX domain socket, a pipe),\n   * false (TCP/IP) otherwise.\n   */\n  enum MHD_tristate is_nonip;\n\n  /**\n   * true if #socket_fd is non-blocking, false otherwise.\n   */\n  bool sk_nonblck;\n\n  /**\n   * true if connection socket has set SIGPIPE suppression\n   */\n  bool sk_spipe_suppress;\n\n  /**\n   * Tracks TCP_CORK / TCP_NOPUSH of the connection socket.\n   */\n  enum MHD_tristate sk_corked;\n\n  /**\n   * Tracks TCP_NODELAY state of the connection socket.\n   */\n  enum MHD_tristate sk_nodelay;\n\n  /**\n   * Has this socket been closed for reading (i.e.  other side closed\n   * the connection)?  If so, we must completely close the connection\n   * once we are done sending our response (and stop trying to read\n   * from this socket).\n   */\n  bool read_closed;\n\n  /**\n   * Some error happens during processing the connection therefore this\n   * connection must be closed.\n   * The error may come from the client side (like wrong request format),\n   * from the application side (like data callback returned error), or from\n   * the OS side (like out-of-memory).\n   */\n  bool stop_with_error;\n\n  /**\n   * Response queued early, before the request is fully processed,\n   * the client upload is rejected.\n   * The connection cannot be reused for additional requests as the current\n   * request is incompletely read and it is unclear where is the initial\n   * byte of the next request.\n   */\n  bool discard_request;\n\n#if defined(MHD_USE_POSIX_THREADS) || defined(MHD_USE_W32_THREADS)\n  /**\n   * Set to `true` if the thread has been joined.\n   */\n  bool thread_joined;\n#endif\n\n  /**\n   * Are we currently inside the \"idle\" handler (to avoid recursively\n   * invoking it).\n   */\n  bool in_idle;\n\n  /**\n   * Connection is in the cleanup DL-linked list.\n   */\n  bool in_cleanup;\n\n#ifdef EPOLL_SUPPORT\n  /**\n   * What is the state of this socket in relation to epoll?\n   */\n  enum MHD_EpollState epoll_state;\n#endif\n\n  /**\n   * State in the FSM for this connection.\n   */\n  enum MHD_CONNECTION_STATE state;\n\n  /**\n   * What is this connection waiting for?\n   */\n  enum MHD_ConnectionEventLoopInfo event_loop_info;\n\n  /**\n   * Function used for reading HTTP request stream.\n   */\n  ReceiveCallback recv_cls;\n\n#ifdef UPGRADE_SUPPORT\n  /**\n   * If this connection was upgraded, this points to\n   * the upgrade response details such that the\n   * #thread_main_connection_upgrade()-logic can perform the\n   * bi-directional forwarding.\n   */\n  struct MHD_UpgradeResponseHandle *urh;\n#endif /* UPGRADE_SUPPORT */\n\n#ifdef HTTPS_SUPPORT\n\n  /**\n   * State required for HTTPS/SSL/TLS support.\n   */\n  gnutls_session_t tls_session;\n\n  /**\n   * State of connection's TLS layer\n   */\n  enum MHD_TLS_CONN_STATE tls_state;\n\n  /**\n   * Could it be that we are ready to read due to TLS buffers\n   * even though the socket is not?\n   */\n  bool tls_read_ready;\n#endif /* HTTPS_SUPPORT */\n\n  /**\n   * Is the connection suspended?\n   */\n  bool suspended;\n\n  /**\n   * Are we currently in the #MHD_AccessHandlerCallback\n   * for this connection (and thus eligible to receive\n   * calls to #MHD_queue_response()?).\n   */\n  bool in_access_handler;\n\n  /**\n   * Is the connection wanting to resume?\n   */\n  volatile bool resuming;\n\n  /**\n   * Special member to be returned by #MHD_get_connection_info()\n   */\n  union MHD_ConnectionInfo connection_info_dummy;\n}\n...\nvoid *\nMHD_pool_reallocate (struct MemoryPool *pool,\n                     void *old,\n                     size_t old_size,\n                     size_t new_size)\n{\n  size_t asize;\n  uint8_t *new_blc;\n\n  mhd_assert (pool->end >= pool->pos);\n  mhd_assert (pool->size >= pool->end - pool->pos);\n  mhd_assert (old != NULL || old_size == 0);\n  mhd_assert (pool->size >= old_size);\n  mhd_assert (pool->pos == ROUND_TO_ALIGN (pool->pos));\n#if defined(MHD_ASAN_POISON_ACTIVE) && defined(HAVE___ASAN_REGION_IS_POISONED)\n  mhd_assert (NULL == __asan_region_is_poisoned (old, old_size));\n#endif /* MHD_ASAN_POISON_ACTIVE && HAVE___ASAN_REGION_IS_POISONED */\n\n  if (NULL != old)\n  {   /* Have previously allocated data */\n    const size_t old_offset = mp_ptr_diff_ (old, pool->memory);\n    const bool shrinking = (old_size > new_size);\n\n    mhd_assert (mp_ptr_le_ (pool->memory, old));\n    /* (pool->memory + pool->size >= (uint8_t*) old + old_size) */\n    mhd_assert ((pool->size - _MHD_RED_ZONE_SIZE) >= (old_offset + old_size));\n    /* Blocks \"from the end\" must not be reallocated */\n    /* (old_size == 0 || pool->memory + pool->pos > (uint8_t*) old) */\n    mhd_assert ((old_size == 0) || \\\n                (pool->pos > old_offset));\n    mhd_assert ((old_size == 0) || \\\n                ((pool->end - _MHD_RED_ZONE_SIZE) >= (old_offset + old_size)));\n    /* Try resizing in-place */\n    if (shrinking)\n    {     /* Shrinking in-place, zero-out freed part */\n      memset ((uint8_t *) old + new_size, 0, old_size - new_size);\n      _MHD_POISON_MEMORY ((uint8_t *) old + new_size, old_size - new_size);\n    }\n    if (pool->pos ==\n        ROUND_TO_ALIGN_PLUS_RED_ZONE (old_offset + old_size))\n    {     /* \"old\" block is the last allocated block */\n      const size_t new_apos =\n        ROUND_TO_ALIGN_PLUS_RED_ZONE (old_offset + new_size);\n      if (! shrinking)\n      {                               /* Grow in-place, check for enough space. */\n        if ( (new_apos > pool->end) ||\n             (new_apos < pool->pos) ) /* Value wrap */\n          return NULL;                /* No space */\n      }\n      /* Resized in-place */\n      pool->pos = new_apos;\n      _MHD_UNPOISON_MEMORY (old, new_size);\n      return old;\n    }\n    if (shrinking)\n      return old;   /* Resized in-place, freed part remains allocated */\n  }\n  /* Need to allocate new block */\n  asize = ROUND_TO_ALIGN_PLUS_RED_ZONE (new_size);\n  if ( ( (0 == asize) &&\n         (0 != new_size) ) || /* Value wrap, too large new_size. */\n       (asize > pool->end - pool->pos) ) /* Not enough space */\n    return NULL;\n\n  new_blc = pool->memory + pool->pos;\n  pool->pos += asize;\n\n  _MHD_UNPOISON_MEMORY (new_blc, new_size);\n  if (0 != old_size)\n  {\n    /* Move data to new block, old block remains allocated */\n    memcpy (new_blc, old, old_size);\n    /* Zero-out old block */\n    memset (old, 0, old_size);\n    _MHD_POISON_MEMORY (old, old_size);\n  }\n  return new_blc;\n}\n...\nvoid\nMHD_pool_deallocate (struct MemoryPool *pool,\n                     void *block,\n                     size_t block_size)\n{\n  mhd_assert (pool->end >= pool->pos);\n  mhd_assert (pool->size >= pool->end - pool->pos);\n  mhd_assert (block != NULL || block_size == 0);\n  mhd_assert (pool->size >= block_size);\n  mhd_assert (pool->pos == ROUND_TO_ALIGN (pool->pos));\n\n  if (NULL != block)\n  {   /* Have previously allocated data */\n    const size_t block_offset = mp_ptr_diff_ (block, pool->memory);\n    mhd_assert (mp_ptr_le_ (pool->memory, block));\n    mhd_assert (block_offset <= pool->size);\n    mhd_assert ((block_offset != pool->pos) || (block_size == 0));\n    /* Zero-out deallocated region */\n    if (0 != block_size)\n    {\n      memset (block, 0, block_size);\n      _MHD_POISON_MEMORY (block, block_size);\n    }\n#if ! defined(MHD_FAVOR_SMALL_CODE) && ! defined(MHD_ASAN_POISON_ACTIVE)\n    else\n      return; /* Zero size, no need to do anything */\n#endif /* ! MHD_FAVOR_SMALL_CODE && ! MHD_ASAN_POISON_ACTIVE */\n    if (block_offset <= pool->pos)\n    {\n      /* \"Normal\" block, not allocated \"from the end\". */\n      const size_t alg_end =\n        ROUND_TO_ALIGN_PLUS_RED_ZONE (block_offset + block_size);\n      mhd_assert (alg_end <= pool->pos);\n      if (alg_end == pool->pos)\n      {\n        /* The last allocated block, return deallocated block to the pool */\n        size_t alg_start = ROUND_TO_ALIGN (block_offset);\n        mhd_assert (alg_start >= block_offset);\n#if defined(MHD_ASAN_POISON_ACTIVE)\n        if (alg_start != block_offset)\n        {\n          _MHD_POISON_MEMORY (pool->memory + block_offset, \\\n                              alg_start - block_offset);\n        }\n        else if (0 != alg_start)\n        {\n          bool need_red_zone_before;\n          mhd_assert (_MHD_RED_ZONE_SIZE <= alg_start);\n#if defined(HAVE___ASAN_REGION_IS_POISONED)\n          need_red_zone_before =\n            (NULL == __asan_region_is_poisoned (pool->memory\n                                                + alg_start\n                                                - _MHD_RED_ZONE_SIZE,\n                                                _MHD_RED_ZONE_SIZE));\n#elif defined(HAVE___ASAN_ADDRESS_IS_POISONED)\n          need_red_zone_before =\n            (0 == __asan_address_is_poisoned (pool->memory + alg_start - 1));\n#else  /* ! HAVE___ASAN_ADDRESS_IS_POISONED */\n          need_red_zone_before = true; /* Unknown, assume new red zone needed */\n#endif /* ! HAVE___ASAN_ADDRESS_IS_POISONED */\n          if (need_red_zone_before)\n          {\n            _MHD_POISON_MEMORY (pool->memory + alg_start, _MHD_RED_ZONE_SIZE);\n            alg_start += _MHD_RED_ZONE_SIZE;\n          }\n        }\n#endif /* MHD_ASAN_POISON_ACTIVE */\n        mhd_assert (alg_start <= pool->pos);\n        mhd_assert (alg_start == ROUND_TO_ALIGN (alg_start));\n        pool->pos = alg_start;\n      }\n    }\n    else\n    {\n      /* Allocated \"from the end\" block. */\n      /* The size and the pointers of such block should not be manipulated by\n         MHD code (block split is disallowed). */\n      mhd_assert (block_offset >= pool->end);\n      mhd_assert (ROUND_TO_ALIGN (block_offset) == block_offset);\n      if (block_offset == pool->end)\n      {\n        /* The last allocated block, return deallocated block to the pool */\n        const size_t alg_end =\n          ROUND_TO_ALIGN_PLUS_RED_ZONE (block_offset + block_size);\n        pool->end = alg_end;\n      }\n    }\n  }\n}\n...\nbool\nMHD_pool_is_resizable_inplace (struct MemoryPool *pool,\n                               void *block,\n                               size_t block_size)\n{\n  mhd_assert (pool->end >= pool->pos);\n  mhd_assert (pool->size >= pool->end - pool->pos);\n  mhd_assert (block != NULL || block_size == 0);\n  mhd_assert (pool->size >= block_size);\n  if (NULL != block)\n  {\n    const size_t block_offset = mp_ptr_diff_ (block, pool->memory);\n    mhd_assert (mp_ptr_le_ (pool->memory, block));\n    mhd_assert (pool->size >= block_offset);\n    mhd_assert (pool->size >= block_offset + block_size);\n    return (pool->pos ==\n            ROUND_TO_ALIGN_PLUS_RED_ZONE (block_offset + block_size));\n  }\n  return false; /* Unallocated blocks cannot be resized in-place */\n}\n...\n#define mhd_assert(ignore) ((void)0)\n</additional code>\nPlease find suspicious code fragments in the code and report them. Other agents can not investigate other fragments that you do not report, so it is very important to find all suspicious fragments without missing any. Report the suspicious fragments AS MUCH AS POSSIBLE.",
  "suspicious_frags": [
    "memset ((uint8_t *) old + new_size, 0, old_size - new_size);",
    "memset (old, 0, old_size);",
    "memcpy (new_blc, old, old_size);",
    "memset (block, 0, block_size);"
  ],
  "explanation": "I did not list other fragments because connection_shrink_read_buffer itself contains no direct calls to the <string.h> functions covered by Rule 21.17 \u2014 it only calls MHD_pool_reallocate and MHD_pool_deallocate. Other code sections that do not invoke the listed string.h functions (or only contain pointer arithmetic, assertions, or non-string helpers like _MHD_POISON_MEMORY/_MHD_UNPOISON_MEMORY) were not included. The four listed lines are the only occurrences of memcpy/memset in the provided excerpts and therefore should be investigated for potential out-of-bounds accesses per the rule."
}