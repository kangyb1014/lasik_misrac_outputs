{
  "user_message": "<misra_rule>\nMISRA C 2023 Rule 1.2 is: Language extensions should not be used.\nYou should report only when the code uses any language compiler extensions that are explicitly stated as an extension in compiler documentations.\n</misra_rule>\n<response format>\nProvide your answer with these fields.\n- is_rule_violated: whether the rule is violated or not (true/false),\n- scenario: a specific violation scenario.\n</response format>\n<target_code>\nHere is the code of connection_shrink_read_buffer:\n```c\nstatic void\nconnection_shrink_read_buffer (struct MHD_Connection *connection)\n{\n  struct MHD_Connection *const c = connection; /**< a short alias */\n  void *new_buf;\n\n  if ((NULL == c->read_buffer) || (0 == c->read_buffer_size))\n  {\n    mhd_assert (0 == c->read_buffer_size);\n    mhd_assert (0 == c->read_buffer_offset);\n    return;\n  }\n\n  mhd_assert (c->read_buffer_offset <= c->read_buffer_size);\n  if (0 == c->read_buffer_offset)\n  {\n    MHD_pool_deallocate (c->pool, c->read_buffer, c->read_buffer_size);\n    c->read_buffer = NULL;\n    c->read_buffer_size = 0;\n  }\n  else\n  {\n    mhd_assert (MHD_pool_is_resizable_inplace (c->pool, c->read_buffer, \\\n                                               c->read_buffer_size));\n    new_buf = MHD_pool_reallocate (c->pool, c->read_buffer, c->read_buffer_size,\n                                   c->read_buffer_offset);\n    mhd_assert (c->read_buffer == new_buf);\n    c->read_buffer = new_buf;\n    c->read_buffer_size = c->read_buffer_offset;\n  }\n}\n```\n</target_code>\n<additional code>Here are the definitions of symbols that are close to the target function connection_shrink_read_buffer:\n#define mhd_assert(ignore) ((void)0)\n...\nbool\nMHD_pool_is_resizable_inplace (struct MemoryPool *pool,\n                               void *block,\n                               size_t block_size)\n{\n  mhd_assert (pool->end >= pool->pos);\n  mhd_assert (pool->size >= pool->end - pool->pos);\n  mhd_assert (block != NULL || block_size == 0);\n  mhd_assert (pool->size >= block_size);\n  if (NULL != block)\n  {\n    const size_t block_offset = mp_ptr_diff_ (block, pool->memory);\n    mhd_assert (mp_ptr_le_ (pool->memory, block));\n    mhd_assert (pool->size >= block_offset);\n    mhd_assert (pool->size >= block_offset + block_size);\n    return (pool->pos ==\n            ROUND_TO_ALIGN_PLUS_RED_ZONE (block_offset + block_size));\n  }\n  return false; /* Unallocated blocks cannot be resized in-place */\n}\n...\nvoid *\nMHD_pool_reallocate (struct MemoryPool *pool,\n                     void *old,\n                     size_t old_size,\n                     size_t new_size)\n{\n  size_t asize;\n  uint8_t *new_blc;\n\n  mhd_assert (pool->end >= pool->pos);\n  mhd_assert (pool->size >= pool->end - pool->pos);\n  mhd_assert (old != NULL || old_size == 0);\n  mhd_assert (pool->size >= old_size);\n  mhd_assert (pool->pos == ROUND_TO_ALIGN (pool->pos));\n#if defined(MHD_ASAN_POISON_ACTIVE) && defined(HAVE___ASAN_REGION_IS_POISONED)\n  mhd_assert (NULL == __asan_region_is_poisoned (old, old_size));\n#endif /* MHD_ASAN_POISON_ACTIVE && HAVE___ASAN_REGION_IS_POISONED */\n\n  if (NULL != old)\n  {   /* Have previously allocated data */\n    const size_t old_offset = mp_ptr_diff_ (old, pool->memory);\n    const bool shrinking = (old_size > new_size);\n\n    mhd_assert (mp_ptr_le_ (pool->memory, old));\n    /* (pool->memory + pool->size >= (uint8_t*) old + old_size) */\n    mhd_assert ((pool->size - _MHD_RED_ZONE_SIZE) >= (old_offset + old_size));\n    /* Blocks \"from the end\" must not be reallocated */\n    /* (old_size == 0 || pool->memory + pool->pos > (uint8_t*) old) */\n    mhd_assert ((old_size == 0) || \\\n                (pool->pos > old_offset));\n    mhd_assert ((old_size == 0) || \\\n                ((pool->end - _MHD_RED_ZONE_SIZE) >= (old_offset + old_size)));\n    /* Try resizing in-place */\n    if (shrinking)\n    {     /* Shrinking in-place, zero-out freed part */\n      memset ((uint8_t *) old + new_size, 0, old_size - new_size);\n      _MHD_POISON_MEMORY ((uint8_t *) old + new_size, old_size - new_size);\n    }\n    if (pool->pos ==\n        ROUND_TO_ALIGN_PLUS_RED_ZONE (old_offset + old_size))\n    {     /* \"old\" block is the last allocated block */\n      const size_t new_apos =\n        ROUND_TO_ALIGN_PLUS_RED_ZONE (old_offset + new_size);\n      if (! shrinking)\n      {                               /* Grow in-place, check for enough space. */\n        if ( (new_apos > pool->end) ||\n             (new_apos < pool->pos) ) /* Value wrap */\n          return NULL;                /* No space */\n      }\n      /* Resized in-place */\n      pool->pos = new_apos;\n      _MHD_UNPOISON_MEMORY (old, new_size);\n      return old;\n    }\n    if (shrinking)\n      return old;   /* Resized in-place, freed part remains allocated */\n  }\n  /* Need to allocate new block */\n  asize = ROUND_TO_ALIGN_PLUS_RED_ZONE (new_size);\n  if ( ( (0 == asize) &&\n         (0 != new_size) ) || /* Value wrap, too large new_size. */\n       (asize > pool->end - pool->pos) ) /* Not enough space */\n    return NULL;\n\n  new_blc = pool->memory + pool->pos;\n  pool->pos += asize;\n\n  _MHD_UNPOISON_MEMORY (new_blc, new_size);\n  if (0 != old_size)\n  {\n    /* Move data to new block, old block remains allocated */\n    memcpy (new_blc, old, old_size);\n    /* Zero-out old block */\n    memset (old, 0, old_size);\n    _MHD_POISON_MEMORY (old, old_size);\n  }\n  return new_blc;\n}\n...\nvoid\nMHD_pool_deallocate (struct MemoryPool *pool,\n                     void *block,\n                     size_t block_size)\n{\n  mhd_assert (pool->end >= pool->pos);\n  mhd_assert (pool->size >= pool->end - pool->pos);\n  mhd_assert (block != NULL || block_size == 0);\n  mhd_assert (pool->size >= block_size);\n  mhd_assert (pool->pos == ROUND_TO_ALIGN (pool->pos));\n\n  if (NULL != block)\n  {   /* Have previously allocated data */\n    const size_t block_offset = mp_ptr_diff_ (block, pool->memory);\n    mhd_assert (mp_ptr_le_ (pool->memory, block));\n    mhd_assert (block_offset <= pool->size);\n    mhd_assert ((block_offset != pool->pos) || (block_size == 0));\n    /* Zero-out deallocated region */\n    if (0 != block_size)\n    {\n      memset (block, 0, block_size);\n      _MHD_POISON_MEMORY (block, block_size);\n    }\n#if ! defined(MHD_FAVOR_SMALL_CODE) && ! defined(MHD_ASAN_POISON_ACTIVE)\n    else\n      return; /* Zero size, no need to do anything */\n#endif /* ! MHD_FAVOR_SMALL_CODE && ! MHD_ASAN_POISON_ACTIVE */\n    if (block_offset <= pool->pos)\n    {\n      /* \"Normal\" block, not allocated \"from the end\". */\n      const size_t alg_end =\n        ROUND_TO_ALIGN_PLUS_RED_ZONE (block_offset + block_size);\n      mhd_assert (alg_end <= pool->pos);\n      if (alg_end == pool->pos)\n      {\n        /* The last allocated block, return deallocated block to the pool */\n        size_t alg_start = ROUND_TO_ALIGN (block_offset);\n        mhd_assert (alg_start >= block_offset);\n#if defined(MHD_ASAN_POISON_ACTIVE)\n        if (alg_start != block_offset)\n        {\n          _MHD_POISON_MEMORY (pool->memory + block_offset, \\\n                              alg_start - block_offset);\n        }\n        else if (0 != alg_start)\n        {\n          bool need_red_zone_before;\n          mhd_assert (_MHD_RED_ZONE_SIZE <= alg_start);\n#if defined(HAVE___ASAN_REGION_IS_POISONED)\n          need_red_zone_before =\n            (NULL == __asan_region_is_poisoned (pool->memory\n                                                + alg_start\n                                                - _MHD_RED_ZONE_SIZE,\n                                                _MHD_RED_ZONE_SIZE));\n#elif defined(HAVE___ASAN_ADDRESS_IS_POISONED)\n          need_red_zone_before =\n            (0 == __asan_address_is_poisoned (pool->memory + alg_start - 1));\n#else  /* ! HAVE___ASAN_ADDRESS_IS_POISONED */\n          need_red_zone_before = true; /* Unknown, assume new red zone needed */\n#endif /* ! HAVE___ASAN_ADDRESS_IS_POISONED */\n          if (need_red_zone_before)\n          {\n            _MHD_POISON_MEMORY (pool->memory + alg_start, _MHD_RED_ZONE_SIZE);\n            alg_start += _MHD_RED_ZONE_SIZE;\n          }\n        }\n#endif /* MHD_ASAN_POISON_ACTIVE */\n        mhd_assert (alg_start <= pool->pos);\n        mhd_assert (alg_start == ROUND_TO_ALIGN (alg_start));\n        pool->pos = alg_start;\n      }\n    }\n    else\n    {\n      /* Allocated \"from the end\" block. */\n      /* The size and the pointers of such block should not be manipulated by\n         MHD code (block split is disallowed). */\n      mhd_assert (block_offset >= pool->end);\n      mhd_assert (ROUND_TO_ALIGN (block_offset) == block_offset);\n      if (block_offset == pool->end)\n      {\n        /* The last allocated block, return deallocated block to the pool */\n        const size_t alg_end =\n          ROUND_TO_ALIGN_PLUS_RED_ZONE (block_offset + block_size);\n        pool->end = alg_end;\n      }\n    }\n  }\n}\n</additional code>\n<target_code>\nHere is the code fragment that you need to analyze:\n```c\n#if defined(MHD_ASAN_POISON_ACTIVE)\n        if (alg_start != block_offset)\n        {\n          _MHD_POISON_MEMORY (pool->memory + block_offset, \\\n                              alg_start - block_offset);\n        }\n        else if (0 != alg_start)\n        {\n          bool need_red_zone_before;\n          mhd_assert (_MHD_RED_ZONE_SIZE <= alg_start);\n#if defined(HAVE___ASAN_REGION_IS_POISONED)\n          need_red_zone_before =\n            (NULL == __asan_region_is_poisoned (pool->memory\n                                                + alg_start\n                                                - _MHD_RED_ZONE_SIZE,\n                                                _MHD_RED_ZONE_SIZE));\n#elif defined(HAVE___ASAN_ADDRESS_IS_POISONED)\n          need_red_zone_before =\n            (0 == __asan_address_is_poisoned (pool->memory + alg_start - 1));\n#else  /* ! HAVE___ASAN_ADDRESS_IS_POISONED */\n          need_red_zone_before = true; /* Unknown, assume new red zone needed */\n#endif /* ! HAVE___ASAN_ADDRESS_IS_POISONED */\n          if (need_red_zone_before)\n          {\n            _MHD_POISON_MEMORY (pool->memory + alg_start, _MHD_RED_ZONE_SIZE);\n            alg_start += _MHD_RED_ZONE_SIZE;\n          }\n        }\n#endif /* MHD_ASAN_POISON_ACTIVE */\n```\nFocus on the above code fragment and judge whether it violates the rule 1.2 or not.\n</target_code>\n",
  "is_rule_violated": true,
  "scenario": "The fragment conditionally calls AddressSanitizer intrinsics (__asan_region_is_poisoned and __asan_address_is_poisoned) under feature-test macros. These __asan_* routines are compiler/ASan-specific facilities (implementation extensions) and thus constitute use of compiler-provided extensions. If those macros are defined, this is a Rule 1.2 violation; if they are never defined in the build, there is no violation."
}