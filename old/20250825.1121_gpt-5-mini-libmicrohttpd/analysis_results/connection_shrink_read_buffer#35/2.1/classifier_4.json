{
  "user_message": "<misra_rule>\nMISRA C 2023 Rule 2.1 is: A project shall not contain unreachable code.\n\n</misra_rule>\n<response format>\nProvide your answer with these fields.\n- is_rule_violated: whether the rule is violated or not (true/false),\n- scenario: a specific violation scenario.\n</response format>\n<target_code>\nHere is the code of connection_shrink_read_buffer:\n```c\nstatic void\nconnection_shrink_read_buffer (struct MHD_Connection *connection)\n{\n  struct MHD_Connection *const c = connection; /**< a short alias */\n  void *new_buf;\n\n  if ((NULL == c->read_buffer) || (0 == c->read_buffer_size))\n  {\n    mhd_assert (0 == c->read_buffer_size);\n    mhd_assert (0 == c->read_buffer_offset);\n    return;\n  }\n\n  mhd_assert (c->read_buffer_offset <= c->read_buffer_size);\n  if (0 == c->read_buffer_offset)\n  {\n    MHD_pool_deallocate (c->pool, c->read_buffer, c->read_buffer_size);\n    c->read_buffer = NULL;\n    c->read_buffer_size = 0;\n  }\n  else\n  {\n    mhd_assert (MHD_pool_is_resizable_inplace (c->pool, c->read_buffer, \\\n                                               c->read_buffer_size));\n    new_buf = MHD_pool_reallocate (c->pool, c->read_buffer, c->read_buffer_size,\n                                   c->read_buffer_offset);\n    mhd_assert (c->read_buffer == new_buf);\n    c->read_buffer = new_buf;\n    c->read_buffer_size = c->read_buffer_offset;\n  }\n}\n```\n</target_code>\n<additional code>Here are the definitions of symbols that are close to the target function connection_shrink_read_buffer:\nstruct MHD_Connection\n{\n\n#ifdef EPOLL_SUPPORT\n  /**\n   * Next pointer for the EDLL listing connections that are epoll-ready.\n   */\n  struct MHD_Connection *nextE;\n\n  /**\n   * Previous pointer for the EDLL listing connections that are epoll-ready.\n   */\n  struct MHD_Connection *prevE;\n#endif\n\n  /**\n   * Next pointer for the DLL describing our IO state.\n   */\n  struct MHD_Connection *next;\n\n  /**\n   * Previous pointer for the DLL describing our IO state.\n   */\n  struct MHD_Connection *prev;\n\n  /**\n   * Next pointer for the XDLL organizing connections by timeout.\n   * This DLL can be either the\n   * 'manual_timeout_head/manual_timeout_tail' or the\n   * 'normal_timeout_head/normal_timeout_tail', depending on whether a\n   * custom timeout is set for the connection.\n   */\n  struct MHD_Connection *nextX;\n\n  /**\n   * Previous pointer for the XDLL organizing connections by timeout.\n   */\n  struct MHD_Connection *prevX;\n\n  /**\n   * Reference to the MHD_Daemon struct.\n   */\n  struct MHD_Daemon *daemon;\n\n  /**\n   * Request-specific data\n   */\n  struct MHD_Request rq;\n\n  /**\n   * Reply-specific data\n   */\n  struct MHD_Reply rp;\n\n  /**\n   * The memory pool is created whenever we first read from the TCP\n   * stream and destroyed at the end of each request (and re-created\n   * for the next request).  In the meantime, this pointer is NULL.\n   * The pool is used for all connection-related data except for the\n   * response (which maybe shared between connections) and the IP\n   * address (which persists across individual requests).\n   */\n  struct MemoryPool *pool;\n\n  /**\n   * We allow the main application to associate some pointer with the\n   * TCP connection (which may span multiple HTTP requests).  Here is\n   * where we store it.  (MHD does not know or care what it is).\n   * The location is given to the #MHD_NotifyConnectionCallback and\n   * also accessible via #MHD_CONNECTION_INFO_SOCKET_CONTEXT.\n   */\n  void *socket_context;\n\n  /**\n   * Close connection after sending response?\n   * Functions may change value from \"Unknown\" or \"KeepAlive\" to \"Must close\",\n   * but no functions reset value \"Must Close\" to any other value.\n   */\n  enum MHD_ConnKeepAlive keepalive;\n\n  /**\n   * Buffer for reading requests.  Allocated in pool.  Actually one\n   * byte larger than @e read_buffer_size (if non-NULL) to allow for\n   * 0-termination.\n   */\n  char *read_buffer;\n\n  /**\n   * Buffer for writing response (headers only).  Allocated\n   * in pool.\n   */\n  char *write_buffer;\n\n  /**\n   * Foreign address (of length @e addr_len).  MALLOCED (not\n   * in pool!).\n   */\n  struct sockaddr_storage *addr;\n\n#if defined(MHD_USE_POSIX_THREADS) || defined(MHD_USE_W32_THREADS)\n  /**\n   * Thread handle for this connection (if we are using\n   * one thread per connection).\n   */\n  MHD_thread_handle_ID_ tid;\n#endif\n\n  /**\n   * Size of @e read_buffer (in bytes).\n   * This value indicates how many bytes we're willing to read\n   * into the buffer.\n   */\n  size_t read_buffer_size;\n\n  /**\n   * Position where we currently append data in @e read_buffer (the\n   * next char after the last valid position).\n   */\n  size_t read_buffer_offset;\n\n  /**\n   * Size of @e write_buffer (in bytes).\n   */\n  size_t write_buffer_size;\n\n  /**\n   * Offset where we are with sending from @e write_buffer.\n   */\n  size_t write_buffer_send_offset;\n\n  /**\n   * Last valid location in write_buffer (where do we\n   * append and up to where is it safe to send?)\n   */\n  size_t write_buffer_append_offset;\n\n  /**\n   * Position in the 100 CONTINUE message that\n   * we need to send when receiving http 1.1 requests.\n   */\n  size_t continue_message_write_offset;\n\n  /**\n   * Length of the foreign address.\n   */\n  socklen_t addr_len;\n\n  /**\n   * Last time this connection had any activity\n   * (reading or writing).\n   */\n  uint64_t last_activity;\n\n  /**\n   * After how many milliseconds of inactivity should\n   * this connection time out?\n   * Zero for no timeout.\n   */\n  uint64_t connection_timeout_ms;\n\n  /**\n   * Socket for this connection.  Set to #MHD_INVALID_SOCKET if\n   * this connection has died (daemon should clean\n   * up in that case).\n   */\n  MHD_socket socket_fd;\n\n  /**\n   * true if @e socket_fd is not TCP/IP (a UNIX domain socket, a pipe),\n   * false (TCP/IP) otherwise.\n   */\n  enum MHD_tristate is_nonip;\n\n  /**\n   * true if #socket_fd is non-blocking, false otherwise.\n   */\n  bool sk_nonblck;\n\n  /**\n   * true if connection socket has set SIGPIPE suppression\n   */\n  bool sk_spipe_suppress;\n\n  /**\n   * Tracks TCP_CORK / TCP_NOPUSH of the connection socket.\n   */\n  enum MHD_tristate sk_corked;\n\n  /**\n   * Tracks TCP_NODELAY state of the connection socket.\n   */\n  enum MHD_tristate sk_nodelay;\n\n  /**\n   * Has this socket been closed for reading (i.e.  other side closed\n   * the connection)?  If so, we must completely close the connection\n   * once we are done sending our response (and stop trying to read\n   * from this socket).\n   */\n  bool read_closed;\n\n  /**\n   * Some error happens during processing the connection therefore this\n   * connection must be closed.\n   * The error may come from the client side (like wrong request format),\n   * from the application side (like data callback returned error), or from\n   * the OS side (like out-of-memory).\n   */\n  bool stop_with_error;\n\n  /**\n   * Response queued early, before the request is fully processed,\n   * the client upload is rejected.\n   * The connection cannot be reused for additional requests as the current\n   * request is incompletely read and it is unclear where is the initial\n   * byte of the next request.\n   */\n  bool discard_request;\n\n#if defined(MHD_USE_POSIX_THREADS) || defined(MHD_USE_W32_THREADS)\n  /**\n   * Set to `true` if the thread has been joined.\n   */\n  bool thread_joined;\n#endif\n\n  /**\n   * Are we currently inside the \"idle\" handler (to avoid recursively\n   * invoking it).\n   */\n  bool in_idle;\n\n  /**\n   * Connection is in the cleanup DL-linked list.\n   */\n  bool in_cleanup;\n\n#ifdef EPOLL_SUPPORT\n  /**\n   * What is the state of this socket in relation to epoll?\n   */\n  enum MHD_EpollState epoll_state;\n#endif\n\n  /**\n   * State in the FSM for this connection.\n   */\n  enum MHD_CONNECTION_STATE state;\n\n  /**\n   * What is this connection waiting for?\n   */\n  enum MHD_ConnectionEventLoopInfo event_loop_info;\n\n  /**\n   * Function used for reading HTTP request stream.\n   */\n  ReceiveCallback recv_cls;\n\n#ifdef UPGRADE_SUPPORT\n  /**\n   * If this connection was upgraded, this points to\n   * the upgrade response details such that the\n   * #thread_main_connection_upgrade()-logic can perform the\n   * bi-directional forwarding.\n   */\n  struct MHD_UpgradeResponseHandle *urh;\n#endif /* UPGRADE_SUPPORT */\n\n#ifdef HTTPS_SUPPORT\n\n  /**\n   * State required for HTTPS/SSL/TLS support.\n   */\n  gnutls_session_t tls_session;\n\n  /**\n   * State of connection's TLS layer\n   */\n  enum MHD_TLS_CONN_STATE tls_state;\n\n  /**\n   * Could it be that we are ready to read due to TLS buffers\n   * even though the socket is not?\n   */\n  bool tls_read_ready;\n#endif /* HTTPS_SUPPORT */\n\n  /**\n   * Is the connection suspended?\n   */\n  bool suspended;\n\n  /**\n   * Are we currently in the #MHD_AccessHandlerCallback\n   * for this connection (and thus eligible to receive\n   * calls to #MHD_queue_response()?).\n   */\n  bool in_access_handler;\n\n  /**\n   * Is the connection wanting to resume?\n   */\n  volatile bool resuming;\n\n  /**\n   * Special member to be returned by #MHD_get_connection_info()\n   */\n  union MHD_ConnectionInfo connection_info_dummy;\n}\n...\n#define mhd_assert(ignore) ((void)0)\n...\nvoid\nMHD_pool_deallocate (struct MemoryPool *pool,\n                     void *block,\n                     size_t block_size)\n{\n  mhd_assert (pool->end >= pool->pos);\n  mhd_assert (pool->size >= pool->end - pool->pos);\n  mhd_assert (block != NULL || block_size == 0);\n  mhd_assert (pool->size >= block_size);\n  mhd_assert (pool->pos == ROUND_TO_ALIGN (pool->pos));\n\n  if (NULL != block)\n  {   /* Have previously allocated data */\n    const size_t block_offset = mp_ptr_diff_ (block, pool->memory);\n    mhd_assert (mp_ptr_le_ (pool->memory, block));\n    mhd_assert (block_offset <= pool->size);\n    mhd_assert ((block_offset != pool->pos) || (block_size == 0));\n    /* Zero-out deallocated region */\n    if (0 != block_size)\n    {\n      memset (block, 0, block_size);\n      _MHD_POISON_MEMORY (block, block_size);\n    }\n#if ! defined(MHD_FAVOR_SMALL_CODE) && ! defined(MHD_ASAN_POISON_ACTIVE)\n    else\n      return; /* Zero size, no need to do anything */\n#endif /* ! MHD_FAVOR_SMALL_CODE && ! MHD_ASAN_POISON_ACTIVE */\n    if (block_offset <= pool->pos)\n    {\n      /* \"Normal\" block, not allocated \"from the end\". */\n      const size_t alg_end =\n        ROUND_TO_ALIGN_PLUS_RED_ZONE (block_offset + block_size);\n      mhd_assert (alg_end <= pool->pos);\n      if (alg_end == pool->pos)\n      {\n        /* The last allocated block, return deallocated block to the pool */\n        size_t alg_start = ROUND_TO_ALIGN (block_offset);\n        mhd_assert (alg_start >= block_offset);\n#if defined(MHD_ASAN_POISON_ACTIVE)\n        if (alg_start != block_offset)\n        {\n          _MHD_POISON_MEMORY (pool->memory + block_offset, \\\n                              alg_start - block_offset);\n        }\n        else if (0 != alg_start)\n        {\n          bool need_red_zone_before;\n          mhd_assert (_MHD_RED_ZONE_SIZE <= alg_start);\n#if defined(HAVE___ASAN_REGION_IS_POISONED)\n          need_red_zone_before =\n            (NULL == __asan_region_is_poisoned (pool->memory\n                                                + alg_start\n                                                - _MHD_RED_ZONE_SIZE,\n                                                _MHD_RED_ZONE_SIZE));\n#elif defined(HAVE___ASAN_ADDRESS_IS_POISONED)\n          need_red_zone_before =\n            (0 == __asan_address_is_poisoned (pool->memory + alg_start - 1));\n#else  /* ! HAVE___ASAN_ADDRESS_IS_POISONED */\n          need_red_zone_before = true; /* Unknown, assume new red zone needed */\n#endif /* ! HAVE___ASAN_ADDRESS_IS_POISONED */\n          if (need_red_zone_before)\n          {\n            _MHD_POISON_MEMORY (pool->memory + alg_start, _MHD_RED_ZONE_SIZE);\n            alg_start += _MHD_RED_ZONE_SIZE;\n          }\n        }\n#endif /* MHD_ASAN_POISON_ACTIVE */\n        mhd_assert (alg_start <= pool->pos);\n        mhd_assert (alg_start == ROUND_TO_ALIGN (alg_start));\n        pool->pos = alg_start;\n      }\n    }\n    else\n    {\n      /* Allocated \"from the end\" block. */\n      /* The size and the pointers of such block should not be manipulated by\n         MHD code (block split is disallowed). */\n      mhd_assert (block_offset >= pool->end);\n      mhd_assert (ROUND_TO_ALIGN (block_offset) == block_offset);\n      if (block_offset == pool->end)\n      {\n        /* The last allocated block, return deallocated block to the pool */\n        const size_t alg_end =\n          ROUND_TO_ALIGN_PLUS_RED_ZONE (block_offset + block_size);\n        pool->end = alg_end;\n      }\n    }\n  }\n}\n...\nvoid *\nMHD_pool_reallocate (struct MemoryPool *pool,\n                     void *old,\n                     size_t old_size,\n                     size_t new_size)\n{\n  size_t asize;\n  uint8_t *new_blc;\n\n  mhd_assert (pool->end >= pool->pos);\n  mhd_assert (pool->size >= pool->end - pool->pos);\n  mhd_assert (old != NULL || old_size == 0);\n  mhd_assert (pool->size >= old_size);\n  mhd_assert (pool->pos == ROUND_TO_ALIGN (pool->pos));\n#if defined(MHD_ASAN_POISON_ACTIVE) && defined(HAVE___ASAN_REGION_IS_POISONED)\n  mhd_assert (NULL == __asan_region_is_poisoned (old, old_size));\n#endif /* MHD_ASAN_POISON_ACTIVE && HAVE___ASAN_REGION_IS_POISONED */\n\n  if (NULL != old)\n  {   /* Have previously allocated data */\n    const size_t old_offset = mp_ptr_diff_ (old, pool->memory);\n    const bool shrinking = (old_size > new_size);\n\n    mhd_assert (mp_ptr_le_ (pool->memory, old));\n    /* (pool->memory + pool->size >= (uint8_t*) old + old_size) */\n    mhd_assert ((pool->size - _MHD_RED_ZONE_SIZE) >= (old_offset + old_size));\n    /* Blocks \"from the end\" must not be reallocated */\n    /* (old_size == 0 || pool->memory + pool->pos > (uint8_t*) old) */\n    mhd_assert ((old_size == 0) || \\\n                (pool->pos > old_offset));\n    mhd_assert ((old_size == 0) || \\\n                ((pool->end - _MHD_RED_ZONE_SIZE) >= (old_offset + old_size)));\n    /* Try resizing in-place */\n    if (shrinking)\n    {     /* Shrinking in-place, zero-out freed part */\n      memset ((uint8_t *) old + new_size, 0, old_size - new_size);\n      _MHD_POISON_MEMORY ((uint8_t *) old + new_size, old_size - new_size);\n    }\n    if (pool->pos ==\n        ROUND_TO_ALIGN_PLUS_RED_ZONE (old_offset + old_size))\n    {     /* \"old\" block is the last allocated block */\n      const size_t new_apos =\n        ROUND_TO_ALIGN_PLUS_RED_ZONE (old_offset + new_size);\n      if (! shrinking)\n      {                               /* Grow in-place, check for enough space. */\n        if ( (new_apos > pool->end) ||\n             (new_apos < pool->pos) ) /* Value wrap */\n          return NULL;                /* No space */\n      }\n      /* Resized in-place */\n      pool->pos = new_apos;\n      _MHD_UNPOISON_MEMORY (old, new_size);\n      return old;\n    }\n    if (shrinking)\n      return old;   /* Resized in-place, freed part remains allocated */\n  }\n  /* Need to allocate new block */\n  asize = ROUND_TO_ALIGN_PLUS_RED_ZONE (new_size);\n  if ( ( (0 == asize) &&\n         (0 != new_size) ) || /* Value wrap, too large new_size. */\n       (asize > pool->end - pool->pos) ) /* Not enough space */\n    return NULL;\n\n  new_blc = pool->memory + pool->pos;\n  pool->pos += asize;\n\n  _MHD_UNPOISON_MEMORY (new_blc, new_size);\n  if (0 != old_size)\n  {\n    /* Move data to new block, old block remains allocated */\n    memcpy (new_blc, old, old_size);\n    /* Zero-out old block */\n    memset (old, 0, old_size);\n    _MHD_POISON_MEMORY (old, old_size);\n  }\n  return new_blc;\n}\n...\nbool\nMHD_pool_is_resizable_inplace (struct MemoryPool *pool,\n                               void *block,\n                               size_t block_size)\n{\n  mhd_assert (pool->end >= pool->pos);\n  mhd_assert (pool->size >= pool->end - pool->pos);\n  mhd_assert (block != NULL || block_size == 0);\n  mhd_assert (pool->size >= block_size);\n  if (NULL != block)\n  {\n    const size_t block_offset = mp_ptr_diff_ (block, pool->memory);\n    mhd_assert (mp_ptr_le_ (pool->memory, block));\n    mhd_assert (pool->size >= block_offset);\n    mhd_assert (pool->size >= block_offset + block_size);\n    return (pool->pos ==\n            ROUND_TO_ALIGN_PLUS_RED_ZONE (block_offset + block_size));\n  }\n  return false; /* Unallocated blocks cannot be resized in-place */\n}\n...\nstatic void\nconnection_switch_from_recv_to_send (struct MHD_Connection *connection)\n{\n  /* Read buffer is not needed for this request, shrink it.*/\n  connection_shrink_read_buffer (connection);\n}\n...\nvoid *\nMHD_connection_alloc_memory_ (struct MHD_Connection *connection,\n                              size_t size)\n{\n  struct MHD_Connection *const c = connection; /* a short alias */\n  struct MemoryPool *const pool = c->pool;     /* a short alias */\n  size_t need_to_be_freed = 0; /**< The required amount of additional free memory */\n  void *res;\n\n  res = MHD_pool_try_alloc (pool,\n                            size,\n                            &need_to_be_freed);\n  if (NULL != res)\n    return res;\n\n  if (MHD_pool_is_resizable_inplace (pool,\n                                     c->write_buffer,\n                                     c->write_buffer_size))\n  {\n    if (c->write_buffer_size - c->write_buffer_append_offset >=\n        need_to_be_freed)\n    {\n      char *buf;\n      const size_t new_buf_size = c->write_buffer_size - need_to_be_freed;\n      buf = MHD_pool_reallocate (pool,\n                                 c->write_buffer,\n                                 c->write_buffer_size,\n                                 new_buf_size);\n      mhd_assert (c->write_buffer == buf);\n      mhd_assert (c->write_buffer_append_offset <= new_buf_size);\n      mhd_assert (c->write_buffer_send_offset <= new_buf_size);\n      c->write_buffer_size = new_buf_size;\n      c->write_buffer = buf;\n    }\n    else\n      return NULL;\n  }\n  else if (MHD_pool_is_resizable_inplace (pool,\n                                          c->read_buffer,\n                                          c->read_buffer_size))\n  {\n    if (c->read_buffer_size - c->read_buffer_offset >= need_to_be_freed)\n    {\n      char *buf;\n      const size_t new_buf_size = c->read_buffer_size - need_to_be_freed;\n      buf = MHD_pool_reallocate (pool,\n                                 c->read_buffer,\n                                 c->read_buffer_size,\n                                 new_buf_size);\n      mhd_assert (c->read_buffer == buf);\n      mhd_assert (c->read_buffer_offset <= new_buf_size);\n      c->read_buffer_size = new_buf_size;\n      c->read_buffer = buf;\n    }\n    else\n      return NULL;\n  }\n  else\n    return NULL;\n  res = MHD_pool_allocate (pool, size, true);\n  mhd_assert (NULL != res); /* It has been checked that pool has enough space */\n  return res;\n}\n...\nstatic bool\ntry_grow_read_buffer (struct MHD_Connection *connection,\n                      bool required)\n{\n  size_t new_size;\n  size_t avail_size;\n  const size_t def_grow_size = connection->daemon->pool_increment;\n  void *rb;\n\n  avail_size = MHD_pool_get_free (connection->pool);\n  if (0 == avail_size)\n    return false;               /* No more space available */\n  if (0 == connection->read_buffer_size)\n    new_size = avail_size / 2;  /* Use half of available buffer for reading */\n  else\n  {\n    size_t grow_size;\n\n    grow_size = avail_size / 8;\n    if (def_grow_size > grow_size)\n    {                  /* Shortage of space */\n      const size_t left_free =\n        connection->read_buffer_size - connection->read_buffer_offset;\n      mhd_assert (connection->read_buffer_size >= \\\n                  connection->read_buffer_offset);\n      if ((def_grow_size <= grow_size + left_free)\n          && (left_free < def_grow_size))\n        grow_size = def_grow_size - left_free;  /* Use precise 'def_grow_size' for new free space */\n      else if (! required)\n        return false;                           /* Grow is not mandatory, leave some space in pool */\n      else\n      {\n        /* Shortage of space, but grow is mandatory */\n        const size_t small_inc =\n          ((MHD_BUF_INC_SIZE > def_grow_size) ?\n           def_grow_size : MHD_BUF_INC_SIZE) / 8;\n        if (small_inc < avail_size)\n          grow_size = small_inc;\n        else\n          grow_size = avail_size;\n      }\n    }\n    new_size = connection->read_buffer_size + grow_size;\n  }\n  /* Make sure that read buffer will not be moved */\n  if ((NULL != connection->read_buffer) &&\n      ! MHD_pool_is_resizable_inplace (connection->pool,\n                                       connection->read_buffer,\n                                       connection->read_buffer_size))\n  {\n    mhd_assert (0);\n    return false;\n  }\n  /* we can actually grow the buffer, do it! */\n  rb = MHD_pool_reallocate (connection->pool,\n                            connection->read_buffer,\n                            connection->read_buffer_size,\n                            new_size);\n  if (NULL == rb)\n  {\n    /* This should NOT be possible: we just computed 'new_size' so that\n       it should fit. If it happens, somehow our read buffer is not in\n       the right position in the pool, say because someone called\n       MHD_pool_allocate() without 'from_end' set to 'true'? Anyway,\n       should be investigated! (Ideally provide all data from\n       *pool and connection->read_buffer and new_size for debugging). */\n    mhd_assert (0);\n    return false;\n  }\n  mhd_assert (connection->read_buffer == rb);\n  connection->read_buffer = rb;\n  mhd_assert (NULL != connection->read_buffer);\n  connection->read_buffer_size = new_size;\n  return true;\n}\n...\nstatic size_t\nconnection_maximize_write_buffer (struct MHD_Connection *connection)\n{\n  struct MHD_Connection *const c = connection; /**< a short alias */\n  struct MemoryPool *const pool = connection->pool;\n  void *new_buf;\n  size_t new_size;\n  size_t free_size;\n\n  mhd_assert ((NULL != c->write_buffer) || (0 == c->write_buffer_size));\n  mhd_assert (c->write_buffer_append_offset >= c->write_buffer_send_offset);\n  mhd_assert (c->write_buffer_size >= c->write_buffer_append_offset);\n\n  free_size = MHD_pool_get_free (pool);\n  if (0 != free_size)\n  {\n    new_size = c->write_buffer_size + free_size;\n    /* This function must not move the buffer position.\n     * MHD_pool_reallocate () may return the new position only if buffer was\n     * allocated 'from_end' or is not the last allocation,\n     * which should not happen. */\n    mhd_assert ((NULL == c->write_buffer) || \\\n                MHD_pool_is_resizable_inplace (pool, c->write_buffer, \\\n                                               c->write_buffer_size));\n    new_buf = MHD_pool_reallocate (pool,\n                                   c->write_buffer,\n                                   c->write_buffer_size,\n                                   new_size);\n    mhd_assert ((c->write_buffer == new_buf) || (NULL == c->write_buffer));\n    c->write_buffer = new_buf;\n    c->write_buffer_size = new_size;\n    if (c->write_buffer_send_offset == c->write_buffer_append_offset)\n    {\n      /* All data have been sent, reset offsets to zero. */\n      c->write_buffer_send_offset = 0;\n      c->write_buffer_append_offset = 0;\n    }\n  }\n\n  return c->write_buffer_size - c->write_buffer_append_offset;\n}\n...\nvoid\nMHD_connection_handle_read (struct MHD_Connection *connection,\n                            bool socket_error)\n{\n  ssize_t bytes_read;\n\n  if ( (MHD_CONNECTION_CLOSED == connection->state) ||\n       (connection->suspended) )\n    return;\n#ifdef HTTPS_SUPPORT\n  if (MHD_TLS_CONN_NO_TLS != connection->tls_state)\n  {   /* HTTPS connection. */\n    if (MHD_TLS_CONN_CONNECTED > connection->tls_state)\n    {\n      if (! MHD_run_tls_handshake_ (connection))\n        return;\n    }\n  }\n#endif /* HTTPS_SUPPORT */\n\n  mhd_assert (NULL != connection->read_buffer);\n  if (connection->read_buffer_size == connection->read_buffer_offset)\n    return; /* No space for receiving data. */\n\n  bytes_read = connection->recv_cls (connection,\n                                     &connection->read_buffer\n                                     [connection->read_buffer_offset],\n                                     connection->read_buffer_size\n                                     - connection->read_buffer_offset);\n  if ((bytes_read < 0) || socket_error)\n  {\n    if ((MHD_ERR_AGAIN_ == bytes_read) && ! socket_error)\n      return;     /* No new data to process. */\n    if ((bytes_read > 0) && connection->sk_nonblck)\n    { /* Try to detect the socket error */\n      int dummy;\n      bytes_read = connection->recv_cls (connection, &dummy, sizeof (dummy));\n    }\n    if (MHD_ERR_CONNRESET_ == bytes_read)\n    {\n      if ( (MHD_CONNECTION_INIT < connection->state) &&\n           (MHD_CONNECTION_FULL_REQ_RECEIVED > connection->state) )\n      {\n#ifdef HAVE_MESSAGES\n        MHD_DLOG (connection->daemon,\n                  _ (\"Socket has been disconnected when reading request.\\n\"));\n#endif\n        connection->discard_request = true;\n      }\n      MHD_connection_close_ (connection,\n                             MHD_REQUEST_TERMINATED_READ_ERROR);\n      return;\n    }\n\n#ifdef HAVE_MESSAGES\n    if (MHD_CONNECTION_INIT != connection->state)\n      MHD_DLOG (connection->daemon,\n                _ (\"Connection socket is closed when reading \" \\\n                   \"request due to the error: %s\\n\"),\n                (bytes_read < 0) ? str_conn_error_ (bytes_read) :\n                \"detected connection closure\");\n#endif\n    CONNECTION_CLOSE_ERROR (connection,\n                            NULL);\n    return;\n  }\n\n  if (0 == bytes_read)\n  {   /* Remote side closed connection. */\n    connection->read_closed = true;\n    if ( (MHD_CONNECTION_INIT < connection->state) &&\n         (MHD_CONNECTION_FULL_REQ_RECEIVED > connection->state) )\n    {\n#ifdef HAVE_MESSAGES\n      MHD_DLOG (connection->daemon,\n                _ (\"Connection was closed by remote side with incomplete \"\n                   \"request.\\n\"));\n#endif\n      connection->discard_request = true;\n      MHD_connection_close_ (connection,\n                             MHD_REQUEST_TERMINATED_CLIENT_ABORT);\n    }\n    else if (MHD_CONNECTION_INIT == connection->state)\n      /* This termination code cannot be reported to the application\n       * because application has not been informed yet about this request */\n      MHD_connection_close_ (connection,\n                             MHD_REQUEST_TERMINATED_COMPLETED_OK);\n    else\n      MHD_connection_close_ (connection,\n                             MHD_REQUEST_TERMINATED_WITH_ERROR);\n    return;\n  }\n  connection->read_buffer_offset += (size_t) bytes_read;\n  MHD_update_last_activity_ (connection);\n#if DEBUG_STATES\n  MHD_DLOG (connection->daemon,\n            _ (\"In function %s handling connection at state: %s\\n\"),\n            MHD_FUNC_,\n            MHD_state_to_string (connection->state));\n#endif\n  /* TODO: check whether the next 'switch()' really needed */\n  switch (connection->state)\n  {\n  case MHD_CONNECTION_INIT:\n  case MHD_CONNECTION_REQ_LINE_RECEIVING:\n  case MHD_CONNECTION_REQ_HEADERS_RECEIVING:\n  case MHD_CONNECTION_BODY_RECEIVING:\n  case MHD_CONNECTION_FOOTERS_RECEIVING:\n  case MHD_CONNECTION_FULL_REQ_RECEIVED:\n    /* nothing to do but default action */\n    if (connection->read_closed)\n    {\n      /* TODO: check whether this really needed */\n      MHD_connection_close_ (connection,\n                             MHD_REQUEST_TERMINATED_READ_ERROR);\n    }\n    return;\n  case MHD_CONNECTION_CLOSED:\n    return;\n#ifdef UPGRADE_SUPPORT\n  case MHD_CONNECTION_UPGRADE:\n    mhd_assert (0);\n    return;\n#endif /* UPGRADE_SUPPORT */\n  case MHD_CONNECTION_START_REPLY:\n    /* shrink read buffer to how much is actually used */\n    /* TODO: remove shrink as it handled in special function */\n    if ((0 != connection->read_buffer_size) &&\n        (connection->read_buffer_size != connection->read_buffer_offset))\n    {\n      mhd_assert (NULL != connection->read_buffer);\n      connection->read_buffer =\n        MHD_pool_reallocate (connection->pool,\n                             connection->read_buffer,\n                             connection->read_buffer_size,\n                             connection->read_buffer_offset);\n      connection->read_buffer_size = connection->read_buffer_offset;\n    }\n    break;\n  case MHD_CONNECTION_REQ_LINE_RECEIVED:\n  case MHD_CONNECTION_HEADERS_RECEIVED:\n  case MHD_CONNECTION_HEADERS_PROCESSED:\n  case MHD_CONNECTION_BODY_RECEIVED:\n  case MHD_CONNECTION_FOOTERS_RECEIVED:\n    /* Milestone state, no data should be read */\n    mhd_assert (0); /* Should not be possible */\n    break;\n  case MHD_CONNECTION_CONTINUE_SENDING:\n  case MHD_CONNECTION_HEADERS_SENDING:\n  case MHD_CONNECTION_HEADERS_SENT:\n  case MHD_CONNECTION_NORMAL_BODY_UNREADY:\n  case MHD_CONNECTION_NORMAL_BODY_READY:\n  case MHD_CONNECTION_CHUNKED_BODY_UNREADY:\n  case MHD_CONNECTION_CHUNKED_BODY_READY:\n  case MHD_CONNECTION_CHUNKED_BODY_SENT:\n  case MHD_CONNECTION_FOOTERS_SENDING:\n  case MHD_CONNECTION_FULL_REPLY_SENT:\n  default:\n    mhd_assert (0); /* Should not be possible */\n    break;\n  }\n  return;\n}\n...\nstatic enum MHD_Result\ntry_ready_chunked_body (struct MHD_Connection *connection,\n                        bool *p_finished)\n{\n  ssize_t ret;\n  struct MHD_Response *response;\n  static const size_t max_chunk = 0xFFFFFF;\n  char chunk_hdr[6];            /* 6: max strlen of \"FFFFFF\" */\n  /* \"FFFFFF\" + \"\\r\\n\" */\n  static const size_t max_chunk_hdr_len = sizeof(chunk_hdr) + 2;\n  /* \"FFFFFF\" + \"\\r\\n\" + \"\\r\\n\" (chunk termination) */\n  static const size_t max_chunk_overhead = sizeof(chunk_hdr) + 2 + 2;\n  size_t chunk_hdr_len;\n  uint64_t left_to_send;\n  size_t size_to_fill;\n\n  response = connection->rp.response;\n  mhd_assert (NULL != response->crc || NULL != response->data);\n\n  mhd_assert (0 == connection->write_buffer_append_offset);\n\n  /* The buffer must be reasonably large enough */\n  if (128 > connection->write_buffer_size)\n  {\n    size_t size;\n\n    size = connection->write_buffer_size + MHD_pool_get_free (connection->pool);\n    if (128 > size)\n    {\n#if defined(MHD_USE_POSIX_THREADS) || defined(MHD_USE_W32_THREADS)\n      MHD_mutex_unlock_chk_ (&response->mutex);\n#endif\n      /* not enough memory */\n      CONNECTION_CLOSE_ERROR (connection,\n                              _ (\"Closing connection (out of memory).\"));\n      return MHD_NO;\n    }\n    /* Limit the buffer size to the largest usable size for chunks */\n    if ( (max_chunk + max_chunk_overhead) < size)\n      size = max_chunk + max_chunk_overhead;\n    mhd_assert ((NULL == connection->write_buffer) || \\\n                MHD_pool_is_resizable_inplace (connection->pool, \\\n                                               connection->write_buffer, \\\n                                               connection->write_buffer_size));\n    connection->write_buffer =\n      MHD_pool_reallocate (connection->pool,\n                           connection->write_buffer,\n                           connection->write_buffer_size,\n                           size);\n    mhd_assert (NULL != connection->write_buffer);\n    connection->write_buffer_size = size;\n  }\n  mhd_assert (max_chunk_overhead < connection->write_buffer_size);\n\n  if (MHD_SIZE_UNKNOWN == response->total_size)\n    left_to_send = MHD_SIZE_UNKNOWN;\n  else\n    left_to_send = response->total_size\n                   - connection->rp.rsp_write_position;\n\n  size_to_fill = connection->write_buffer_size - max_chunk_overhead;\n  /* Limit size for the callback to the max usable size */\n  if (max_chunk < size_to_fill)\n    size_to_fill = max_chunk;\n  if (left_to_send < size_to_fill)\n    size_to_fill = (size_t) left_to_send;\n\n  if (0 == left_to_send)\n    /* nothing to send, don't bother calling crc */\n    ret = MHD_CONTENT_READER_END_OF_STREAM;\n  else if ( (response->data_start <=\n             connection->rp.rsp_write_position) &&\n            (response->data_start + response->data_size >\n             connection->rp.rsp_write_position) )\n  {\n    /* difference between rsp_write_position and data_start is less\n       than data_size which is size_t type, no need to check for overflow */\n    const size_t data_write_offset\n      = (size_t) (connection->rp.rsp_write_position\n                  - response->data_start);\n    /* buffer already ready, use what is there for the chunk */\n    mhd_assert (SSIZE_MAX >= (response->data_size - data_write_offset));\n    mhd_assert (response->data_size >= data_write_offset);\n    ret = (ssize_t) (response->data_size - data_write_offset);\n    if ( ((size_t) ret) > size_to_fill)\n      ret = (ssize_t) size_to_fill;\n    memcpy (&connection->write_buffer[max_chunk_hdr_len],\n            &response->data[data_write_offset],\n            (size_t) ret);\n  }\n  else\n  {\n    if (NULL == response->crc)\n    { /* There is no way to reach this code */\n#if defined(MHD_USE_THREADS)\n      MHD_mutex_unlock_chk_ (&response->mutex);\n#endif\n      CONNECTION_CLOSE_ERROR (connection,\n                              _ (\"No callback for the chunked data.\"));\n      return MHD_NO;\n    }\n    ret = response->crc (response->crc_cls,\n                         connection->rp.rsp_write_position,\n                         &connection->write_buffer[max_chunk_hdr_len],\n                         size_to_fill);\n  }\n  if (MHD_CONTENT_READER_END_WITH_ERROR == ret)\n  {\n    /* error, close socket! */\n    /* TODO: remove update of the response size */\n    response->total_size = connection->rp.rsp_write_position;\n#if defined(MHD_USE_POSIX_THREADS) || defined(MHD_USE_W32_THREADS)\n    MHD_mutex_unlock_chk_ (&response->mutex);\n#endif\n    CONNECTION_CLOSE_ERROR (connection,\n                            _ (\"Closing connection (application error \" \\\n                               \"generating response).\"));\n    return MHD_NO;\n  }\n  if (MHD_CONTENT_READER_END_OF_STREAM == ret)\n  {\n    *p_finished = true;\n    /* TODO: remove update of the response size */\n    response->total_size = connection->rp.rsp_write_position;\n    return MHD_YES;\n  }\n  if (0 == ret)\n  {\n    connection->state = MHD_CONNECTION_CHUNKED_BODY_UNREADY;\n#if defined(MHD_USE_POSIX_THREADS) || defined(MHD_USE_W32_THREADS)\n    MHD_mutex_unlock_chk_ (&response->mutex);\n#endif\n    return MHD_NO;\n  }\n  if (size_to_fill < (size_t) ret)\n  {\n#if defined(MHD_USE_THREADS)\n    MHD_mutex_unlock_chk_ (&response->mutex);\n#endif\n    CONNECTION_CLOSE_ERROR (connection,\n                            _ (\"Closing connection (application returned \" \\\n                               \"more data than requested).\"));\n    return MHD_NO;\n  }\n  chunk_hdr_len = MHD_uint32_to_strx ((uint32_t) ret, chunk_hdr,\n                                      sizeof(chunk_hdr));\n  mhd_assert (chunk_hdr_len != 0);\n  mhd_assert (chunk_hdr_len < sizeof(chunk_hdr));\n  *p_finished = false;\n  connection->write_buffer_send_offset =\n    (max_chunk_hdr_len - (chunk_hdr_len + 2));\n  memcpy (connection->write_buffer + connection->write_buffer_send_offset,\n          chunk_hdr,\n          chunk_hdr_len);\n  connection->write_buffer[max_chunk_hdr_len - 2] = '\\r';\n  connection->write_buffer[max_chunk_hdr_len - 1] = '\\n';\n  connection->write_buffer[max_chunk_hdr_len + (size_t) ret] = '\\r';\n  connection->write_buffer[max_chunk_hdr_len + (size_t) ret + 1] = '\\n';\n  connection->rp.rsp_write_position += (size_t) ret;\n  connection->write_buffer_append_offset = max_chunk_hdr_len + (size_t) ret + 2;\n  return MHD_YES;\n}\n</additional code>\n<target_code>\nHere is the code fragment that you need to analyze:\n```c\nif (NULL == response->crc)\n{ /* There is no way to reach this code */\n#if defined(MHD_USE_THREADS)\n      MHD_mutex_unlock_chk_ (&response->mutex);\n#endif\n      CONNECTION_CLOSE_ERROR (connection,\n                              _ (\"No callback for the chunked data.\"));\n      return MHD_NO;\n}\n```\nFocus on the above code fragment and judge whether it violates the rule 2.1 or not.\n</target_code>\n",
  "is_rule_violated": false,
  "scenario": "The comment says \"There is no way to reach this code\", but the code is reachable at run-time: mhd_assert(NULL != response->crc || NULL != response->data) is defined as ((void)0) and has no effect, so if response->data does not cover the current position and response->crc == NULL, the branch executes and returns MHD_NO. Therefore the fragment is not unreachable."
}