{
  "user_message": "<misra_rule>\nThe target MISRA C 2023 Rule 17.2 is: Functions shall not call themselves, either directly or indirectly.\n\n</misra_rule>\n<instruction>\nOther agents will judge whether the code follows the MISRA C 2023 guidelines.\nThey will investigate the code fragments you give.\nYour job is to find code fragments in the code that should be investigated to check whether the code follows the MISRA C rule.\n</instruction>\n<response format>\nProvide your answer with these fields.\n- suspicious_frags: The list of suspicious code fragments in the code.\nIt should contain only the code fragments exists in the code. If you do not find any suspicious code fragments, return an empty list for suspicious_frags\n- explanation: The explanation of why other code fragments should NOT be investigated.\nIt is very important to not miss any suspicious code fragments, so please give a sufficient explanation why other code fragments should not be investigated.\nDO NOT give any explanation for the selected suspicious code fragments.\n</response format>\n<target_code>\nHere is the code of connection_shrink_read_buffer:\n```c\nstatic void\nconnection_shrink_read_buffer (struct MHD_Connection *connection)\n{\n  struct MHD_Connection *const c = connection; /**< a short alias */\n  void *new_buf;\n\n  if ((NULL == c->read_buffer) || (0 == c->read_buffer_size))\n  {\n    mhd_assert (0 == c->read_buffer_size);\n    mhd_assert (0 == c->read_buffer_offset);\n    return;\n  }\n\n  mhd_assert (c->read_buffer_offset <= c->read_buffer_size);\n  if (0 == c->read_buffer_offset)\n  {\n    MHD_pool_deallocate (c->pool, c->read_buffer, c->read_buffer_size);\n    c->read_buffer = NULL;\n    c->read_buffer_size = 0;\n  }\n  else\n  {\n    mhd_assert (MHD_pool_is_resizable_inplace (c->pool, c->read_buffer, \\\n                                               c->read_buffer_size));\n    new_buf = MHD_pool_reallocate (c->pool, c->read_buffer, c->read_buffer_size,\n                                   c->read_buffer_offset);\n    mhd_assert (c->read_buffer == new_buf);\n    c->read_buffer = new_buf;\n    c->read_buffer_size = c->read_buffer_offset;\n  }\n}\n```\n</target_code>\n<additional code>Here are the definitions of symbols that are related to the target function connection_shrink_read_buffer:\nvoid\nMHD_pool_deallocate (struct MemoryPool *pool,\n                     void *block,\n                     size_t block_size)\n{\n  mhd_assert (pool->end >= pool->pos);\n  mhd_assert (pool->size >= pool->end - pool->pos);\n  mhd_assert (block != NULL || block_size == 0);\n  mhd_assert (pool->size >= block_size);\n  mhd_assert (pool->pos == ROUND_TO_ALIGN (pool->pos));\n\n  if (NULL != block)\n  {   /* Have previously allocated data */\n    const size_t block_offset = mp_ptr_diff_ (block, pool->memory);\n    mhd_assert (mp_ptr_le_ (pool->memory, block));\n    mhd_assert (block_offset <= pool->size);\n    mhd_assert ((block_offset != pool->pos) || (block_size == 0));\n    /* Zero-out deallocated region */\n    if (0 != block_size)\n    {\n      memset (block, 0, block_size);\n      _MHD_POISON_MEMORY (block, block_size);\n    }\n#if ! defined(MHD_FAVOR_SMALL_CODE) && ! defined(MHD_ASAN_POISON_ACTIVE)\n    else\n      return; /* Zero size, no need to do anything */\n#endif /* ! MHD_FAVOR_SMALL_CODE && ! MHD_ASAN_POISON_ACTIVE */\n    if (block_offset <= pool->pos)\n    {\n      /* \"Normal\" block, not allocated \"from the end\". */\n      const size_t alg_end =\n        ROUND_TO_ALIGN_PLUS_RED_ZONE (block_offset + block_size);\n      mhd_assert (alg_end <= pool->pos);\n      if (alg_end == pool->pos)\n      {\n        /* The last allocated block, return deallocated block to the pool */\n        size_t alg_start = ROUND_TO_ALIGN (block_offset);\n        mhd_assert (alg_start >= block_offset);\n#if defined(MHD_ASAN_POISON_ACTIVE)\n        if (alg_start != block_offset)\n        {\n          _MHD_POISON_MEMORY (pool->memory + block_offset, \\\n                              alg_start - block_offset);\n        }\n        else if (0 != alg_start)\n        {\n          bool need_red_zone_before;\n          mhd_assert (_MHD_RED_ZONE_SIZE <= alg_start);\n#if defined(HAVE___ASAN_REGION_IS_POISONED)\n          need_red_zone_before =\n            (NULL == __asan_region_is_poisoned (pool->memory\n                                                + alg_start\n                                                - _MHD_RED_ZONE_SIZE,\n                                                _MHD_RED_ZONE_SIZE));\n#elif defined(HAVE___ASAN_ADDRESS_IS_POISONED)\n          need_red_zone_before =\n            (0 == __asan_address_is_poisoned (pool->memory + alg_start - 1));\n#else  /* ! HAVE___ASAN_ADDRESS_IS_POISONED */\n          need_red_zone_before = true; /* Unknown, assume new red zone needed */\n#endif /* ! HAVE___ASAN_ADDRESS_IS_POISONED */\n          if (need_red_zone_before)\n          {\n            _MHD_POISON_MEMORY (pool->memory + alg_start, _MHD_RED_ZONE_SIZE);\n            alg_start += _MHD_RED_ZONE_SIZE;\n          }\n        }\n#endif /* MHD_ASAN_POISON_ACTIVE */\n        mhd_assert (alg_start <= pool->pos);\n        mhd_assert (alg_start == ROUND_TO_ALIGN (alg_start));\n        pool->pos = alg_start;\n      }\n    }\n    else\n    {\n      /* Allocated \"from the end\" block. */\n      /* The size and the pointers of such block should not be manipulated by\n         MHD code (block split is disallowed). */\n      mhd_assert (block_offset >= pool->end);\n      mhd_assert (ROUND_TO_ALIGN (block_offset) == block_offset);\n      if (block_offset == pool->end)\n      {\n        /* The last allocated block, return deallocated block to the pool */\n        const size_t alg_end =\n          ROUND_TO_ALIGN_PLUS_RED_ZONE (block_offset + block_size);\n        pool->end = alg_end;\n      }\n    }\n  }\n}\n...\nvoid *\nMHD_pool_reallocate (struct MemoryPool *pool,\n                     void *old,\n                     size_t old_size,\n                     size_t new_size)\n{\n  size_t asize;\n  uint8_t *new_blc;\n\n  mhd_assert (pool->end >= pool->pos);\n  mhd_assert (pool->size >= pool->end - pool->pos);\n  mhd_assert (old != NULL || old_size == 0);\n  mhd_assert (pool->size >= old_size);\n  mhd_assert (pool->pos == ROUND_TO_ALIGN (pool->pos));\n#if defined(MHD_ASAN_POISON_ACTIVE) && defined(HAVE___ASAN_REGION_IS_POISONED)\n  mhd_assert (NULL == __asan_region_is_poisoned (old, old_size));\n#endif /* MHD_ASAN_POISON_ACTIVE && HAVE___ASAN_REGION_IS_POISONED */\n\n  if (NULL != old)\n  {   /* Have previously allocated data */\n    const size_t old_offset = mp_ptr_diff_ (old, pool->memory);\n    const bool shrinking = (old_size > new_size);\n\n    mhd_assert (mp_ptr_le_ (pool->memory, old));\n    /* (pool->memory + pool->size >= (uint8_t*) old + old_size) */\n    mhd_assert ((pool->size - _MHD_RED_ZONE_SIZE) >= (old_offset + old_size));\n    /* Blocks \"from the end\" must not be reallocated */\n    /* (old_size == 0 || pool->memory + pool->pos > (uint8_t*) old) */\n    mhd_assert ((old_size == 0) || \\\n                (pool->pos > old_offset));\n    mhd_assert ((old_size == 0) || \\\n                ((pool->end - _MHD_RED_ZONE_SIZE) >= (old_offset + old_size)));\n    /* Try resizing in-place */\n    if (shrinking)\n    {     /* Shrinking in-place, zero-out freed part */\n      memset ((uint8_t *) old + new_size, 0, old_size - new_size);\n      _MHD_POISON_MEMORY ((uint8_t *) old + new_size, old_size - new_size);\n    }\n    if (pool->pos ==\n        ROUND_TO_ALIGN_PLUS_RED_ZONE (old_offset + old_size))\n    {     /* \"old\" block is the last allocated block */\n      const size_t new_apos =\n        ROUND_TO_ALIGN_PLUS_RED_ZONE (old_offset + new_size);\n      if (! shrinking)\n      {                               /* Grow in-place, check for enough space. */\n        if ( (new_apos > pool->end) ||\n             (new_apos < pool->pos) ) /* Value wrap */\n          return NULL;                /* No space */\n      }\n      /* Resized in-place */\n      pool->pos = new_apos;\n      _MHD_UNPOISON_MEMORY (old, new_size);\n      return old;\n    }\n    if (shrinking)\n      return old;   /* Resized in-place, freed part remains allocated */\n  }\n  /* Need to allocate new block */\n  asize = ROUND_TO_ALIGN_PLUS_RED_ZONE (new_size);\n  if ( ( (0 == asize) &&\n         (0 != new_size) ) || /* Value wrap, too large new_size. */\n       (asize > pool->end - pool->pos) ) /* Not enough space */\n    return NULL;\n\n  new_blc = pool->memory + pool->pos;\n  pool->pos += asize;\n\n  _MHD_UNPOISON_MEMORY (new_blc, new_size);\n  if (0 != old_size)\n  {\n    /* Move data to new block, old block remains allocated */\n    memcpy (new_blc, old, old_size);\n    /* Zero-out old block */\n    memset (old, 0, old_size);\n    _MHD_POISON_MEMORY (old, old_size);\n  }\n  return new_blc;\n}\n...\nbool\nMHD_pool_is_resizable_inplace (struct MemoryPool *pool,\n                               void *block,\n                               size_t block_size)\n{\n  mhd_assert (pool->end >= pool->pos);\n  mhd_assert (pool->size >= pool->end - pool->pos);\n  mhd_assert (block != NULL || block_size == 0);\n  mhd_assert (pool->size >= block_size);\n  if (NULL != block)\n  {\n    const size_t block_offset = mp_ptr_diff_ (block, pool->memory);\n    mhd_assert (mp_ptr_le_ (pool->memory, block));\n    mhd_assert (pool->size >= block_offset);\n    mhd_assert (pool->size >= block_offset + block_size);\n    return (pool->pos ==\n            ROUND_TO_ALIGN_PLUS_RED_ZONE (block_offset + block_size));\n  }\n  return false; /* Unallocated blocks cannot be resized in-place */\n}\n...\n#define mhd_assert(ignore) ((void)0)\n</additional code>\nPlease find suspicious code fragments in the code and report them. Other agents can not investigate other fragments that you do not report, so it is very important to find all suspicious fragments without missing any. Report the suspicious fragments AS MUCH AS POSSIBLE.",
  "suspicious_frags": [],
  "explanation": "No direct or indirect recursive calls are present in the provided code. The function connection_shrink_read_buffer only calls these functions: MHD_pool_deallocate, MHD_pool_is_resizable_inplace and MHD_pool_reallocate. The supplied definitions of those three functions do not call connection_shrink_read_buffer (or any other function that calls it), so there is no direct or indirect recursion in the shown call chain. There are no function pointers or callback parameters passed from connection_shrink_read_buffer into the pool functions that could cause a callback into connection_shrink_read_buffer, and the mhd_assert macro is defined as a no-op, so it cannot introduce a call. Therefore no code fragments in the provided snippets require investigation for Rule 17.2."
}