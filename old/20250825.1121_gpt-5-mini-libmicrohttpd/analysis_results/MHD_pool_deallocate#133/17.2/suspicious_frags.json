{
  "user_message": "<misra_rule>\nThe target MISRA C 2023 Rule 17.2 is: Functions shall not call themselves, either directly or indirectly.\n\n</misra_rule>\n<instruction>\nOther agents will judge whether the code follows the MISRA C 2023 guidelines.\nThey will investigate the code fragments you give.\nYour job is to find code fragments in the code that should be investigated to check whether the code follows the MISRA C rule.\n</instruction>\n<response format>\nProvide your answer with these fields.\n- suspicious_frags: The list of suspicious code fragments in the code.\nIt should contain only the code fragments exists in the code. If you do not find any suspicious code fragments, return an empty list for suspicious_frags\n- explanation: The explanation of why other code fragments should NOT be investigated.\nIt is very important to not miss any suspicious code fragments, so please give a sufficient explanation why other code fragments should not be investigated.\nDO NOT give any explanation for the selected suspicious code fragments.\n</response format>\n<target_code>\nHere is the code of MHD_pool_deallocate:\n```c\nvoid\nMHD_pool_deallocate (struct MemoryPool *pool,\n                     void *block,\n                     size_t block_size)\n{\n  mhd_assert (pool->end >= pool->pos);\n  mhd_assert (pool->size >= pool->end - pool->pos);\n  mhd_assert (block != NULL || block_size == 0);\n  mhd_assert (pool->size >= block_size);\n  mhd_assert (pool->pos == ROUND_TO_ALIGN (pool->pos));\n\n  if (NULL != block)\n  {   /* Have previously allocated data */\n    const size_t block_offset = mp_ptr_diff_ (block, pool->memory);\n    mhd_assert (mp_ptr_le_ (pool->memory, block));\n    mhd_assert (block_offset <= pool->size);\n    mhd_assert ((block_offset != pool->pos) || (block_size == 0));\n    /* Zero-out deallocated region */\n    if (0 != block_size)\n    {\n      memset (block, 0, block_size);\n      _MHD_POISON_MEMORY (block, block_size);\n    }\n#if ! defined(MHD_FAVOR_SMALL_CODE) && ! defined(MHD_ASAN_POISON_ACTIVE)\n    else\n      return; /* Zero size, no need to do anything */\n#endif /* ! MHD_FAVOR_SMALL_CODE && ! MHD_ASAN_POISON_ACTIVE */\n    if (block_offset <= pool->pos)\n    {\n      /* \"Normal\" block, not allocated \"from the end\". */\n      const size_t alg_end =\n        ROUND_TO_ALIGN_PLUS_RED_ZONE (block_offset + block_size);\n      mhd_assert (alg_end <= pool->pos);\n      if (alg_end == pool->pos)\n      {\n        /* The last allocated block, return deallocated block to the pool */\n        size_t alg_start = ROUND_TO_ALIGN (block_offset);\n        mhd_assert (alg_start >= block_offset);\n#if defined(MHD_ASAN_POISON_ACTIVE)\n        if (alg_start != block_offset)\n        {\n          _MHD_POISON_MEMORY (pool->memory + block_offset, \\\n                              alg_start - block_offset);\n        }\n        else if (0 != alg_start)\n        {\n          bool need_red_zone_before;\n          mhd_assert (_MHD_RED_ZONE_SIZE <= alg_start);\n#if defined(HAVE___ASAN_REGION_IS_POISONED)\n          need_red_zone_before =\n            (NULL == __asan_region_is_poisoned (pool->memory\n                                                + alg_start\n                                                - _MHD_RED_ZONE_SIZE,\n                                                _MHD_RED_ZONE_SIZE));\n#elif defined(HAVE___ASAN_ADDRESS_IS_POISONED)\n          need_red_zone_before =\n            (0 == __asan_address_is_poisoned (pool->memory + alg_start - 1));\n#else  /* ! HAVE___ASAN_ADDRESS_IS_POISONED */\n          need_red_zone_before = true; /* Unknown, assume new red zone needed */\n#endif /* ! HAVE___ASAN_ADDRESS_IS_POISONED */\n          if (need_red_zone_before)\n          {\n            _MHD_POISON_MEMORY (pool->memory + alg_start, _MHD_RED_ZONE_SIZE);\n            alg_start += _MHD_RED_ZONE_SIZE;\n          }\n        }\n#endif /* MHD_ASAN_POISON_ACTIVE */\n        mhd_assert (alg_start <= pool->pos);\n        mhd_assert (alg_start == ROUND_TO_ALIGN (alg_start));\n        pool->pos = alg_start;\n      }\n    }\n    else\n    {\n      /* Allocated \"from the end\" block. */\n      /* The size and the pointers of such block should not be manipulated by\n         MHD code (block split is disallowed). */\n      mhd_assert (block_offset >= pool->end);\n      mhd_assert (ROUND_TO_ALIGN (block_offset) == block_offset);\n      if (block_offset == pool->end)\n      {\n        /* The last allocated block, return deallocated block to the pool */\n        const size_t alg_end =\n          ROUND_TO_ALIGN_PLUS_RED_ZONE (block_offset + block_size);\n        pool->end = alg_end;\n      }\n    }\n  }\n}\n```\n</target_code>\n<additional code>Here are the definitions of symbols that are related to the target function MHD_pool_deallocate:\n#define _MHD_POISON_MEMORY(pointer, size) (void)0\n</additional code>\nPlease find suspicious code fragments in the code and report them. Other agents can not investigate other fragments that you do not report, so it is very important to find all suspicious fragments without missing any. Report the suspicious fragments AS MUCH AS POSSIBLE.",
  "suspicious_frags": [
    "const size_t alg_end = ROUND_TO_ALIGN_PLUS_RED_ZONE (block_offset + block_size);",
    "mhd_assert (block_offset <= pool->size);",
    "mhd_assert (alg_start >= block_offset);",
    "mhd_assert (ROUND_TO_ALIGN (block_offset) == block_offset);",
    "mhd_assert (pool->pos == ROUND_TO_ALIGN (pool->pos));",
    "mhd_assert (block_offset >= pool->end);",
    "mhd_assert (mp_ptr_le_ (pool->memory, block));",
    "mhd_assert (pool->size >= block_size);",
    "mhd_assert ((block_offset != pool->pos) || (block_size == 0));",
    "size_t alg_start = ROUND_TO_ALIGN (block_offset);",
    "const size_t alg_end =\n          ROUND_TO_ALIGN_PLUS_RED_ZONE (block_offset + block_size);",
    "const size_t block_offset = mp_ptr_diff_ (block, pool->memory);",
    "mhd_assert (pool->end >= pool->pos);",
    "memset (block, 0, block_size);",
    "mhd_assert (alg_start <= pool->pos);",
    "#endif /* ! HAVE___ASAN_ADDRESS_IS_POISONED */",
    "mhd_assert (pool->size >= pool->end - pool->pos);",
    "#if defined(HAVE___ASAN_REGION_IS_POISONED)\n          need_red_zone_before =\n            (NULL == __asan_region_is_poisoned (pool->memory\n                                                + alg_start\n                                                - _MHD_RED_ZONE_SIZE,\n                                                _MHD_RED_ZONE_SIZE));",
    "mhd_assert (alg_end <= pool->pos);",
    "mhd_assert (alg_start == ROUND_TO_ALIGN (alg_start));",
    "#elif defined(HAVE___ASAN_ADDRESS_IS_POISONED)\n          need_red_zone_before =\n            (0 == __asan_address_is_poisoned (pool->memory + alg_start - 1));",
    "mhd_assert (block != NULL || block_size == 0);"
  ],
  "explanation": "I selected all locations that perform calls (or invoke function-like macros) from inside MHD_pool_deallocate because any of these could (in principle) be implemented so that they call back into MHD_pool_deallocate and create direct or indirect recursion. These include: all mhd_assert usages (macro/inline), the pointer helper functions/macros mp_ptr_diff_ and mp_ptr_le_, the ROUND_TO_ALIGN and ROUND_TO_ALIGN_PLUS_RED_ZONE uses, the memset call, and the AddressSanitizer query functions (__asan_region_is_poisoned, __asan_address_is_poisoned). I did not include uses of _MHD_POISON_MEMORY because you provided its definition as #define _MHD_POISON_MEMORY(pointer, size) (void)0, so that macro is a no-op and cannot cause a call back into the function. I also did not list simple non-call fragments (assignments, pointer arithmetic, comparisons, control-flow keywords, comments, and return statements) because they do not perform function calls and therefore cannot directly or indirectly invoke MHD_pool_deallocate."
}