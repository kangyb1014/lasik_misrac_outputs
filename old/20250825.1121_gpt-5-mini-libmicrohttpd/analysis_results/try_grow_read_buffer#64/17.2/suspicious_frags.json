{
  "user_message": "<misra_rule>\nThe target MISRA C 2023 Rule 17.2 is: Functions shall not call themselves, either directly or indirectly.\n\n</misra_rule>\n<instruction>\nOther agents will judge whether the code follows the MISRA C 2023 guidelines.\nThey will investigate the code fragments you give.\nYour job is to find code fragments in the code that should be investigated to check whether the code follows the MISRA C rule.\n</instruction>\n<response format>\nProvide your answer with these fields.\n- suspicious_frags: The list of suspicious code fragments in the code.\nIt should contain only the code fragments exists in the code. If you do not find any suspicious code fragments, return an empty list for suspicious_frags\n- explanation: The explanation of why other code fragments should NOT be investigated.\nIt is very important to not miss any suspicious code fragments, so please give a sufficient explanation why other code fragments should not be investigated.\nDO NOT give any explanation for the selected suspicious code fragments.\n</response format>\n<target_code>\nHere is the code of try_grow_read_buffer:\n```c\nstatic bool\ntry_grow_read_buffer (struct MHD_Connection *connection,\n                      bool required)\n{\n  size_t new_size;\n  size_t avail_size;\n  const size_t def_grow_size = connection->daemon->pool_increment;\n  void *rb;\n\n  avail_size = MHD_pool_get_free (connection->pool);\n  if (0 == avail_size)\n    return false;               /* No more space available */\n  if (0 == connection->read_buffer_size)\n    new_size = avail_size / 2;  /* Use half of available buffer for reading */\n  else\n  {\n    size_t grow_size;\n\n    grow_size = avail_size / 8;\n    if (def_grow_size > grow_size)\n    {                  /* Shortage of space */\n      const size_t left_free =\n        connection->read_buffer_size - connection->read_buffer_offset;\n      mhd_assert (connection->read_buffer_size >= \\\n                  connection->read_buffer_offset);\n      if ((def_grow_size <= grow_size + left_free)\n          && (left_free < def_grow_size))\n        grow_size = def_grow_size - left_free;  /* Use precise 'def_grow_size' for new free space */\n      else if (! required)\n        return false;                           /* Grow is not mandatory, leave some space in pool */\n      else\n      {\n        /* Shortage of space, but grow is mandatory */\n        const size_t small_inc =\n          ((MHD_BUF_INC_SIZE > def_grow_size) ?\n           def_grow_size : MHD_BUF_INC_SIZE) / 8;\n        if (small_inc < avail_size)\n          grow_size = small_inc;\n        else\n          grow_size = avail_size;\n      }\n    }\n    new_size = connection->read_buffer_size + grow_size;\n  }\n  /* Make sure that read buffer will not be moved */\n  if ((NULL != connection->read_buffer) &&\n      ! MHD_pool_is_resizable_inplace (connection->pool,\n                                       connection->read_buffer,\n                                       connection->read_buffer_size))\n  {\n    mhd_assert (0);\n    return false;\n  }\n  /* we can actually grow the buffer, do it! */\n  rb = MHD_pool_reallocate (connection->pool,\n                            connection->read_buffer,\n                            connection->read_buffer_size,\n                            new_size);\n  if (NULL == rb)\n  {\n    /* This should NOT be possible: we just computed 'new_size' so that\n       it should fit. If it happens, somehow our read buffer is not in\n       the right position in the pool, say because someone called\n       MHD_pool_allocate() without 'from_end' set to 'true'? Anyway,\n       should be investigated! (Ideally provide all data from\n       *pool and connection->read_buffer and new_size for debugging). */\n    mhd_assert (0);\n    return false;\n  }\n  mhd_assert (connection->read_buffer == rb);\n  connection->read_buffer = rb;\n  mhd_assert (NULL != connection->read_buffer);\n  connection->read_buffer_size = new_size;\n  return true;\n}\n```\n</target_code>\n<additional code>Here are the definitions of symbols that are related to the target function try_grow_read_buffer:\nsize_t\nMHD_pool_get_free (struct MemoryPool *pool)\n{\n  mhd_assert (pool->end >= pool->pos);\n  mhd_assert (pool->size >= pool->end - pool->pos);\n  mhd_assert (pool->pos == ROUND_TO_ALIGN (pool->pos));\n#ifdef MHD_ASAN_POISON_ACTIVE\n  if ((pool->end - pool->pos) <= _MHD_RED_ZONE_SIZE)\n    return 0;\n#endif /* MHD_ASAN_POISON_ACTIVE */\n  return (pool->end - pool->pos) - _MHD_RED_ZONE_SIZE;\n}\n...\nvoid *\nMHD_pool_reallocate (struct MemoryPool *pool,\n                     void *old,\n                     size_t old_size,\n                     size_t new_size)\n{\n  size_t asize;\n  uint8_t *new_blc;\n\n  mhd_assert (pool->end >= pool->pos);\n  mhd_assert (pool->size >= pool->end - pool->pos);\n  mhd_assert (old != NULL || old_size == 0);\n  mhd_assert (pool->size >= old_size);\n  mhd_assert (pool->pos == ROUND_TO_ALIGN (pool->pos));\n#if defined(MHD_ASAN_POISON_ACTIVE) && defined(HAVE___ASAN_REGION_IS_POISONED)\n  mhd_assert (NULL == __asan_region_is_poisoned (old, old_size));\n#endif /* MHD_ASAN_POISON_ACTIVE && HAVE___ASAN_REGION_IS_POISONED */\n\n  if (NULL != old)\n  {   /* Have previously allocated data */\n    const size_t old_offset = mp_ptr_diff_ (old, pool->memory);\n    const bool shrinking = (old_size > new_size);\n\n    mhd_assert (mp_ptr_le_ (pool->memory, old));\n    /* (pool->memory + pool->size >= (uint8_t*) old + old_size) */\n    mhd_assert ((pool->size - _MHD_RED_ZONE_SIZE) >= (old_offset + old_size));\n    /* Blocks \"from the end\" must not be reallocated */\n    /* (old_size == 0 || pool->memory + pool->pos > (uint8_t*) old) */\n    mhd_assert ((old_size == 0) || \\\n                (pool->pos > old_offset));\n    mhd_assert ((old_size == 0) || \\\n                ((pool->end - _MHD_RED_ZONE_SIZE) >= (old_offset + old_size)));\n    /* Try resizing in-place */\n    if (shrinking)\n    {     /* Shrinking in-place, zero-out freed part */\n      memset ((uint8_t *) old + new_size, 0, old_size - new_size);\n      _MHD_POISON_MEMORY ((uint8_t *) old + new_size, old_size - new_size);\n    }\n    if (pool->pos ==\n        ROUND_TO_ALIGN_PLUS_RED_ZONE (old_offset + old_size))\n    {     /* \"old\" block is the last allocated block */\n      const size_t new_apos =\n        ROUND_TO_ALIGN_PLUS_RED_ZONE (old_offset + new_size);\n      if (! shrinking)\n      {                               /* Grow in-place, check for enough space. */\n        if ( (new_apos > pool->end) ||\n             (new_apos < pool->pos) ) /* Value wrap */\n          return NULL;                /* No space */\n      }\n      /* Resized in-place */\n      pool->pos = new_apos;\n      _MHD_UNPOISON_MEMORY (old, new_size);\n      return old;\n    }\n    if (shrinking)\n      return old;   /* Resized in-place, freed part remains allocated */\n  }\n  /* Need to allocate new block */\n  asize = ROUND_TO_ALIGN_PLUS_RED_ZONE (new_size);\n  if ( ( (0 == asize) &&\n         (0 != new_size) ) || /* Value wrap, too large new_size. */\n       (asize > pool->end - pool->pos) ) /* Not enough space */\n    return NULL;\n\n  new_blc = pool->memory + pool->pos;\n  pool->pos += asize;\n\n  _MHD_UNPOISON_MEMORY (new_blc, new_size);\n  if (0 != old_size)\n  {\n    /* Move data to new block, old block remains allocated */\n    memcpy (new_blc, old, old_size);\n    /* Zero-out old block */\n    memset (old, 0, old_size);\n    _MHD_POISON_MEMORY (old, old_size);\n  }\n  return new_blc;\n}\n...\nbool\nMHD_pool_is_resizable_inplace (struct MemoryPool *pool,\n                               void *block,\n                               size_t block_size)\n{\n  mhd_assert (pool->end >= pool->pos);\n  mhd_assert (pool->size >= pool->end - pool->pos);\n  mhd_assert (block != NULL || block_size == 0);\n  mhd_assert (pool->size >= block_size);\n  if (NULL != block)\n  {\n    const size_t block_offset = mp_ptr_diff_ (block, pool->memory);\n    mhd_assert (mp_ptr_le_ (pool->memory, block));\n    mhd_assert (pool->size >= block_offset);\n    mhd_assert (pool->size >= block_offset + block_size);\n    return (pool->pos ==\n            ROUND_TO_ALIGN_PLUS_RED_ZONE (block_offset + block_size));\n  }\n  return false; /* Unallocated blocks cannot be resized in-place */\n}\n...\n#define mhd_assert(ignore) ((void)0)\n...\nstatic bool\ncheck_and_grow_read_buffer_space (struct MHD_Connection *c)\n{\n  /**\n   * The increase of read buffer size is desirable.\n   */\n  bool rbuff_grow_desired;\n  /**\n   * The increase of read buffer size is a hard requirement.\n   */\n  bool rbuff_grow_required;\n\n  mhd_assert (0 != (MHD_EVENT_LOOP_INFO_READ & c->event_loop_info));\n  mhd_assert (! c->discard_request);\n\n  rbuff_grow_required = (c->read_buffer_offset == c->read_buffer_size);\n  if (rbuff_grow_required)\n    rbuff_grow_desired = true;\n  else\n  {\n    rbuff_grow_desired = (c->read_buffer_offset + c->daemon->pool_increment >\n                          c->read_buffer_size);\n\n    if ((rbuff_grow_desired) &&\n        (MHD_CONNECTION_BODY_RECEIVING == c->state))\n    {\n      if (! c->rq.have_chunked_upload)\n      {\n        mhd_assert (MHD_SIZE_UNKNOWN != c->rq.remaining_upload_size);\n        /* Do not grow read buffer more than necessary to process the current\n           request. */\n        rbuff_grow_desired =\n          (c->rq.remaining_upload_size > c->read_buffer_size);\n      }\n      else\n      {\n        mhd_assert (MHD_SIZE_UNKNOWN == c->rq.remaining_upload_size);\n        if (0 == c->rq.current_chunk_size)\n          rbuff_grow_desired =  /* Reading value of the next chunk size */\n                               (MHD_CHUNK_HEADER_REASONABLE_LEN >\n                                c->read_buffer_size);\n        else\n        {\n          const uint64_t cur_chunk_left =\n            c->rq.current_chunk_size - c->rq.current_chunk_offset;\n          /* Do not grow read buffer more than necessary to process the current\n             chunk with terminating CRLF. */\n          mhd_assert (c->rq.current_chunk_offset <= c->rq.current_chunk_size);\n          rbuff_grow_desired =\n            ((cur_chunk_left + 2) > (uint64_t) (c->read_buffer_size));\n        }\n      }\n    }\n  }\n\n  if (! rbuff_grow_desired)\n    return true; /* No need to increase the buffer */\n\n  if (try_grow_read_buffer (c, rbuff_grow_required))\n    return true; /* Buffer increase succeed */\n\n  if (! rbuff_grow_required)\n    return true; /* Can continue without buffer increase */\n\n  /* Failed to increase the read buffer size, but need to read the data\n     from the network.\n     No more space left in the buffer, no more space to increase the buffer. */\n\n  /* 'PROCESS_READ' event state flag must be set only if the last application\n     callback has processed some data. If any data is processed then some\n     space in the read buffer must be available. */\n  mhd_assert (0 == (MHD_EVENT_LOOP_INFO_PROCESS & c->event_loop_info));\n\n  if ((! MHD_D_IS_USING_THREADS_ (c->daemon))\n      && (MHD_CONNECTION_BODY_RECEIVING == c->state)\n      && has_unprocessed_upload_body_data_in_buffer (c))\n  {\n    /* The application is handling processing cycles.\n       The data could be processed later. */\n    c->event_loop_info = MHD_EVENT_LOOP_INFO_PROCESS;\n    return true;\n  }\n  else\n  {\n    enum MHD_ProcRecvDataStage stage;\n\n    switch (c->state)\n    {\n    case MHD_CONNECTION_INIT:\n      stage = MHD_PROC_RECV_INIT;\n      break;\n    case MHD_CONNECTION_REQ_LINE_RECEIVING:\n      if (MHD_HTTP_MTHD_NO_METHOD == c->rq.http_mthd)\n        stage = MHD_PROC_RECV_METHOD;\n      else if (0 == c->rq.req_target_len)\n        stage = MHD_PROC_RECV_URI;\n      else\n        stage = MHD_PROC_RECV_HTTPVER;\n      break;\n    case MHD_CONNECTION_REQ_HEADERS_RECEIVING:\n      stage = MHD_PROC_RECV_HEADERS;\n      break;\n    case MHD_CONNECTION_BODY_RECEIVING:\n      stage = c->rq.have_chunked_upload ?\n              MHD_PROC_RECV_BODY_CHUNKED : MHD_PROC_RECV_BODY_NORMAL;\n      break;\n    case MHD_CONNECTION_FOOTERS_RECEIVING:\n      stage = MHD_PROC_RECV_FOOTERS;\n      break;\n    case MHD_CONNECTION_REQ_LINE_RECEIVED:\n    case MHD_CONNECTION_HEADERS_RECEIVED:\n    case MHD_CONNECTION_HEADERS_PROCESSED:\n    case MHD_CONNECTION_CONTINUE_SENDING:\n    case MHD_CONNECTION_BODY_RECEIVED:\n    case MHD_CONNECTION_FOOTERS_RECEIVED:\n    case MHD_CONNECTION_FULL_REQ_RECEIVED:\n    case MHD_CONNECTION_START_REPLY:\n    case MHD_CONNECTION_HEADERS_SENDING:\n    case MHD_CONNECTION_HEADERS_SENT:\n    case MHD_CONNECTION_NORMAL_BODY_UNREADY:\n    case MHD_CONNECTION_NORMAL_BODY_READY:\n    case MHD_CONNECTION_CHUNKED_BODY_UNREADY:\n    case MHD_CONNECTION_CHUNKED_BODY_READY:\n    case MHD_CONNECTION_CHUNKED_BODY_SENT:\n    case MHD_CONNECTION_FOOTERS_SENDING:\n    case MHD_CONNECTION_FULL_REPLY_SENT:\n    case MHD_CONNECTION_CLOSED:\n#ifdef UPGRADE_SUPPORT\n    case MHD_CONNECTION_UPGRADE:\n#endif\n    default:\n      stage = MHD_PROC_RECV_BODY_NORMAL;\n      mhd_assert (0);\n    }\n\n    handle_recv_no_space (c, stage);\n  }\n  return false;\n}\n</additional code>\nPlease find suspicious code fragments in the code and report them. Other agents can not investigate other fragments that you do not report, so it is very important to find all suspicious fragments without missing any. Report the suspicious fragments AS MUCH AS POSSIBLE.",
  "suspicious_frags": [],
  "explanation": "I examined the provided code and the related functions. The MISRA Rule 17.2 (no direct or indirect self-calls) would be violated if try_grow_read_buffer called itself or if any function it calls could (directly or indirectly) call back into try_grow_read_buffer. In the supplied snippets: try_grow_read_buffer only calls MHD_pool_get_free, MHD_pool_is_resizable_inplace, MHD_pool_reallocate and uses mhd_assert. The supplied definitions of these functions/macros do not call try_grow_read_buffer (mhd_assert is defined to ((void)0); the pool functions manipulate memory and do not invoke higher-level connection logic). The only caller of try_grow_read_buffer shown is check_and_grow_read_buffer_space, which calls try_grow_read_buffer but is not called by try_grow_read_buffer, so no recursion is present in the given code paths. Therefore there are no suspicious fragments in the provided code that appear to violate Rule 17.2.\n\nNote: If there are other functions outside the supplied snippets (for example handle_recv_no_space, application callbacks, or other parts of the codebase) that call check_and_grow_read_buffer_space or try_grow_read_buffer and those in turn call back into them, those external call paths were not provided and should be checked separately. Based on the provided code alone, no direct or indirect recursion is evident."
}