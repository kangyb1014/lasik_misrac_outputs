{
  "user_message": "<misra_rule>\nMISRA C 2023 Rule 2.1 is: A project shall not contain unreachable code.\n\n</misra_rule>\n<response format>\nProvide your answer with these fields.\n- is_rule_violated: whether the rule is violated or not (true/false),\n- scenario: a specific violation scenario.\n</response format>\n<target_code>\nHere is the code of try_grow_read_buffer:\n```c\nstatic bool\ntry_grow_read_buffer (struct MHD_Connection *connection,\n                      bool required)\n{\n  size_t new_size;\n  size_t avail_size;\n  const size_t def_grow_size = connection->daemon->pool_increment;\n  void *rb;\n\n  avail_size = MHD_pool_get_free (connection->pool);\n  if (0 == avail_size)\n    return false;               /* No more space available */\n  if (0 == connection->read_buffer_size)\n    new_size = avail_size / 2;  /* Use half of available buffer for reading */\n  else\n  {\n    size_t grow_size;\n\n    grow_size = avail_size / 8;\n    if (def_grow_size > grow_size)\n    {                  /* Shortage of space */\n      const size_t left_free =\n        connection->read_buffer_size - connection->read_buffer_offset;\n      mhd_assert (connection->read_buffer_size >= \\\n                  connection->read_buffer_offset);\n      if ((def_grow_size <= grow_size + left_free)\n          && (left_free < def_grow_size))\n        grow_size = def_grow_size - left_free;  /* Use precise 'def_grow_size' for new free space */\n      else if (! required)\n        return false;                           /* Grow is not mandatory, leave some space in pool */\n      else\n      {\n        /* Shortage of space, but grow is mandatory */\n        const size_t small_inc =\n          ((MHD_BUF_INC_SIZE > def_grow_size) ?\n           def_grow_size : MHD_BUF_INC_SIZE) / 8;\n        if (small_inc < avail_size)\n          grow_size = small_inc;\n        else\n          grow_size = avail_size;\n      }\n    }\n    new_size = connection->read_buffer_size + grow_size;\n  }\n  /* Make sure that read buffer will not be moved */\n  if ((NULL != connection->read_buffer) &&\n      ! MHD_pool_is_resizable_inplace (connection->pool,\n                                       connection->read_buffer,\n                                       connection->read_buffer_size))\n  {\n    mhd_assert (0);\n    return false;\n  }\n  /* we can actually grow the buffer, do it! */\n  rb = MHD_pool_reallocate (connection->pool,\n                            connection->read_buffer,\n                            connection->read_buffer_size,\n                            new_size);\n  if (NULL == rb)\n  {\n    /* This should NOT be possible: we just computed 'new_size' so that\n       it should fit. If it happens, somehow our read buffer is not in\n       the right position in the pool, say because someone called\n       MHD_pool_allocate() without 'from_end' set to 'true'? Anyway,\n       should be investigated! (Ideally provide all data from\n       *pool and connection->read_buffer and new_size for debugging). */\n    mhd_assert (0);\n    return false;\n  }\n  mhd_assert (connection->read_buffer == rb);\n  connection->read_buffer = rb;\n  mhd_assert (NULL != connection->read_buffer);\n  connection->read_buffer_size = new_size;\n  return true;\n}\n```\n</target_code>\n<additional code>Here are the definitions of symbols that are close to the target function try_grow_read_buffer:\nstruct MHD_Connection\n{\n\n#ifdef EPOLL_SUPPORT\n  /**\n   * Next pointer for the EDLL listing connections that are epoll-ready.\n   */\n  struct MHD_Connection *nextE;\n\n  /**\n   * Previous pointer for the EDLL listing connections that are epoll-ready.\n   */\n  struct MHD_Connection *prevE;\n#endif\n\n  /**\n   * Next pointer for the DLL describing our IO state.\n   */\n  struct MHD_Connection *next;\n\n  /**\n   * Previous pointer for the DLL describing our IO state.\n   */\n  struct MHD_Connection *prev;\n\n  /**\n   * Next pointer for the XDLL organizing connections by timeout.\n   * This DLL can be either the\n   * 'manual_timeout_head/manual_timeout_tail' or the\n   * 'normal_timeout_head/normal_timeout_tail', depending on whether a\n   * custom timeout is set for the connection.\n   */\n  struct MHD_Connection *nextX;\n\n  /**\n   * Previous pointer for the XDLL organizing connections by timeout.\n   */\n  struct MHD_Connection *prevX;\n\n  /**\n   * Reference to the MHD_Daemon struct.\n   */\n  struct MHD_Daemon *daemon;\n\n  /**\n   * Request-specific data\n   */\n  struct MHD_Request rq;\n\n  /**\n   * Reply-specific data\n   */\n  struct MHD_Reply rp;\n\n  /**\n   * The memory pool is created whenever we first read from the TCP\n   * stream and destroyed at the end of each request (and re-created\n   * for the next request).  In the meantime, this pointer is NULL.\n   * The pool is used for all connection-related data except for the\n   * response (which maybe shared between connections) and the IP\n   * address (which persists across individual requests).\n   */\n  struct MemoryPool *pool;\n\n  /**\n   * We allow the main application to associate some pointer with the\n   * TCP connection (which may span multiple HTTP requests).  Here is\n   * where we store it.  (MHD does not know or care what it is).\n   * The location is given to the #MHD_NotifyConnectionCallback and\n   * also accessible via #MHD_CONNECTION_INFO_SOCKET_CONTEXT.\n   */\n  void *socket_context;\n\n  /**\n   * Close connection after sending response?\n   * Functions may change value from \"Unknown\" or \"KeepAlive\" to \"Must close\",\n   * but no functions reset value \"Must Close\" to any other value.\n   */\n  enum MHD_ConnKeepAlive keepalive;\n\n  /**\n   * Buffer for reading requests.  Allocated in pool.  Actually one\n   * byte larger than @e read_buffer_size (if non-NULL) to allow for\n   * 0-termination.\n   */\n  char *read_buffer;\n\n  /**\n   * Buffer for writing response (headers only).  Allocated\n   * in pool.\n   */\n  char *write_buffer;\n\n  /**\n   * Foreign address (of length @e addr_len).  MALLOCED (not\n   * in pool!).\n   */\n  struct sockaddr_storage *addr;\n\n#if defined(MHD_USE_POSIX_THREADS) || defined(MHD_USE_W32_THREADS)\n  /**\n   * Thread handle for this connection (if we are using\n   * one thread per connection).\n   */\n  MHD_thread_handle_ID_ tid;\n#endif\n\n  /**\n   * Size of @e read_buffer (in bytes).\n   * This value indicates how many bytes we're willing to read\n   * into the buffer.\n   */\n  size_t read_buffer_size;\n\n  /**\n   * Position where we currently append data in @e read_buffer (the\n   * next char after the last valid position).\n   */\n  size_t read_buffer_offset;\n\n  /**\n   * Size of @e write_buffer (in bytes).\n   */\n  size_t write_buffer_size;\n\n  /**\n   * Offset where we are with sending from @e write_buffer.\n   */\n  size_t write_buffer_send_offset;\n\n  /**\n   * Last valid location in write_buffer (where do we\n   * append and up to where is it safe to send?)\n   */\n  size_t write_buffer_append_offset;\n\n  /**\n   * Position in the 100 CONTINUE message that\n   * we need to send when receiving http 1.1 requests.\n   */\n  size_t continue_message_write_offset;\n\n  /**\n   * Length of the foreign address.\n   */\n  socklen_t addr_len;\n\n  /**\n   * Last time this connection had any activity\n   * (reading or writing).\n   */\n  uint64_t last_activity;\n\n  /**\n   * After how many milliseconds of inactivity should\n   * this connection time out?\n   * Zero for no timeout.\n   */\n  uint64_t connection_timeout_ms;\n\n  /**\n   * Socket for this connection.  Set to #MHD_INVALID_SOCKET if\n   * this connection has died (daemon should clean\n   * up in that case).\n   */\n  MHD_socket socket_fd;\n\n  /**\n   * true if @e socket_fd is not TCP/IP (a UNIX domain socket, a pipe),\n   * false (TCP/IP) otherwise.\n   */\n  enum MHD_tristate is_nonip;\n\n  /**\n   * true if #socket_fd is non-blocking, false otherwise.\n   */\n  bool sk_nonblck;\n\n  /**\n   * true if connection socket has set SIGPIPE suppression\n   */\n  bool sk_spipe_suppress;\n\n  /**\n   * Tracks TCP_CORK / TCP_NOPUSH of the connection socket.\n   */\n  enum MHD_tristate sk_corked;\n\n  /**\n   * Tracks TCP_NODELAY state of the connection socket.\n   */\n  enum MHD_tristate sk_nodelay;\n\n  /**\n   * Has this socket been closed for reading (i.e.  other side closed\n   * the connection)?  If so, we must completely close the connection\n   * once we are done sending our response (and stop trying to read\n   * from this socket).\n   */\n  bool read_closed;\n\n  /**\n   * Some error happens during processing the connection therefore this\n   * connection must be closed.\n   * The error may come from the client side (like wrong request format),\n   * from the application side (like data callback returned error), or from\n   * the OS side (like out-of-memory).\n   */\n  bool stop_with_error;\n\n  /**\n   * Response queued early, before the request is fully processed,\n   * the client upload is rejected.\n   * The connection cannot be reused for additional requests as the current\n   * request is incompletely read and it is unclear where is the initial\n   * byte of the next request.\n   */\n  bool discard_request;\n\n#if defined(MHD_USE_POSIX_THREADS) || defined(MHD_USE_W32_THREADS)\n  /**\n   * Set to `true` if the thread has been joined.\n   */\n  bool thread_joined;\n#endif\n\n  /**\n   * Are we currently inside the \"idle\" handler (to avoid recursively\n   * invoking it).\n   */\n  bool in_idle;\n\n  /**\n   * Connection is in the cleanup DL-linked list.\n   */\n  bool in_cleanup;\n\n#ifdef EPOLL_SUPPORT\n  /**\n   * What is the state of this socket in relation to epoll?\n   */\n  enum MHD_EpollState epoll_state;\n#endif\n\n  /**\n   * State in the FSM for this connection.\n   */\n  enum MHD_CONNECTION_STATE state;\n\n  /**\n   * What is this connection waiting for?\n   */\n  enum MHD_ConnectionEventLoopInfo event_loop_info;\n\n  /**\n   * Function used for reading HTTP request stream.\n   */\n  ReceiveCallback recv_cls;\n\n#ifdef UPGRADE_SUPPORT\n  /**\n   * If this connection was upgraded, this points to\n   * the upgrade response details such that the\n   * #thread_main_connection_upgrade()-logic can perform the\n   * bi-directional forwarding.\n   */\n  struct MHD_UpgradeResponseHandle *urh;\n#endif /* UPGRADE_SUPPORT */\n\n#ifdef HTTPS_SUPPORT\n\n  /**\n   * State required for HTTPS/SSL/TLS support.\n   */\n  gnutls_session_t tls_session;\n\n  /**\n   * State of connection's TLS layer\n   */\n  enum MHD_TLS_CONN_STATE tls_state;\n\n  /**\n   * Could it be that we are ready to read due to TLS buffers\n   * even though the socket is not?\n   */\n  bool tls_read_ready;\n#endif /* HTTPS_SUPPORT */\n\n  /**\n   * Is the connection suspended?\n   */\n  bool suspended;\n\n  /**\n   * Are we currently in the #MHD_AccessHandlerCallback\n   * for this connection (and thus eligible to receive\n   * calls to #MHD_queue_response()?).\n   */\n  bool in_access_handler;\n\n  /**\n   * Is the connection wanting to resume?\n   */\n  volatile bool resuming;\n\n  /**\n   * Special member to be returned by #MHD_get_connection_info()\n   */\n  union MHD_ConnectionInfo connection_info_dummy;\n}\n...\nsize_t\nMHD_pool_get_free (struct MemoryPool *pool)\n{\n  mhd_assert (pool->end >= pool->pos);\n  mhd_assert (pool->size >= pool->end - pool->pos);\n  mhd_assert (pool->pos == ROUND_TO_ALIGN (pool->pos));\n#ifdef MHD_ASAN_POISON_ACTIVE\n  if ((pool->end - pool->pos) <= _MHD_RED_ZONE_SIZE)\n    return 0;\n#endif /* MHD_ASAN_POISON_ACTIVE */\n  return (pool->end - pool->pos) - _MHD_RED_ZONE_SIZE;\n}\n...\nbool\nMHD_pool_is_resizable_inplace (struct MemoryPool *pool,\n                               void *block,\n                               size_t block_size)\n{\n  mhd_assert (pool->end >= pool->pos);\n  mhd_assert (pool->size >= pool->end - pool->pos);\n  mhd_assert (block != NULL || block_size == 0);\n  mhd_assert (pool->size >= block_size);\n  if (NULL != block)\n  {\n    const size_t block_offset = mp_ptr_diff_ (block, pool->memory);\n    mhd_assert (mp_ptr_le_ (pool->memory, block));\n    mhd_assert (pool->size >= block_offset);\n    mhd_assert (pool->size >= block_offset + block_size);\n    return (pool->pos ==\n            ROUND_TO_ALIGN_PLUS_RED_ZONE (block_offset + block_size));\n  }\n  return false; /* Unallocated blocks cannot be resized in-place */\n}\n...\nvoid *\nMHD_pool_reallocate (struct MemoryPool *pool,\n                     void *old,\n                     size_t old_size,\n                     size_t new_size)\n{\n  size_t asize;\n  uint8_t *new_blc;\n\n  mhd_assert (pool->end >= pool->pos);\n  mhd_assert (pool->size >= pool->end - pool->pos);\n  mhd_assert (old != NULL || old_size == 0);\n  mhd_assert (pool->size >= old_size);\n  mhd_assert (pool->pos == ROUND_TO_ALIGN (pool->pos));\n#if defined(MHD_ASAN_POISON_ACTIVE) && defined(HAVE___ASAN_REGION_IS_POISONED)\n  mhd_assert (NULL == __asan_region_is_poisoned (old, old_size));\n#endif /* MHD_ASAN_POISON_ACTIVE && HAVE___ASAN_REGION_IS_POISONED */\n\n  if (NULL != old)\n  {   /* Have previously allocated data */\n    const size_t old_offset = mp_ptr_diff_ (old, pool->memory);\n    const bool shrinking = (old_size > new_size);\n\n    mhd_assert (mp_ptr_le_ (pool->memory, old));\n    /* (pool->memory + pool->size >= (uint8_t*) old + old_size) */\n    mhd_assert ((pool->size - _MHD_RED_ZONE_SIZE) >= (old_offset + old_size));\n    /* Blocks \"from the end\" must not be reallocated */\n    /* (old_size == 0 || pool->memory + pool->pos > (uint8_t*) old) */\n    mhd_assert ((old_size == 0) || \\\n                (pool->pos > old_offset));\n    mhd_assert ((old_size == 0) || \\\n                ((pool->end - _MHD_RED_ZONE_SIZE) >= (old_offset + old_size)));\n    /* Try resizing in-place */\n    if (shrinking)\n    {     /* Shrinking in-place, zero-out freed part */\n      memset ((uint8_t *) old + new_size, 0, old_size - new_size);\n      _MHD_POISON_MEMORY ((uint8_t *) old + new_size, old_size - new_size);\n    }\n    if (pool->pos ==\n        ROUND_TO_ALIGN_PLUS_RED_ZONE (old_offset + old_size))\n    {     /* \"old\" block is the last allocated block */\n      const size_t new_apos =\n        ROUND_TO_ALIGN_PLUS_RED_ZONE (old_offset + new_size);\n      if (! shrinking)\n      {                               /* Grow in-place, check for enough space. */\n        if ( (new_apos > pool->end) ||\n             (new_apos < pool->pos) ) /* Value wrap */\n          return NULL;                /* No space */\n      }\n      /* Resized in-place */\n      pool->pos = new_apos;\n      _MHD_UNPOISON_MEMORY (old, new_size);\n      return old;\n    }\n    if (shrinking)\n      return old;   /* Resized in-place, freed part remains allocated */\n  }\n  /* Need to allocate new block */\n  asize = ROUND_TO_ALIGN_PLUS_RED_ZONE (new_size);\n  if ( ( (0 == asize) &&\n         (0 != new_size) ) || /* Value wrap, too large new_size. */\n       (asize > pool->end - pool->pos) ) /* Not enough space */\n    return NULL;\n\n  new_blc = pool->memory + pool->pos;\n  pool->pos += asize;\n\n  _MHD_UNPOISON_MEMORY (new_blc, new_size);\n  if (0 != old_size)\n  {\n    /* Move data to new block, old block remains allocated */\n    memcpy (new_blc, old, old_size);\n    /* Zero-out old block */\n    memset (old, 0, old_size);\n    _MHD_POISON_MEMORY (old, old_size);\n  }\n  return new_blc;\n}\n...\nvoid *\nMHD_pool_allocate (struct MemoryPool *pool,\n                   size_t size,\n                   bool from_end)\n{\n  void *ret;\n  size_t asize;\n\n  mhd_assert (pool->end >= pool->pos);\n  mhd_assert (pool->size >= pool->end - pool->pos);\n  mhd_assert (pool->pos == ROUND_TO_ALIGN (pool->pos));\n  asize = ROUND_TO_ALIGN_PLUS_RED_ZONE (size);\n  if ( (0 == asize) && (0 != size) )\n    return NULL; /* size too close to SIZE_MAX */\n  if (asize > pool->end - pool->pos)\n    return NULL;\n  if (from_end)\n  {\n    ret = &pool->memory[pool->end - asize];\n    pool->end -= asize;\n  }\n  else\n  {\n    ret = &pool->memory[pool->pos];\n    pool->pos += asize;\n  }\n  _MHD_UNPOISON_MEMORY (ret, size);\n  return ret;\n}\n...\n#define MHD_BUF_INC_SIZE 1500\n...\n#define mhd_assert(ignore) ((void)0)\n...\nstatic bool\ncheck_and_grow_read_buffer_space (struct MHD_Connection *c)\n{\n  /**\n   * The increase of read buffer size is desirable.\n   */\n  bool rbuff_grow_desired;\n  /**\n   * The increase of read buffer size is a hard requirement.\n   */\n  bool rbuff_grow_required;\n\n  mhd_assert (0 != (MHD_EVENT_LOOP_INFO_READ & c->event_loop_info));\n  mhd_assert (! c->discard_request);\n\n  rbuff_grow_required = (c->read_buffer_offset == c->read_buffer_size);\n  if (rbuff_grow_required)\n    rbuff_grow_desired = true;\n  else\n  {\n    rbuff_grow_desired = (c->read_buffer_offset + c->daemon->pool_increment >\n                          c->read_buffer_size);\n\n    if ((rbuff_grow_desired) &&\n        (MHD_CONNECTION_BODY_RECEIVING == c->state))\n    {\n      if (! c->rq.have_chunked_upload)\n      {\n        mhd_assert (MHD_SIZE_UNKNOWN != c->rq.remaining_upload_size);\n        /* Do not grow read buffer more than necessary to process the current\n           request. */\n        rbuff_grow_desired =\n          (c->rq.remaining_upload_size > c->read_buffer_size);\n      }\n      else\n      {\n        mhd_assert (MHD_SIZE_UNKNOWN == c->rq.remaining_upload_size);\n        if (0 == c->rq.current_chunk_size)\n          rbuff_grow_desired =  /* Reading value of the next chunk size */\n                               (MHD_CHUNK_HEADER_REASONABLE_LEN >\n                                c->read_buffer_size);\n        else\n        {\n          const uint64_t cur_chunk_left =\n            c->rq.current_chunk_size - c->rq.current_chunk_offset;\n          /* Do not grow read buffer more than necessary to process the current\n             chunk with terminating CRLF. */\n          mhd_assert (c->rq.current_chunk_offset <= c->rq.current_chunk_size);\n          rbuff_grow_desired =\n            ((cur_chunk_left + 2) > (uint64_t) (c->read_buffer_size));\n        }\n      }\n    }\n  }\n\n  if (! rbuff_grow_desired)\n    return true; /* No need to increase the buffer */\n\n  if (try_grow_read_buffer (c, rbuff_grow_required))\n    return true; /* Buffer increase succeed */\n\n  if (! rbuff_grow_required)\n    return true; /* Can continue without buffer increase */\n\n  /* Failed to increase the read buffer size, but need to read the data\n     from the network.\n     No more space left in the buffer, no more space to increase the buffer. */\n\n  /* 'PROCESS_READ' event state flag must be set only if the last application\n     callback has processed some data. If any data is processed then some\n     space in the read buffer must be available. */\n  mhd_assert (0 == (MHD_EVENT_LOOP_INFO_PROCESS & c->event_loop_info));\n\n  if ((! MHD_D_IS_USING_THREADS_ (c->daemon))\n      && (MHD_CONNECTION_BODY_RECEIVING == c->state)\n      && has_unprocessed_upload_body_data_in_buffer (c))\n  {\n    /* The application is handling processing cycles.\n       The data could be processed later. */\n    c->event_loop_info = MHD_EVENT_LOOP_INFO_PROCESS;\n    return true;\n  }\n  else\n  {\n    enum MHD_ProcRecvDataStage stage;\n\n    switch (c->state)\n    {\n    case MHD_CONNECTION_INIT:\n      stage = MHD_PROC_RECV_INIT;\n      break;\n    case MHD_CONNECTION_REQ_LINE_RECEIVING:\n      if (MHD_HTTP_MTHD_NO_METHOD == c->rq.http_mthd)\n        stage = MHD_PROC_RECV_METHOD;\n      else if (0 == c->rq.req_target_len)\n        stage = MHD_PROC_RECV_URI;\n      else\n        stage = MHD_PROC_RECV_HTTPVER;\n      break;\n    case MHD_CONNECTION_REQ_HEADERS_RECEIVING:\n      stage = MHD_PROC_RECV_HEADERS;\n      break;\n    case MHD_CONNECTION_BODY_RECEIVING:\n      stage = c->rq.have_chunked_upload ?\n              MHD_PROC_RECV_BODY_CHUNKED : MHD_PROC_RECV_BODY_NORMAL;\n      break;\n    case MHD_CONNECTION_FOOTERS_RECEIVING:\n      stage = MHD_PROC_RECV_FOOTERS;\n      break;\n    case MHD_CONNECTION_REQ_LINE_RECEIVED:\n    case MHD_CONNECTION_HEADERS_RECEIVED:\n    case MHD_CONNECTION_HEADERS_PROCESSED:\n    case MHD_CONNECTION_CONTINUE_SENDING:\n    case MHD_CONNECTION_BODY_RECEIVED:\n    case MHD_CONNECTION_FOOTERS_RECEIVED:\n    case MHD_CONNECTION_FULL_REQ_RECEIVED:\n    case MHD_CONNECTION_START_REPLY:\n    case MHD_CONNECTION_HEADERS_SENDING:\n    case MHD_CONNECTION_HEADERS_SENT:\n    case MHD_CONNECTION_NORMAL_BODY_UNREADY:\n    case MHD_CONNECTION_NORMAL_BODY_READY:\n    case MHD_CONNECTION_CHUNKED_BODY_UNREADY:\n    case MHD_CONNECTION_CHUNKED_BODY_READY:\n    case MHD_CONNECTION_CHUNKED_BODY_SENT:\n    case MHD_CONNECTION_FOOTERS_SENDING:\n    case MHD_CONNECTION_FULL_REPLY_SENT:\n    case MHD_CONNECTION_CLOSED:\n#ifdef UPGRADE_SUPPORT\n    case MHD_CONNECTION_UPGRADE:\n#endif\n    default:\n      stage = MHD_PROC_RECV_BODY_NORMAL;\n      mhd_assert (0);\n    }\n\n    handle_recv_no_space (c, stage);\n  }\n  return false;\n}\n...\nvoid *\nMHD_connection_alloc_memory_ (struct MHD_Connection *connection,\n                              size_t size)\n{\n  struct MHD_Connection *const c = connection; /* a short alias */\n  struct MemoryPool *const pool = c->pool;     /* a short alias */\n  size_t need_to_be_freed = 0; /**< The required amount of additional free memory */\n  void *res;\n\n  res = MHD_pool_try_alloc (pool,\n                            size,\n                            &need_to_be_freed);\n  if (NULL != res)\n    return res;\n\n  if (MHD_pool_is_resizable_inplace (pool,\n                                     c->write_buffer,\n                                     c->write_buffer_size))\n  {\n    if (c->write_buffer_size - c->write_buffer_append_offset >=\n        need_to_be_freed)\n    {\n      char *buf;\n      const size_t new_buf_size = c->write_buffer_size - need_to_be_freed;\n      buf = MHD_pool_reallocate (pool,\n                                 c->write_buffer,\n                                 c->write_buffer_size,\n                                 new_buf_size);\n      mhd_assert (c->write_buffer == buf);\n      mhd_assert (c->write_buffer_append_offset <= new_buf_size);\n      mhd_assert (c->write_buffer_send_offset <= new_buf_size);\n      c->write_buffer_size = new_buf_size;\n      c->write_buffer = buf;\n    }\n    else\n      return NULL;\n  }\n  else if (MHD_pool_is_resizable_inplace (pool,\n                                          c->read_buffer,\n                                          c->read_buffer_size))\n  {\n    if (c->read_buffer_size - c->read_buffer_offset >= need_to_be_freed)\n    {\n      char *buf;\n      const size_t new_buf_size = c->read_buffer_size - need_to_be_freed;\n      buf = MHD_pool_reallocate (pool,\n                                 c->read_buffer,\n                                 c->read_buffer_size,\n                                 new_buf_size);\n      mhd_assert (c->read_buffer == buf);\n      mhd_assert (c->read_buffer_offset <= new_buf_size);\n      c->read_buffer_size = new_buf_size;\n      c->read_buffer = buf;\n    }\n    else\n      return NULL;\n  }\n  else\n    return NULL;\n  res = MHD_pool_allocate (pool, size, true);\n  mhd_assert (NULL != res); /* It has been checked that pool has enough space */\n  return res;\n}\n...\nstatic void\nconnection_shrink_read_buffer (struct MHD_Connection *connection)\n{\n  struct MHD_Connection *const c = connection; /**< a short alias */\n  void *new_buf;\n\n  if ((NULL == c->read_buffer) || (0 == c->read_buffer_size))\n  {\n    mhd_assert (0 == c->read_buffer_size);\n    mhd_assert (0 == c->read_buffer_offset);\n    return;\n  }\n\n  mhd_assert (c->read_buffer_offset <= c->read_buffer_size);\n  if (0 == c->read_buffer_offset)\n  {\n    MHD_pool_deallocate (c->pool, c->read_buffer, c->read_buffer_size);\n    c->read_buffer = NULL;\n    c->read_buffer_size = 0;\n  }\n  else\n  {\n    mhd_assert (MHD_pool_is_resizable_inplace (c->pool, c->read_buffer, \\\n                                               c->read_buffer_size));\n    new_buf = MHD_pool_reallocate (c->pool, c->read_buffer, c->read_buffer_size,\n                                   c->read_buffer_offset);\n    mhd_assert (c->read_buffer == new_buf);\n    c->read_buffer = new_buf;\n    c->read_buffer_size = c->read_buffer_offset;\n  }\n}\n</additional code>\n<target_code>\nHere is the code fragment that you need to analyze:\n```c\nif ((NULL != connection->read_buffer) &&\n      ! MHD_pool_is_resizable_inplace (connection->pool,\n                                       connection->read_buffer,\n                                       connection->read_buffer_size))\n  {\n    mhd_assert (0);\n    return false;\n  }\n```\nFocus on the above code fragment and judge whether it violates the rule 2.1 or not.\n</target_code>\n",
  "is_rule_violated": false,
  "scenario": "Given the provided codebase mhd_assert is defined as ((void)0), so the assertion is a no-op and the subsequent 'return false;' is reachable \u2014 therefore no unreachable code in this fragment. Note: if in another build configuration mhd_assert were implemented as a non-returning assertion handler (e.g. calling abort or otherwise not returning), then the 'return false;' would be unreachable in that build, which would violate MISRA C 2023 Rule 2.1."
}