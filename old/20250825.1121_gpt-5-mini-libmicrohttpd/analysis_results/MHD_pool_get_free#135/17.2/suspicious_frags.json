{
  "user_message": "<misra_rule>\nThe target MISRA C 2023 Rule 17.2 is: Functions shall not call themselves, either directly or indirectly.\n\n</misra_rule>\n<instruction>\nOther agents will judge whether the code follows the MISRA C 2023 guidelines.\nThey will investigate the code fragments you give.\nYour job is to find code fragments in the code that should be investigated to check whether the code follows the MISRA C rule.\n</instruction>\n<response format>\nProvide your answer with these fields.\n- suspicious_frags: The list of suspicious code fragments in the code.\nIt should contain only the code fragments exists in the code. If you do not find any suspicious code fragments, return an empty list for suspicious_frags\n- explanation: The explanation of why other code fragments should NOT be investigated.\nIt is very important to not miss any suspicious code fragments, so please give a sufficient explanation why other code fragments should not be investigated.\nDO NOT give any explanation for the selected suspicious code fragments.\n</response format>\n<target_code>\nHere is the code of MHD_pool_get_free:\n```c\nsize_t\nMHD_pool_get_free (struct MemoryPool *pool)\n{\n  mhd_assert (pool->end >= pool->pos);\n  mhd_assert (pool->size >= pool->end - pool->pos);\n  mhd_assert (pool->pos == ROUND_TO_ALIGN (pool->pos));\n#ifdef MHD_ASAN_POISON_ACTIVE\n  if ((pool->end - pool->pos) <= _MHD_RED_ZONE_SIZE)\n    return 0;\n#endif /* MHD_ASAN_POISON_ACTIVE */\n  return (pool->end - pool->pos) - _MHD_RED_ZONE_SIZE;\n}\n```\n</target_code>\n<additional code>Here are the definitions of symbols that are related to the target function MHD_pool_get_free:\n#define mhd_assert(ignore) ((void)0)\n...\n#define ROUND_TO_ALIGN(n) (((n)+(ALIGN_SIZE-1))/(ALIGN_SIZE)*(ALIGN_SIZE))\n...\n#define _MHD_RED_ZONE_SIZE (0)\n...\nstatic enum MHD_Result\ntry_ready_chunked_body (struct MHD_Connection *connection,\n                        bool *p_finished)\n{\n  ssize_t ret;\n  struct MHD_Response *response;\n  static const size_t max_chunk = 0xFFFFFF;\n  char chunk_hdr[6];            /* 6: max strlen of \"FFFFFF\" */\n  /* \"FFFFFF\" + \"\\r\\n\" */\n  static const size_t max_chunk_hdr_len = sizeof(chunk_hdr) + 2;\n  /* \"FFFFFF\" + \"\\r\\n\" + \"\\r\\n\" (chunk termination) */\n  static const size_t max_chunk_overhead = sizeof(chunk_hdr) + 2 + 2;\n  size_t chunk_hdr_len;\n  uint64_t left_to_send;\n  size_t size_to_fill;\n\n  response = connection->rp.response;\n  mhd_assert (NULL != response->crc || NULL != response->data);\n\n  mhd_assert (0 == connection->write_buffer_append_offset);\n\n  /* The buffer must be reasonably large enough */\n  if (128 > connection->write_buffer_size)\n  {\n    size_t size;\n\n    size = connection->write_buffer_size + MHD_pool_get_free (connection->pool);\n    if (128 > size)\n    {\n#if defined(MHD_USE_POSIX_THREADS) || defined(MHD_USE_W32_THREADS)\n      MHD_mutex_unlock_chk_ (&response->mutex);\n#endif\n      /* not enough memory */\n      CONNECTION_CLOSE_ERROR (connection,\n                              _ (\"Closing connection (out of memory).\"));\n      return MHD_NO;\n    }\n    /* Limit the buffer size to the largest usable size for chunks */\n    if ( (max_chunk + max_chunk_overhead) < size)\n      size = max_chunk + max_chunk_overhead;\n    mhd_assert ((NULL == connection->write_buffer) || \\\n                MHD_pool_is_resizable_inplace (connection->pool, \\\n                                               connection->write_buffer, \\\n                                               connection->write_buffer_size));\n    connection->write_buffer =\n      MHD_pool_reallocate (connection->pool,\n                           connection->write_buffer,\n                           connection->write_buffer_size,\n                           size);\n    mhd_assert (NULL != connection->write_buffer);\n    connection->write_buffer_size = size;\n  }\n  mhd_assert (max_chunk_overhead < connection->write_buffer_size);\n\n  if (MHD_SIZE_UNKNOWN == response->total_size)\n    left_to_send = MHD_SIZE_UNKNOWN;\n  else\n    left_to_send = response->total_size\n                   - connection->rp.rsp_write_position;\n\n  size_to_fill = connection->write_buffer_size - max_chunk_overhead;\n  /* Limit size for the callback to the max usable size */\n  if (max_chunk < size_to_fill)\n    size_to_fill = max_chunk;\n  if (left_to_send < size_to_fill)\n    size_to_fill = (size_t) left_to_send;\n\n  if (0 == left_to_send)\n    /* nothing to send, don't bother calling crc */\n    ret = MHD_CONTENT_READER_END_OF_STREAM;\n  else if ( (response->data_start <=\n             connection->rp.rsp_write_position) &&\n            (response->data_start + response->data_size >\n             connection->rp.rsp_write_position) )\n  {\n    /* difference between rsp_write_position and data_start is less\n       than data_size which is size_t type, no need to check for overflow */\n    const size_t data_write_offset\n      = (size_t) (connection->rp.rsp_write_position\n                  - response->data_start);\n    /* buffer already ready, use what is there for the chunk */\n    mhd_assert (SSIZE_MAX >= (response->data_size - data_write_offset));\n    mhd_assert (response->data_size >= data_write_offset);\n    ret = (ssize_t) (response->data_size - data_write_offset);\n    if ( ((size_t) ret) > size_to_fill)\n      ret = (ssize_t) size_to_fill;\n    memcpy (&connection->write_buffer[max_chunk_hdr_len],\n            &response->data[data_write_offset],\n            (size_t) ret);\n  }\n  else\n  {\n    if (NULL == response->crc)\n    { /* There is no way to reach this code */\n#if defined(MHD_USE_THREADS)\n      MHD_mutex_unlock_chk_ (&response->mutex);\n#endif\n      CONNECTION_CLOSE_ERROR (connection,\n                              _ (\"No callback for the chunked data.\"));\n      return MHD_NO;\n    }\n    ret = response->crc (response->crc_cls,\n                         connection->rp.rsp_write_position,\n                         &connection->write_buffer[max_chunk_hdr_len],\n                         size_to_fill);\n  }\n  if (MHD_CONTENT_READER_END_WITH_ERROR == ret)\n  {\n    /* error, close socket! */\n    /* TODO: remove update of the response size */\n    response->total_size = connection->rp.rsp_write_position;\n#if defined(MHD_USE_POSIX_THREADS) || defined(MHD_USE_W32_THREADS)\n    MHD_mutex_unlock_chk_ (&response->mutex);\n#endif\n    CONNECTION_CLOSE_ERROR (connection,\n                            _ (\"Closing connection (application error \" \\\n                               \"generating response).\"));\n    return MHD_NO;\n  }\n  if (MHD_CONTENT_READER_END_OF_STREAM == ret)\n  {\n    *p_finished = true;\n    /* TODO: remove update of the response size */\n    response->total_size = connection->rp.rsp_write_position;\n    return MHD_YES;\n  }\n  if (0 == ret)\n  {\n    connection->state = MHD_CONNECTION_CHUNKED_BODY_UNREADY;\n#if defined(MHD_USE_POSIX_THREADS) || defined(MHD_USE_W32_THREADS)\n    MHD_mutex_unlock_chk_ (&response->mutex);\n#endif\n    return MHD_NO;\n  }\n  if (size_to_fill < (size_t) ret)\n  {\n#if defined(MHD_USE_THREADS)\n    MHD_mutex_unlock_chk_ (&response->mutex);\n#endif\n    CONNECTION_CLOSE_ERROR (connection,\n                            _ (\"Closing connection (application returned \" \\\n                               \"more data than requested).\"));\n    return MHD_NO;\n  }\n  chunk_hdr_len = MHD_uint32_to_strx ((uint32_t) ret, chunk_hdr,\n                                      sizeof(chunk_hdr));\n  mhd_assert (chunk_hdr_len != 0);\n  mhd_assert (chunk_hdr_len < sizeof(chunk_hdr));\n  *p_finished = false;\n  connection->write_buffer_send_offset =\n    (max_chunk_hdr_len - (chunk_hdr_len + 2));\n  memcpy (connection->write_buffer + connection->write_buffer_send_offset,\n          chunk_hdr,\n          chunk_hdr_len);\n  connection->write_buffer[max_chunk_hdr_len - 2] = '\\r';\n  connection->write_buffer[max_chunk_hdr_len - 1] = '\\n';\n  connection->write_buffer[max_chunk_hdr_len + (size_t) ret] = '\\r';\n  connection->write_buffer[max_chunk_hdr_len + (size_t) ret + 1] = '\\n';\n  connection->rp.rsp_write_position += (size_t) ret;\n  connection->write_buffer_append_offset = max_chunk_hdr_len + (size_t) ret + 2;\n  return MHD_YES;\n}\n...\nstatic bool\ntry_grow_read_buffer (struct MHD_Connection *connection,\n                      bool required)\n{\n  size_t new_size;\n  size_t avail_size;\n  const size_t def_grow_size = connection->daemon->pool_increment;\n  void *rb;\n\n  avail_size = MHD_pool_get_free (connection->pool);\n  if (0 == avail_size)\n    return false;               /* No more space available */\n  if (0 == connection->read_buffer_size)\n    new_size = avail_size / 2;  /* Use half of available buffer for reading */\n  else\n  {\n    size_t grow_size;\n\n    grow_size = avail_size / 8;\n    if (def_grow_size > grow_size)\n    {                  /* Shortage of space */\n      const size_t left_free =\n        connection->read_buffer_size - connection->read_buffer_offset;\n      mhd_assert (connection->read_buffer_size >= \\\n                  connection->read_buffer_offset);\n      if ((def_grow_size <= grow_size + left_free)\n          && (left_free < def_grow_size))\n        grow_size = def_grow_size - left_free;  /* Use precise 'def_grow_size' for new free space */\n      else if (! required)\n        return false;                           /* Grow is not mandatory, leave some space in pool */\n      else\n      {\n        /* Shortage of space, but grow is mandatory */\n        const size_t small_inc =\n          ((MHD_BUF_INC_SIZE > def_grow_size) ?\n           def_grow_size : MHD_BUF_INC_SIZE) / 8;\n        if (small_inc < avail_size)\n          grow_size = small_inc;\n        else\n          grow_size = avail_size;\n      }\n    }\n    new_size = connection->read_buffer_size + grow_size;\n  }\n  /* Make sure that read buffer will not be moved */\n  if ((NULL != connection->read_buffer) &&\n      ! MHD_pool_is_resizable_inplace (connection->pool,\n                                       connection->read_buffer,\n                                       connection->read_buffer_size))\n  {\n    mhd_assert (0);\n    return false;\n  }\n  /* we can actually grow the buffer, do it! */\n  rb = MHD_pool_reallocate (connection->pool,\n                            connection->read_buffer,\n                            connection->read_buffer_size,\n                            new_size);\n  if (NULL == rb)\n  {\n    /* This should NOT be possible: we just computed 'new_size' so that\n       it should fit. If it happens, somehow our read buffer is not in\n       the right position in the pool, say because someone called\n       MHD_pool_allocate() without 'from_end' set to 'true'? Anyway,\n       should be investigated! (Ideally provide all data from\n       *pool and connection->read_buffer and new_size for debugging). */\n    mhd_assert (0);\n    return false;\n  }\n  mhd_assert (connection->read_buffer == rb);\n  connection->read_buffer = rb;\n  mhd_assert (NULL != connection->read_buffer);\n  connection->read_buffer_size = new_size;\n  return true;\n}\n...\nstatic size_t\nconnection_maximize_write_buffer (struct MHD_Connection *connection)\n{\n  struct MHD_Connection *const c = connection; /**< a short alias */\n  struct MemoryPool *const pool = connection->pool;\n  void *new_buf;\n  size_t new_size;\n  size_t free_size;\n\n  mhd_assert ((NULL != c->write_buffer) || (0 == c->write_buffer_size));\n  mhd_assert (c->write_buffer_append_offset >= c->write_buffer_send_offset);\n  mhd_assert (c->write_buffer_size >= c->write_buffer_append_offset);\n\n  free_size = MHD_pool_get_free (pool);\n  if (0 != free_size)\n  {\n    new_size = c->write_buffer_size + free_size;\n    /* This function must not move the buffer position.\n     * MHD_pool_reallocate () may return the new position only if buffer was\n     * allocated 'from_end' or is not the last allocation,\n     * which should not happen. */\n    mhd_assert ((NULL == c->write_buffer) || \\\n                MHD_pool_is_resizable_inplace (pool, c->write_buffer, \\\n                                               c->write_buffer_size));\n    new_buf = MHD_pool_reallocate (pool,\n                                   c->write_buffer,\n                                   c->write_buffer_size,\n                                   new_size);\n    mhd_assert ((c->write_buffer == new_buf) || (NULL == c->write_buffer));\n    c->write_buffer = new_buf;\n    c->write_buffer_size = new_size;\n    if (c->write_buffer_send_offset == c->write_buffer_append_offset)\n    {\n      /* All data have been sent, reset offsets to zero. */\n      c->write_buffer_send_offset = 0;\n      c->write_buffer_append_offset = 0;\n    }\n  }\n\n  return c->write_buffer_size - c->write_buffer_append_offset;\n}\n</additional code>\nPlease find suspicious code fragments in the code and report them. Other agents can not investigate other fragments that you do not report, so it is very important to find all suspicious fragments without missing any. Report the suspicious fragments AS MUCH AS POSSIBLE.",
  "suspicious_frags": [
    "size = connection->write_buffer_size + MHD_pool_get_free (connection->pool);",
    "mhd_assert ((NULL == c->write_buffer) || \\\n                MHD_pool_is_resizable_inplace (pool, c->write_buffer, \\\n                                               c->write_buffer_size));",
    "new_buf = MHD_pool_reallocate (pool,\n                                   c->write_buffer,\n                                   c->write_buffer_size,\n                                   new_size);",
    "free_size = MHD_pool_get_free (pool);",
    "mhd_assert ((NULL == connection->write_buffer) || \\\n                MHD_pool_is_resizable_inplace (connection->pool, \\\n                                               connection->write_buffer, \\\n                                               connection->write_buffer_size));",
    "connection->write_buffer =\n      MHD_pool_reallocate (connection->pool,\n                           connection->write_buffer,\n                           connection->write_buffer_size,\n                           size);",
    "avail_size = MHD_pool_get_free (connection->pool);",
    "chunk_hdr_len = MHD_uint32_to_strx ((uint32_t) ret, chunk_hdr,\n                                      sizeof(chunk_hdr));",
    "ret = response->crc (response->crc_cls,\n                         connection->rp.rsp_write_position,\n                         &connection->write_buffer[max_chunk_hdr_len],\n                         size_to_fill);",
    "rb = MHD_pool_reallocate (connection->pool,\n                            connection->read_buffer,\n                            connection->read_buffer_size,\n                            new_size);"
  ],
  "explanation": "MHD_pool_get_free itself contains only assertions/macros and simple arithmetic \u2014 it does not call any non-macro functions (mhd_assert is a no-op macro here, ROUND_TO_ALIGN is a macro and _MHD_RED_ZONE_SIZE is a macro constant). No function in the provided code body directly calls itself. The only potential for indirect recursion in the shown code is via calls to the pool API and to application callbacks: MHD_pool_reallocate and MHD_pool_is_resizable_inplace (pool-management functions) and the response->crc callback (application-supplied). Those calls are listed above because, if any of those external functions or callbacks were implemented to invoke back into the same code paths (directly or through other functions), an indirect recursion cycle could arise. Other fragments (simple assertions, arithmetic, memcpy, buffer/index manipulations, state updates, and control-flow constructs) do not perform function calls that could participate in recursion and therefore do not need further investigation for Rule 17.2 based on the provided code."
}