{
  "user_message": "<misra_rule>\nThe target MISRA C 2023 Rule 2.1 is: A project shall not contain unreachable code.\n\n</misra_rule>\n<instruction>\nOther agents will judge whether the code follows the MISRA C 2023 guidelines.\nThey will investigate the code fragments you give.\nYour job is to find code fragments in the code that should be investigated to check whether the code follows the MISRA C rule.\n</instruction>\n<response format>\nProvide your answer with these fields.\n- suspicious_frags: The list of suspicious code fragments in the code.\nIt should contain only the code fragments exists in the code. If you do not find any suspicious code fragments, return an empty list for suspicious_frags\n- explanation: The explanation of why other code fragments should NOT be investigated.\nIt is very important to not miss any suspicious code fragments, so please give a sufficient explanation why other code fragments should not be investigated.\nDO NOT give any explanation for the selected suspicious code fragments.\n</response format>\n<target_code>\nHere is the code of MHD_pool_reallocate:\n```c\nvoid *\nMHD_pool_reallocate (struct MemoryPool *pool,\n                     void *old,\n                     size_t old_size,\n                     size_t new_size)\n{\n  size_t asize;\n  uint8_t *new_blc;\n\n  mhd_assert (pool->end >= pool->pos);\n  mhd_assert (pool->size >= pool->end - pool->pos);\n  mhd_assert (old != NULL || old_size == 0);\n  mhd_assert (pool->size >= old_size);\n  mhd_assert (pool->pos == ROUND_TO_ALIGN (pool->pos));\n#if defined(MHD_ASAN_POISON_ACTIVE) && defined(HAVE___ASAN_REGION_IS_POISONED)\n  mhd_assert (NULL == __asan_region_is_poisoned (old, old_size));\n#endif /* MHD_ASAN_POISON_ACTIVE && HAVE___ASAN_REGION_IS_POISONED */\n\n  if (NULL != old)\n  {   /* Have previously allocated data */\n    const size_t old_offset = mp_ptr_diff_ (old, pool->memory);\n    const bool shrinking = (old_size > new_size);\n\n    mhd_assert (mp_ptr_le_ (pool->memory, old));\n    /* (pool->memory + pool->size >= (uint8_t*) old + old_size) */\n    mhd_assert ((pool->size - _MHD_RED_ZONE_SIZE) >= (old_offset + old_size));\n    /* Blocks \"from the end\" must not be reallocated */\n    /* (old_size == 0 || pool->memory + pool->pos > (uint8_t*) old) */\n    mhd_assert ((old_size == 0) || \\\n                (pool->pos > old_offset));\n    mhd_assert ((old_size == 0) || \\\n                ((pool->end - _MHD_RED_ZONE_SIZE) >= (old_offset + old_size)));\n    /* Try resizing in-place */\n    if (shrinking)\n    {     /* Shrinking in-place, zero-out freed part */\n      memset ((uint8_t *) old + new_size, 0, old_size - new_size);\n      _MHD_POISON_MEMORY ((uint8_t *) old + new_size, old_size - new_size);\n    }\n    if (pool->pos ==\n        ROUND_TO_ALIGN_PLUS_RED_ZONE (old_offset + old_size))\n    {     /* \"old\" block is the last allocated block */\n      const size_t new_apos =\n        ROUND_TO_ALIGN_PLUS_RED_ZONE (old_offset + new_size);\n      if (! shrinking)\n      {                               /* Grow in-place, check for enough space. */\n        if ( (new_apos > pool->end) ||\n             (new_apos < pool->pos) ) /* Value wrap */\n          return NULL;                /* No space */\n      }\n      /* Resized in-place */\n      pool->pos = new_apos;\n      _MHD_UNPOISON_MEMORY (old, new_size);\n      return old;\n    }\n    if (shrinking)\n      return old;   /* Resized in-place, freed part remains allocated */\n  }\n  /* Need to allocate new block */\n  asize = ROUND_TO_ALIGN_PLUS_RED_ZONE (new_size);\n  if ( ( (0 == asize) &&\n         (0 != new_size) ) || /* Value wrap, too large new_size. */\n       (asize > pool->end - pool->pos) ) /* Not enough space */\n    return NULL;\n\n  new_blc = pool->memory + pool->pos;\n  pool->pos += asize;\n\n  _MHD_UNPOISON_MEMORY (new_blc, new_size);\n  if (0 != old_size)\n  {\n    /* Move data to new block, old block remains allocated */\n    memcpy (new_blc, old, old_size);\n    /* Zero-out old block */\n    memset (old, 0, old_size);\n    _MHD_POISON_MEMORY (old, old_size);\n  }\n  return new_blc;\n}\n```\n</target_code>\n<additional code>Here are the definitions of symbols that are related to the target function MHD_pool_reallocate:\nstruct MemoryPool\n{\n\n  /**\n   * Pointer to the pool's memory\n   */\n  uint8_t *memory;\n\n  /**\n   * Size of the pool.\n   */\n  size_t size;\n\n  /**\n   * Offset of the first unallocated byte.\n   */\n  size_t pos;\n\n  /**\n   * Offset of the byte after the last unallocated byte.\n   */\n  size_t end;\n\n  /**\n   * 'false' if pool was malloc'ed, 'true' if mmapped (VirtualAlloc'ed for W32).\n   */\n  bool is_mmap;\n}\n...\n#define ROUND_TO_ALIGN(n) (((n)+(ALIGN_SIZE-1))/(ALIGN_SIZE)*(ALIGN_SIZE))\n...\n#define ROUND_TO_ALIGN_PLUS_RED_ZONE(n) ROUND_TO_ALIGN(n)\n...\n#define _MHD_RED_ZONE_SIZE (0)\n...\n#define mp_ptr_diff_(p1, p2) ((size_t)(((constuint8_t*)(p1))-((constuint8_t*)(p2))))\n...\n#define mp_ptr_le_(p1, p2) (((constuint8_t*)(p1))<=((constuint8_t*)(p2)))\n...\n#define mhd_assert(ignore) ((void)0)\n...\n#define _MHD_POISON_MEMORY(pointer, size) (void)0\n...\n#define _MHD_UNPOISON_MEMORY(pointer, size) (void)0\n</additional code>\nPlease find suspicious code fragments in the code and report them. Other agents can not investigate other fragments that you do not report, so it is very important to find all suspicious fragments without missing any. Report the suspicious fragments AS MUCH AS POSSIBLE.",
  "suspicious_frags": [],
  "explanation": "I did not find any code fragment that is definitively unreachable (i.e. cannot be executed under any valid runtime conditions). Reasoning: \n\n- The function has two primary paths: old != NULL and old == NULL. Both are reachable depending on the caller's arguments.\n- Within the old != NULL path the code further splits on the runtime boolean shrinking (old_size > new_size) and on whether the old block is the last allocated block (pool->pos == ROUND_TO_ALIGN_PLUS_RED_ZONE(old_offset + old_size)). Each combination leads to a distinct, reachable outcome: shrinking & last-block \u2192 in-place shrink and return; shrinking & not-last \u2192 early return; not-shrinking & last-block \u2192 attempt in-place grow (may return NULL on insufficient space) or succeed and return; not-shrinking & not-last \u2192 fall through to allocate a new block and copy.\n- All return statements are reachable from at least one runtime path described above. The final allocation-and-copy path (following the old == NULL branch or a non-shrinking old != NULL path) is reachable whenever a reallocation requires a new block.\n- The guards that look impossible (for example the check new_apos < pool->pos) are deliberate overflow/wrap checks; they are reachable if an overflow/wrap occurs and thus are not dead code. The checks for asize == 0 with new_size != 0 similarly detect size_t wrap. These make the corresponding return NULL branches reachable in cases of arithmetic wrap or insufficient space.\n- The mhd_assert macros and the ASAN assertion are defined as no-ops in the provided context, so they do not introduce or hide any control flow; they merely vanish, and thus do not create unreachable code.\n\nGiven the above, there is no statement or block that is provably unreachable in all builds/executions; therefore there are no fragments that need investigation for MISRA C 2023 Rule 2.1 in this function."
}