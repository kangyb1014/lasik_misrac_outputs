{
  "user_message": "<misra_rule>\nThe target MISRA C 2023 Rule 17.2 is: Functions shall not call themselves, either directly or indirectly.\n\n</misra_rule>\n<instruction>\nOther agents will judge whether the code follows the MISRA C 2023 guidelines.\nThey will investigate the code fragments you give.\nYour job is to find code fragments in the code that should be investigated to check whether the code follows the MISRA C rule.\n</instruction>\n<response format>\nProvide your answer with these fields.\n- suspicious_frags: The list of suspicious code fragments in the code.\nIt should contain only the code fragments exists in the code. If you do not find any suspicious code fragments, return an empty list for suspicious_frags\n- explanation: The explanation of why other code fragments should NOT be investigated.\nIt is very important to not miss any suspicious code fragments, so please give a sufficient explanation why other code fragments should not be investigated.\nDO NOT give any explanation for the selected suspicious code fragments.\n</response format>\n<target_code>\nHere is the code of MHD_pool_reallocate:\n```c\nvoid *\nMHD_pool_reallocate (struct MemoryPool *pool,\n                     void *old,\n                     size_t old_size,\n                     size_t new_size)\n{\n  size_t asize;\n  uint8_t *new_blc;\n\n  mhd_assert (pool->end >= pool->pos);\n  mhd_assert (pool->size >= pool->end - pool->pos);\n  mhd_assert (old != NULL || old_size == 0);\n  mhd_assert (pool->size >= old_size);\n  mhd_assert (pool->pos == ROUND_TO_ALIGN (pool->pos));\n#if defined(MHD_ASAN_POISON_ACTIVE) && defined(HAVE___ASAN_REGION_IS_POISONED)\n  mhd_assert (NULL == __asan_region_is_poisoned (old, old_size));\n#endif /* MHD_ASAN_POISON_ACTIVE && HAVE___ASAN_REGION_IS_POISONED */\n\n  if (NULL != old)\n  {   /* Have previously allocated data */\n    const size_t old_offset = mp_ptr_diff_ (old, pool->memory);\n    const bool shrinking = (old_size > new_size);\n\n    mhd_assert (mp_ptr_le_ (pool->memory, old));\n    /* (pool->memory + pool->size >= (uint8_t*) old + old_size) */\n    mhd_assert ((pool->size - _MHD_RED_ZONE_SIZE) >= (old_offset + old_size));\n    /* Blocks \"from the end\" must not be reallocated */\n    /* (old_size == 0 || pool->memory + pool->pos > (uint8_t*) old) */\n    mhd_assert ((old_size == 0) || \\\n                (pool->pos > old_offset));\n    mhd_assert ((old_size == 0) || \\\n                ((pool->end - _MHD_RED_ZONE_SIZE) >= (old_offset + old_size)));\n    /* Try resizing in-place */\n    if (shrinking)\n    {     /* Shrinking in-place, zero-out freed part */\n      memset ((uint8_t *) old + new_size, 0, old_size - new_size);\n      _MHD_POISON_MEMORY ((uint8_t *) old + new_size, old_size - new_size);\n    }\n    if (pool->pos ==\n        ROUND_TO_ALIGN_PLUS_RED_ZONE (old_offset + old_size))\n    {     /* \"old\" block is the last allocated block */\n      const size_t new_apos =\n        ROUND_TO_ALIGN_PLUS_RED_ZONE (old_offset + new_size);\n      if (! shrinking)\n      {                               /* Grow in-place, check for enough space. */\n        if ( (new_apos > pool->end) ||\n             (new_apos < pool->pos) ) /* Value wrap */\n          return NULL;                /* No space */\n      }\n      /* Resized in-place */\n      pool->pos = new_apos;\n      _MHD_UNPOISON_MEMORY (old, new_size);\n      return old;\n    }\n    if (shrinking)\n      return old;   /* Resized in-place, freed part remains allocated */\n  }\n  /* Need to allocate new block */\n  asize = ROUND_TO_ALIGN_PLUS_RED_ZONE (new_size);\n  if ( ( (0 == asize) &&\n         (0 != new_size) ) || /* Value wrap, too large new_size. */\n       (asize > pool->end - pool->pos) ) /* Not enough space */\n    return NULL;\n\n  new_blc = pool->memory + pool->pos;\n  pool->pos += asize;\n\n  _MHD_UNPOISON_MEMORY (new_blc, new_size);\n  if (0 != old_size)\n  {\n    /* Move data to new block, old block remains allocated */\n    memcpy (new_blc, old, old_size);\n    /* Zero-out old block */\n    memset (old, 0, old_size);\n    _MHD_POISON_MEMORY (old, old_size);\n  }\n  return new_blc;\n}\n```\n</target_code>\n<additional code>Here are the definitions of symbols that are related to the target function MHD_pool_reallocate:\n#define mhd_assert(ignore) ((void)0)\n...\n#define ROUND_TO_ALIGN(n) (((n)+(ALIGN_SIZE-1))/(ALIGN_SIZE)*(ALIGN_SIZE))\n...\n#define ROUND_TO_ALIGN_PLUS_RED_ZONE(n) ROUND_TO_ALIGN(n)\n...\n#define mp_ptr_diff_(p1, p2) ((size_t)(((constuint8_t*)(p1))-((constuint8_t*)(p2))))\n...\n#define mp_ptr_le_(p1, p2) (((constuint8_t*)(p1))<=((constuint8_t*)(p2)))\n...\n#define _MHD_POISON_MEMORY(pointer, size) (void)0\n...\n#define _MHD_UNPOISON_MEMORY(pointer, size) (void)0\n...\n#define _MHD_RED_ZONE_SIZE (0)\n...\nstruct MemoryPool\n{\n\n  /**\n   * Pointer to the pool's memory\n   */\n  uint8_t *memory;\n\n  /**\n   * Size of the pool.\n   */\n  size_t size;\n\n  /**\n   * Offset of the first unallocated byte.\n   */\n  size_t pos;\n\n  /**\n   * Offset of the byte after the last unallocated byte.\n   */\n  size_t end;\n\n  /**\n   * 'false' if pool was malloc'ed, 'true' if mmapped (VirtualAlloc'ed for W32).\n   */\n  bool is_mmap;\n}\n...\nvoid *\nMHD_connection_alloc_memory_ (struct MHD_Connection *connection,\n                              size_t size)\n{\n  struct MHD_Connection *const c = connection; /* a short alias */\n  struct MemoryPool *const pool = c->pool;     /* a short alias */\n  size_t need_to_be_freed = 0; /**< The required amount of additional free memory */\n  void *res;\n\n  res = MHD_pool_try_alloc (pool,\n                            size,\n                            &need_to_be_freed);\n  if (NULL != res)\n    return res;\n\n  if (MHD_pool_is_resizable_inplace (pool,\n                                     c->write_buffer,\n                                     c->write_buffer_size))\n  {\n    if (c->write_buffer_size - c->write_buffer_append_offset >=\n        need_to_be_freed)\n    {\n      char *buf;\n      const size_t new_buf_size = c->write_buffer_size - need_to_be_freed;\n      buf = MHD_pool_reallocate (pool,\n                                 c->write_buffer,\n                                 c->write_buffer_size,\n                                 new_buf_size);\n      mhd_assert (c->write_buffer == buf);\n      mhd_assert (c->write_buffer_append_offset <= new_buf_size);\n      mhd_assert (c->write_buffer_send_offset <= new_buf_size);\n      c->write_buffer_size = new_buf_size;\n      c->write_buffer = buf;\n    }\n    else\n      return NULL;\n  }\n  else if (MHD_pool_is_resizable_inplace (pool,\n                                          c->read_buffer,\n                                          c->read_buffer_size))\n  {\n    if (c->read_buffer_size - c->read_buffer_offset >= need_to_be_freed)\n    {\n      char *buf;\n      const size_t new_buf_size = c->read_buffer_size - need_to_be_freed;\n      buf = MHD_pool_reallocate (pool,\n                                 c->read_buffer,\n                                 c->read_buffer_size,\n                                 new_buf_size);\n      mhd_assert (c->read_buffer == buf);\n      mhd_assert (c->read_buffer_offset <= new_buf_size);\n      c->read_buffer_size = new_buf_size;\n      c->read_buffer = buf;\n    }\n    else\n      return NULL;\n  }\n  else\n    return NULL;\n  res = MHD_pool_allocate (pool, size, true);\n  mhd_assert (NULL != res); /* It has been checked that pool has enough space */\n  return res;\n}\n...\nstatic enum MHD_Result\ntry_ready_chunked_body (struct MHD_Connection *connection,\n                        bool *p_finished)\n{\n  ssize_t ret;\n  struct MHD_Response *response;\n  static const size_t max_chunk = 0xFFFFFF;\n  char chunk_hdr[6];            /* 6: max strlen of \"FFFFFF\" */\n  /* \"FFFFFF\" + \"\\r\\n\" */\n  static const size_t max_chunk_hdr_len = sizeof(chunk_hdr) + 2;\n  /* \"FFFFFF\" + \"\\r\\n\" + \"\\r\\n\" (chunk termination) */\n  static const size_t max_chunk_overhead = sizeof(chunk_hdr) + 2 + 2;\n  size_t chunk_hdr_len;\n  uint64_t left_to_send;\n  size_t size_to_fill;\n\n  response = connection->rp.response;\n  mhd_assert (NULL != response->crc || NULL != response->data);\n\n  mhd_assert (0 == connection->write_buffer_append_offset);\n\n  /* The buffer must be reasonably large enough */\n  if (128 > connection->write_buffer_size)\n  {\n    size_t size;\n\n    size = connection->write_buffer_size + MHD_pool_get_free (connection->pool);\n    if (128 > size)\n    {\n#if defined(MHD_USE_POSIX_THREADS) || defined(MHD_USE_W32_THREADS)\n      MHD_mutex_unlock_chk_ (&response->mutex);\n#endif\n      /* not enough memory */\n      CONNECTION_CLOSE_ERROR (connection,\n                              _ (\"Closing connection (out of memory).\"));\n      return MHD_NO;\n    }\n    /* Limit the buffer size to the largest usable size for chunks */\n    if ( (max_chunk + max_chunk_overhead) < size)\n      size = max_chunk + max_chunk_overhead;\n    mhd_assert ((NULL == connection->write_buffer) || \\\n                MHD_pool_is_resizable_inplace (connection->pool, \\\n                                               connection->write_buffer, \\\n                                               connection->write_buffer_size));\n    connection->write_buffer =\n      MHD_pool_reallocate (connection->pool,\n                           connection->write_buffer,\n                           connection->write_buffer_size,\n                           size);\n    mhd_assert (NULL != connection->write_buffer);\n    connection->write_buffer_size = size;\n  }\n  mhd_assert (max_chunk_overhead < connection->write_buffer_size);\n\n  if (MHD_SIZE_UNKNOWN == response->total_size)\n    left_to_send = MHD_SIZE_UNKNOWN;\n  else\n    left_to_send = response->total_size\n                   - connection->rp.rsp_write_position;\n\n  size_to_fill = connection->write_buffer_size - max_chunk_overhead;\n  /* Limit size for the callback to the max usable size */\n  if (max_chunk < size_to_fill)\n    size_to_fill = max_chunk;\n  if (left_to_send < size_to_fill)\n    size_to_fill = (size_t) left_to_send;\n\n  if (0 == left_to_send)\n    /* nothing to send, don't bother calling crc */\n    ret = MHD_CONTENT_READER_END_OF_STREAM;\n  else if ( (response->data_start <=\n             connection->rp.rsp_write_position) &&\n            (response->data_start + response->data_size >\n             connection->rp.rsp_write_position) )\n  {\n    /* difference between rsp_write_position and data_start is less\n       than data_size which is size_t type, no need to check for overflow */\n    const size_t data_write_offset\n      = (size_t) (connection->rp.rsp_write_position\n                  - response->data_start);\n    /* buffer already ready, use what is there for the chunk */\n    mhd_assert (SSIZE_MAX >= (response->data_size - data_write_offset));\n    mhd_assert (response->data_size >= data_write_offset);\n    ret = (ssize_t) (response->data_size - data_write_offset);\n    if ( ((size_t) ret) > size_to_fill)\n      ret = (ssize_t) size_to_fill;\n    memcpy (&connection->write_buffer[max_chunk_hdr_len],\n            &response->data[data_write_offset],\n            (size_t) ret);\n  }\n  else\n  {\n    if (NULL == response->crc)\n    { /* There is no way to reach this code */\n#if defined(MHD_USE_THREADS)\n      MHD_mutex_unlock_chk_ (&response->mutex);\n#endif\n      CONNECTION_CLOSE_ERROR (connection,\n                              _ (\"No callback for the chunked data.\"));\n      return MHD_NO;\n    }\n    ret = response->crc (response->crc_cls,\n                         connection->rp.rsp_write_position,\n                         &connection->write_buffer[max_chunk_hdr_len],\n                         size_to_fill);\n  }\n  if (MHD_CONTENT_READER_END_WITH_ERROR == ret)\n  {\n    /* error, close socket! */\n    /* TODO: remove update of the response size */\n    response->total_size = connection->rp.rsp_write_position;\n#if defined(MHD_USE_POSIX_THREADS) || defined(MHD_USE_W32_THREADS)\n    MHD_mutex_unlock_chk_ (&response->mutex);\n#endif\n    CONNECTION_CLOSE_ERROR (connection,\n                            _ (\"Closing connection (application error \" \\\n                               \"generating response).\"));\n    return MHD_NO;\n  }\n  if (MHD_CONTENT_READER_END_OF_STREAM == ret)\n  {\n    *p_finished = true;\n    /* TODO: remove update of the response size */\n    response->total_size = connection->rp.rsp_write_position;\n    return MHD_YES;\n  }\n  if (0 == ret)\n  {\n    connection->state = MHD_CONNECTION_CHUNKED_BODY_UNREADY;\n#if defined(MHD_USE_POSIX_THREADS) || defined(MHD_USE_W32_THREADS)\n    MHD_mutex_unlock_chk_ (&response->mutex);\n#endif\n    return MHD_NO;\n  }\n  if (size_to_fill < (size_t) ret)\n  {\n#if defined(MHD_USE_THREADS)\n    MHD_mutex_unlock_chk_ (&response->mutex);\n#endif\n    CONNECTION_CLOSE_ERROR (connection,\n                            _ (\"Closing connection (application returned \" \\\n                               \"more data than requested).\"));\n    return MHD_NO;\n  }\n  chunk_hdr_len = MHD_uint32_to_strx ((uint32_t) ret, chunk_hdr,\n                                      sizeof(chunk_hdr));\n  mhd_assert (chunk_hdr_len != 0);\n  mhd_assert (chunk_hdr_len < sizeof(chunk_hdr));\n  *p_finished = false;\n  connection->write_buffer_send_offset =\n    (max_chunk_hdr_len - (chunk_hdr_len + 2));\n  memcpy (connection->write_buffer + connection->write_buffer_send_offset,\n          chunk_hdr,\n          chunk_hdr_len);\n  connection->write_buffer[max_chunk_hdr_len - 2] = '\\r';\n  connection->write_buffer[max_chunk_hdr_len - 1] = '\\n';\n  connection->write_buffer[max_chunk_hdr_len + (size_t) ret] = '\\r';\n  connection->write_buffer[max_chunk_hdr_len + (size_t) ret + 1] = '\\n';\n  connection->rp.rsp_write_position += (size_t) ret;\n  connection->write_buffer_append_offset = max_chunk_hdr_len + (size_t) ret + 2;\n  return MHD_YES;\n}\n...\nstatic bool\ntry_grow_read_buffer (struct MHD_Connection *connection,\n                      bool required)\n{\n  size_t new_size;\n  size_t avail_size;\n  const size_t def_grow_size = connection->daemon->pool_increment;\n  void *rb;\n\n  avail_size = MHD_pool_get_free (connection->pool);\n  if (0 == avail_size)\n    return false;               /* No more space available */\n  if (0 == connection->read_buffer_size)\n    new_size = avail_size / 2;  /* Use half of available buffer for reading */\n  else\n  {\n    size_t grow_size;\n\n    grow_size = avail_size / 8;\n    if (def_grow_size > grow_size)\n    {                  /* Shortage of space */\n      const size_t left_free =\n        connection->read_buffer_size - connection->read_buffer_offset;\n      mhd_assert (connection->read_buffer_size >= \\\n                  connection->read_buffer_offset);\n      if ((def_grow_size <= grow_size + left_free)\n          && (left_free < def_grow_size))\n        grow_size = def_grow_size - left_free;  /* Use precise 'def_grow_size' for new free space */\n      else if (! required)\n        return false;                           /* Grow is not mandatory, leave some space in pool */\n      else\n      {\n        /* Shortage of space, but grow is mandatory */\n        const size_t small_inc =\n          ((MHD_BUF_INC_SIZE > def_grow_size) ?\n           def_grow_size : MHD_BUF_INC_SIZE) / 8;\n        if (small_inc < avail_size)\n          grow_size = small_inc;\n        else\n          grow_size = avail_size;\n      }\n    }\n    new_size = connection->read_buffer_size + grow_size;\n  }\n  /* Make sure that read buffer will not be moved */\n  if ((NULL != connection->read_buffer) &&\n      ! MHD_pool_is_resizable_inplace (connection->pool,\n                                       connection->read_buffer,\n                                       connection->read_buffer_size))\n  {\n    mhd_assert (0);\n    return false;\n  }\n  /* we can actually grow the buffer, do it! */\n  rb = MHD_pool_reallocate (connection->pool,\n                            connection->read_buffer,\n                            connection->read_buffer_size,\n                            new_size);\n  if (NULL == rb)\n  {\n    /* This should NOT be possible: we just computed 'new_size' so that\n       it should fit. If it happens, somehow our read buffer is not in\n       the right position in the pool, say because someone called\n       MHD_pool_allocate() without 'from_end' set to 'true'? Anyway,\n       should be investigated! (Ideally provide all data from\n       *pool and connection->read_buffer and new_size for debugging). */\n    mhd_assert (0);\n    return false;\n  }\n  mhd_assert (connection->read_buffer == rb);\n  connection->read_buffer = rb;\n  mhd_assert (NULL != connection->read_buffer);\n  connection->read_buffer_size = new_size;\n  return true;\n}\n...\nstatic void\nconnection_shrink_read_buffer (struct MHD_Connection *connection)\n{\n  struct MHD_Connection *const c = connection; /**< a short alias */\n  void *new_buf;\n\n  if ((NULL == c->read_buffer) || (0 == c->read_buffer_size))\n  {\n    mhd_assert (0 == c->read_buffer_size);\n    mhd_assert (0 == c->read_buffer_offset);\n    return;\n  }\n\n  mhd_assert (c->read_buffer_offset <= c->read_buffer_size);\n  if (0 == c->read_buffer_offset)\n  {\n    MHD_pool_deallocate (c->pool, c->read_buffer, c->read_buffer_size);\n    c->read_buffer = NULL;\n    c->read_buffer_size = 0;\n  }\n  else\n  {\n    mhd_assert (MHD_pool_is_resizable_inplace (c->pool, c->read_buffer, \\\n                                               c->read_buffer_size));\n    new_buf = MHD_pool_reallocate (c->pool, c->read_buffer, c->read_buffer_size,\n                                   c->read_buffer_offset);\n    mhd_assert (c->read_buffer == new_buf);\n    c->read_buffer = new_buf;\n    c->read_buffer_size = c->read_buffer_offset;\n  }\n}\n...\nstatic size_t\nconnection_maximize_write_buffer (struct MHD_Connection *connection)\n{\n  struct MHD_Connection *const c = connection; /**< a short alias */\n  struct MemoryPool *const pool = connection->pool;\n  void *new_buf;\n  size_t new_size;\n  size_t free_size;\n\n  mhd_assert ((NULL != c->write_buffer) || (0 == c->write_buffer_size));\n  mhd_assert (c->write_buffer_append_offset >= c->write_buffer_send_offset);\n  mhd_assert (c->write_buffer_size >= c->write_buffer_append_offset);\n\n  free_size = MHD_pool_get_free (pool);\n  if (0 != free_size)\n  {\n    new_size = c->write_buffer_size + free_size;\n    /* This function must not move the buffer position.\n     * MHD_pool_reallocate () may return the new position only if buffer was\n     * allocated 'from_end' or is not the last allocation,\n     * which should not happen. */\n    mhd_assert ((NULL == c->write_buffer) || \\\n                MHD_pool_is_resizable_inplace (pool, c->write_buffer, \\\n                                               c->write_buffer_size));\n    new_buf = MHD_pool_reallocate (pool,\n                                   c->write_buffer,\n                                   c->write_buffer_size,\n                                   new_size);\n    mhd_assert ((c->write_buffer == new_buf) || (NULL == c->write_buffer));\n    c->write_buffer = new_buf;\n    c->write_buffer_size = new_size;\n    if (c->write_buffer_send_offset == c->write_buffer_append_offset)\n    {\n      /* All data have been sent, reset offsets to zero. */\n      c->write_buffer_send_offset = 0;\n      c->write_buffer_append_offset = 0;\n    }\n  }\n\n  return c->write_buffer_size - c->write_buffer_append_offset;\n}\n...\nvoid\nMHD_connection_handle_read (struct MHD_Connection *connection,\n                            bool socket_error)\n{\n  ssize_t bytes_read;\n\n  if ( (MHD_CONNECTION_CLOSED == connection->state) ||\n       (connection->suspended) )\n    return;\n#ifdef HTTPS_SUPPORT\n  if (MHD_TLS_CONN_NO_TLS != connection->tls_state)\n  {   /* HTTPS connection. */\n    if (MHD_TLS_CONN_CONNECTED > connection->tls_state)\n    {\n      if (! MHD_run_tls_handshake_ (connection))\n        return;\n    }\n  }\n#endif /* HTTPS_SUPPORT */\n\n  mhd_assert (NULL != connection->read_buffer);\n  if (connection->read_buffer_size == connection->read_buffer_offset)\n    return; /* No space for receiving data. */\n\n  bytes_read = connection->recv_cls (connection,\n                                     &connection->read_buffer\n                                     [connection->read_buffer_offset],\n                                     connection->read_buffer_size\n                                     - connection->read_buffer_offset);\n  if ((bytes_read < 0) || socket_error)\n  {\n    if ((MHD_ERR_AGAIN_ == bytes_read) && ! socket_error)\n      return;     /* No new data to process. */\n    if ((bytes_read > 0) && connection->sk_nonblck)\n    { /* Try to detect the socket error */\n      int dummy;\n      bytes_read = connection->recv_cls (connection, &dummy, sizeof (dummy));\n    }\n    if (MHD_ERR_CONNRESET_ == bytes_read)\n    {\n      if ( (MHD_CONNECTION_INIT < connection->state) &&\n           (MHD_CONNECTION_FULL_REQ_RECEIVED > connection->state) )\n      {\n#ifdef HAVE_MESSAGES\n        MHD_DLOG (connection->daemon,\n                  _ (\"Socket has been disconnected when reading request.\\n\"));\n#endif\n        connection->discard_request = true;\n      }\n      MHD_connection_close_ (connection,\n                             MHD_REQUEST_TERMINATED_READ_ERROR);\n      return;\n    }\n\n#ifdef HAVE_MESSAGES\n    if (MHD_CONNECTION_INIT != connection->state)\n      MHD_DLOG (connection->daemon,\n                _ (\"Connection socket is closed when reading \" \\\n                   \"request due to the error: %s\\n\"),\n                (bytes_read < 0) ? str_conn_error_ (bytes_read) :\n                \"detected connection closure\");\n#endif\n    CONNECTION_CLOSE_ERROR (connection,\n                            NULL);\n    return;\n  }\n\n  if (0 == bytes_read)\n  {   /* Remote side closed connection. */\n    connection->read_closed = true;\n    if ( (MHD_CONNECTION_INIT < connection->state) &&\n         (MHD_CONNECTION_FULL_REQ_RECEIVED > connection->state) )\n    {\n#ifdef HAVE_MESSAGES\n      MHD_DLOG (connection->daemon,\n                _ (\"Connection was closed by remote side with incomplete \"\n                   \"request.\\n\"));\n#endif\n      connection->discard_request = true;\n      MHD_connection_close_ (connection,\n                             MHD_REQUEST_TERMINATED_CLIENT_ABORT);\n    }\n    else if (MHD_CONNECTION_INIT == connection->state)\n      /* This termination code cannot be reported to the application\n       * because application has not been informed yet about this request */\n      MHD_connection_close_ (connection,\n                             MHD_REQUEST_TERMINATED_COMPLETED_OK);\n    else\n      MHD_connection_close_ (connection,\n                             MHD_REQUEST_TERMINATED_WITH_ERROR);\n    return;\n  }\n  connection->read_buffer_offset += (size_t) bytes_read;\n  MHD_update_last_activity_ (connection);\n#if DEBUG_STATES\n  MHD_DLOG (connection->daemon,\n            _ (\"In function %s handling connection at state: %s\\n\"),\n            MHD_FUNC_,\n            MHD_state_to_string (connection->state));\n#endif\n  /* TODO: check whether the next 'switch()' really needed */\n  switch (connection->state)\n  {\n  case MHD_CONNECTION_INIT:\n  case MHD_CONNECTION_REQ_LINE_RECEIVING:\n  case MHD_CONNECTION_REQ_HEADERS_RECEIVING:\n  case MHD_CONNECTION_BODY_RECEIVING:\n  case MHD_CONNECTION_FOOTERS_RECEIVING:\n  case MHD_CONNECTION_FULL_REQ_RECEIVED:\n    /* nothing to do but default action */\n    if (connection->read_closed)\n    {\n      /* TODO: check whether this really needed */\n      MHD_connection_close_ (connection,\n                             MHD_REQUEST_TERMINATED_READ_ERROR);\n    }\n    return;\n  case MHD_CONNECTION_CLOSED:\n    return;\n#ifdef UPGRADE_SUPPORT\n  case MHD_CONNECTION_UPGRADE:\n    mhd_assert (0);\n    return;\n#endif /* UPGRADE_SUPPORT */\n  case MHD_CONNECTION_START_REPLY:\n    /* shrink read buffer to how much is actually used */\n    /* TODO: remove shrink as it handled in special function */\n    if ((0 != connection->read_buffer_size) &&\n        (connection->read_buffer_size != connection->read_buffer_offset))\n    {\n      mhd_assert (NULL != connection->read_buffer);\n      connection->read_buffer =\n        MHD_pool_reallocate (connection->pool,\n                             connection->read_buffer,\n                             connection->read_buffer_size,\n                             connection->read_buffer_offset);\n      connection->read_buffer_size = connection->read_buffer_offset;\n    }\n    break;\n  case MHD_CONNECTION_REQ_LINE_RECEIVED:\n  case MHD_CONNECTION_HEADERS_RECEIVED:\n  case MHD_CONNECTION_HEADERS_PROCESSED:\n  case MHD_CONNECTION_BODY_RECEIVED:\n  case MHD_CONNECTION_FOOTERS_RECEIVED:\n    /* Milestone state, no data should be read */\n    mhd_assert (0); /* Should not be possible */\n    break;\n  case MHD_CONNECTION_CONTINUE_SENDING:\n  case MHD_CONNECTION_HEADERS_SENDING:\n  case MHD_CONNECTION_HEADERS_SENT:\n  case MHD_CONNECTION_NORMAL_BODY_UNREADY:\n  case MHD_CONNECTION_NORMAL_BODY_READY:\n  case MHD_CONNECTION_CHUNKED_BODY_UNREADY:\n  case MHD_CONNECTION_CHUNKED_BODY_READY:\n  case MHD_CONNECTION_CHUNKED_BODY_SENT:\n  case MHD_CONNECTION_FOOTERS_SENDING:\n  case MHD_CONNECTION_FULL_REPLY_SENT:\n  default:\n    mhd_assert (0); /* Should not be possible */\n    break;\n  }\n  return;\n}\n...\nvoid *\nMHD_pool_try_alloc (struct MemoryPool *pool,\n                    size_t size,\n                    size_t *required_bytes)\n{\n  void *ret;\n  size_t asize;\n\n  mhd_assert (pool->end >= pool->pos);\n  mhd_assert (pool->size >= pool->end - pool->pos);\n  mhd_assert (pool->pos == ROUND_TO_ALIGN (pool->pos));\n  asize = ROUND_TO_ALIGN_PLUS_RED_ZONE (size);\n  if ( (0 == asize) && (0 != size) )\n  { /* size is too close to SIZE_MAX, very unlikely */\n    *required_bytes = SIZE_MAX;\n    return NULL;\n  }\n  if (asize > pool->end - pool->pos)\n  {\n    mhd_assert ((pool->end - pool->pos) == \\\n                ROUND_TO_ALIGN (pool->end - pool->pos));\n    if (asize <= pool->end)\n      *required_bytes = asize - (pool->end - pool->pos);\n    else\n      *required_bytes = SIZE_MAX;\n    return NULL;\n  }\n  *required_bytes = 0;\n  ret = &pool->memory[pool->end - asize];\n  pool->end -= asize;\n  _MHD_UNPOISON_MEMORY (ret, size);\n  return ret;\n}\n...\nvoid *\nMHD_pool_allocate (struct MemoryPool *pool,\n                   size_t size,\n                   bool from_end)\n{\n  void *ret;\n  size_t asize;\n\n  mhd_assert (pool->end >= pool->pos);\n  mhd_assert (pool->size >= pool->end - pool->pos);\n  mhd_assert (pool->pos == ROUND_TO_ALIGN (pool->pos));\n  asize = ROUND_TO_ALIGN_PLUS_RED_ZONE (size);\n  if ( (0 == asize) && (0 != size) )\n    return NULL; /* size too close to SIZE_MAX */\n  if (asize > pool->end - pool->pos)\n    return NULL;\n  if (from_end)\n  {\n    ret = &pool->memory[pool->end - asize];\n    pool->end -= asize;\n  }\n  else\n  {\n    ret = &pool->memory[pool->pos];\n    pool->pos += asize;\n  }\n  _MHD_UNPOISON_MEMORY (ret, size);\n  return ret;\n}\n...\nsize_t\nMHD_pool_get_free (struct MemoryPool *pool)\n{\n  mhd_assert (pool->end >= pool->pos);\n  mhd_assert (pool->size >= pool->end - pool->pos);\n  mhd_assert (pool->pos == ROUND_TO_ALIGN (pool->pos));\n#ifdef MHD_ASAN_POISON_ACTIVE\n  if ((pool->end - pool->pos) <= _MHD_RED_ZONE_SIZE)\n    return 0;\n#endif /* MHD_ASAN_POISON_ACTIVE */\n  return (pool->end - pool->pos) - _MHD_RED_ZONE_SIZE;\n}\n...\nvoid\nMHD_pool_deallocate (struct MemoryPool *pool,\n                     void *block,\n                     size_t block_size)\n{\n  mhd_assert (pool->end >= pool->pos);\n  mhd_assert (pool->size >= pool->end - pool->pos);\n  mhd_assert (block != NULL || block_size == 0);\n  mhd_assert (pool->size >= block_size);\n  mhd_assert (pool->pos == ROUND_TO_ALIGN (pool->pos));\n\n  if (NULL != block)\n  {   /* Have previously allocated data */\n    const size_t block_offset = mp_ptr_diff_ (block, pool->memory);\n    mhd_assert (mp_ptr_le_ (pool->memory, block));\n    mhd_assert (block_offset <= pool->size);\n    mhd_assert ((block_offset != pool->pos) || (block_size == 0));\n    /* Zero-out deallocated region */\n    if (0 != block_size)\n    {\n      memset (block, 0, block_size);\n      _MHD_POISON_MEMORY (block, block_size);\n    }\n#if ! defined(MHD_FAVOR_SMALL_CODE) && ! defined(MHD_ASAN_POISON_ACTIVE)\n    else\n      return; /* Zero size, no need to do anything */\n#endif /* ! MHD_FAVOR_SMALL_CODE && ! MHD_ASAN_POISON_ACTIVE */\n    if (block_offset <= pool->pos)\n    {\n      /* \"Normal\" block, not allocated \"from the end\". */\n      const size_t alg_end =\n        ROUND_TO_ALIGN_PLUS_RED_ZONE (block_offset + block_size);\n      mhd_assert (alg_end <= pool->pos);\n      if (alg_end == pool->pos)\n      {\n        /* The last allocated block, return deallocated block to the pool */\n        size_t alg_start = ROUND_TO_ALIGN (block_offset);\n        mhd_assert (alg_start >= block_offset);\n#if defined(MHD_ASAN_POISON_ACTIVE)\n        if (alg_start != block_offset)\n        {\n          _MHD_POISON_MEMORY (pool->memory + block_offset, \\\n                              alg_start - block_offset);\n        }\n        else if (0 != alg_start)\n        {\n          bool need_red_zone_before;\n          mhd_assert (_MHD_RED_ZONE_SIZE <= alg_start);\n#if defined(HAVE___ASAN_REGION_IS_POISONED)\n          need_red_zone_before =\n            (NULL == __asan_region_is_poisoned (pool->memory\n                                                + alg_start\n                                                - _MHD_RED_ZONE_SIZE,\n                                                _MHD_RED_ZONE_SIZE));\n#elif defined(HAVE___ASAN_ADDRESS_IS_POISONED)\n          need_red_zone_before =\n            (0 == __asan_address_is_poisoned (pool->memory + alg_start - 1));\n#else  /* ! HAVE___ASAN_ADDRESS_IS_POISONED */\n          need_red_zone_before = true; /* Unknown, assume new red zone needed */\n#endif /* ! HAVE___ASAN_ADDRESS_IS_POISONED */\n          if (need_red_zone_before)\n          {\n            _MHD_POISON_MEMORY (pool->memory + alg_start, _MHD_RED_ZONE_SIZE);\n            alg_start += _MHD_RED_ZONE_SIZE;\n          }\n        }\n#endif /* MHD_ASAN_POISON_ACTIVE */\n        mhd_assert (alg_start <= pool->pos);\n        mhd_assert (alg_start == ROUND_TO_ALIGN (alg_start));\n        pool->pos = alg_start;\n      }\n    }\n    else\n    {\n      /* Allocated \"from the end\" block. */\n      /* The size and the pointers of such block should not be manipulated by\n         MHD code (block split is disallowed). */\n      mhd_assert (block_offset >= pool->end);\n      mhd_assert (ROUND_TO_ALIGN (block_offset) == block_offset);\n      if (block_offset == pool->end)\n      {\n        /* The last allocated block, return deallocated block to the pool */\n        const size_t alg_end =\n          ROUND_TO_ALIGN_PLUS_RED_ZONE (block_offset + block_size);\n        pool->end = alg_end;\n      }\n    }\n  }\n}\n...\nstatic void\nconnection_close_error (struct MHD_Connection *connection,\n                        const char *emsg)\n{\n  connection->stop_with_error = true;\n  connection->discard_request = true;\n#ifdef HAVE_MESSAGES\n  if (NULL != emsg)\n    MHD_DLOG (connection->daemon,\n              \"%s\\n\",\n              emsg);\n#else  /* ! HAVE_MESSAGES */\n  (void) emsg; /* Mute compiler warning. */\n#endif /* ! HAVE_MESSAGES */\n  MHD_connection_close_ (connection,\n                         MHD_REQUEST_TERMINATED_WITH_ERROR);\n}\n...\nsize_t\nMHD_uint32_to_strx (uint32_t val,\n                    char *buf,\n                    size_t buf_size)\n{\n  size_t o_pos = 0; /**< position of the output character */\n  int digit_pos = 8; /** zero-based, digit position in @a 'val' */\n  int digit;\n\n  /* Skip leading zeros */\n  do\n  {\n    digit_pos--;\n    digit = (int) (val >> 28);\n    val <<= 4;\n  } while ((0 == digit) && (0 != digit_pos));\n\n  while (o_pos < buf_size)\n  {\n    buf[o_pos++] =\n      (char) ((digit <= 9) ?\n              ('0' + (char) digit) :\n              ('A' + (char) digit - 10));\n    if (0 == digit_pos)\n      return o_pos;\n    digit_pos--;\n    digit = (int) (val >> 28);\n    val <<= 4;\n  }\n  return 0; /* The buffer is too small */\n}\n...\nvoid\nMHD_DLOG (const struct MHD_Daemon *daemon,\n          const char *format,\n          ...)\n{\n  va_list va;\n\n  if (0 == (daemon->options & MHD_USE_ERROR_LOG))\n    return;\n  va_start (va, format);\n  daemon->custom_error_log (daemon->custom_error_log_cls,\n                            format,\n                            va);\n  va_end (va);\n}\n...\nvoid\nMHD_connection_close_ (struct MHD_Connection *connection,\n                       enum MHD_RequestTerminationCode termination_code)\n{\n  struct MHD_Daemon *daemon = connection->daemon;\n  struct MHD_Response *resp = connection->rp.response;\n\n  mhd_assert (! connection->suspended);\n#ifdef MHD_USE_THREADS\n  mhd_assert ( (! MHD_D_IS_USING_THREADS_ (daemon)) || \\\n               MHD_thread_handle_ID_is_current_thread_ (connection->tid) );\n#endif /* MHD_USE_THREADS */\n  if ( (NULL != daemon->notify_completed) &&\n       (connection->rq.client_aware) )\n    daemon->notify_completed (daemon->notify_completed_cls,\n                              connection,\n                              &connection->rq.client_context,\n                              termination_code);\n  connection->rq.client_aware = false;\n  if (NULL != resp)\n  {\n    connection->rp.response = NULL;\n    MHD_destroy_response (resp);\n  }\n  if (NULL != connection->pool)\n  {\n    MHD_pool_destroy (connection->pool);\n    connection->pool = NULL;\n  }\n\n  MHD_connection_mark_closed_ (connection);\n}\n...\nstatic const char *\nstr_conn_error_ (ssize_t mhd_err_code)\n{\n  switch (mhd_err_code)\n  {\n  case MHD_ERR_AGAIN_:\n    return _ (\"The operation would block, retry later\");\n  case MHD_ERR_CONNRESET_:\n    return _ (\"The connection was forcibly closed by remote peer\");\n  case MHD_ERR_NOTCONN_:\n    return _ (\"The socket is not connected\");\n  case MHD_ERR_NOMEM_:\n    return _ (\"Not enough system resources to serve the request\");\n  case MHD_ERR_BADF_:\n    return _ (\"Bad FD value\");\n  case MHD_ERR_INVAL_:\n    return _ (\"Argument value is invalid\");\n  case MHD_ERR_OPNOTSUPP_:\n    return _ (\"Argument value is not supported\");\n  case MHD_ERR_PIPE_:\n    return _ (\"The socket is no longer available for sending\");\n  case MHD_ERR_TLS_:\n    return _ (\"TLS encryption or decryption error\");\n  default:\n    break;   /* Mute compiler warning */\n  }\n  if (0 <= mhd_err_code)\n    return _ (\"Not an error code\");\n\n  mhd_assert (0); /* Should never be reachable */\n  return _ (\"Wrong error code value\");\n}\n...\nvoid\nMHD_update_last_activity_ (struct MHD_Connection *connection)\n{\n  struct MHD_Daemon *daemon = connection->daemon;\n#if defined(MHD_USE_THREADS)\n  mhd_assert (NULL == daemon->worker_pool);\n#endif /* MHD_USE_THREADS */\n\n  if (0 == connection->connection_timeout_ms)\n    return;  /* Skip update of activity for connections\n               without timeout timer. */\n  if (connection->suspended)\n    return;  /* no activity on suspended connections */\n\n  connection->last_activity = MHD_monotonic_msec_counter ();\n  if (MHD_D_IS_USING_THREAD_PER_CONN_ (daemon))\n    return; /* each connection has personal timeout */\n\n  if (connection->connection_timeout_ms != daemon->connection_timeout_ms)\n    return; /* custom timeout, no need to move it in \"normal\" DLL */\n#if defined(MHD_USE_POSIX_THREADS) || defined(MHD_USE_W32_THREADS)\n  MHD_mutex_lock_chk_ (&daemon->cleanup_connection_mutex);\n#endif\n  /* move connection to head of timeout list (by remove + add operation) */\n  XDLL_remove (daemon->normal_timeout_head,\n               daemon->normal_timeout_tail,\n               connection);\n  XDLL_insert (daemon->normal_timeout_head,\n               daemon->normal_timeout_tail,\n               connection);\n#if defined(MHD_USE_POSIX_THREADS) || defined(MHD_USE_W32_THREADS)\n  MHD_mutex_unlock_chk_ (&daemon->cleanup_connection_mutex);\n#endif\n}\n</additional code>\nPlease find suspicious code fragments in the code and report them. Other agents can not investigate other fragments that you do not report, so it is very important to find all suspicious fragments without missing any. Report the suspicious fragments AS MUCH AS POSSIBLE.",
  "suspicious_frags": [],
  "explanation": "I inspected the code and the call graph involving MHD_pool_reallocate and the surrounding functions. MHD_pool_reallocate itself only invokes macros and library/helpers (ROUND_TO_ALIGN, ROUND_TO_ALIGN_PLUS_RED_ZONE, mp_ptr_diff_, mp_ptr_le_, memset, memcpy, _MHD_POISON_MEMORY, _MHD_UNPOISON_MEMORY and optionally __asan_region_is_poisoned). None of those are defined to call back into MHD_pool_reallocate or into any of the higher-level connection functions shown. The other functions that call MHD_pool_reallocate (e.g. MHD_connection_alloc_memory_, try_ready_chunked_body, try_grow_read_buffer, connection_shrink_read_buffer, connection_maximize_write_buffer, MHD_connection_handle_read) are not invoked from within MHD_pool_reallocate, and there are no function pointers passed into MHD_pool_reallocate that could cause an indirect callback. Macros such as mhd_assert and poison/unpoison are no-ops in the provided definitions. Therefore there is no direct or indirect self-call (recursion) present in the provided code fragments and no code fragments need further investigation for potential violation of MISRA C 2023 Rule 17.2."
}