{
  "user_message": "An agent A claimed that the following detect_process_cpu_core_count code violates the MISRA C 2023 rule 2.2.\n<misra_rule>\nMISRA C 2023 Rule 2.2 is A project shall not contain dead code.\nAny operation that is executed but whose removal would not affect program behaviour constitutes dead code. Notes:\n1. The behaviour of an embedded sytem is often determined not just by the nature of its actions, but also by the time at which they occur.\n2. unreachable code is not dead code, as it cannot be executed.\n3.Initialization is not the same as an assignment operation and is therfore not a candidate for dead code.\n</misra_rule>\n<target_code>\nHere is the original code of detect_process_cpu_core_count.\n```c\nstatic unsigned int\ndetect_process_cpu_core_count (void)\n{\n  unsigned int num_proc_cpu_cores;\n  unsigned int sys_cpu_cores;\n  int res;\n\n  sys_cpu_cores = get_cpu_core_count ();\n  res = mhd_tool_get_proc_cpu_count ();\n  if (0 > res)\n  {\n    fprintf (stderr, \"Cannot detect the number of logical CPU cores available \"\n             \"for this process.\\n\");\n    if (1 != sys_cpu_cores)\n      printf (\"Assuming all %u system logical CPU cores are available to run \"\n              \"threads of this process.\\n\", sys_cpu_cores);\n    else\n      printf (\"Assuming single logical CPU core available for this process.\\n\");\n    num_proc_cpu_cores = sys_cpu_cores;\n  }\n  else\n  {\n    printf (\"Detected %d logical CPU core%s available to run threads \"\n            \"of this process.\\n\", res, (1 == res) ? \"\" : \"s\");\n    num_proc_cpu_cores = (unsigned int) res;\n  }\n  if (num_proc_cpu_cores > sys_cpu_cores)\n  {\n    fprintf (stderr, \"WARNING: Detected number of CPU cores available \"\n             \"for this process (%u) is larger than detected number \"\n             \"of CPU cores on the system (%u).\\n\",\n             num_proc_cpu_cores, sys_cpu_cores);\n    num_proc_cpu_cores = sys_cpu_cores;\n    fprintf (stderr, \"Using %u as the number of logical CPU cores available \"\n             \"for this process.\\n\", num_proc_cpu_cores);\n  }\n  return num_proc_cpu_cores;\n}\n```\n</target_code>\n<response format>\nProvide your answer with these fields.\n- explanation: your evaluation of the scenario provided by the agent A.\n- is_report_correct: whether the report is correct or not (true/false). True means there is a violation.\n</response format>\n<scenario>\nThe agent A provided the following violation scenario:\nThe second call to get_process_cpu_core_count() inside the fprintf is redundant. get_process_cpu_core_count() caches its result in a static variable (and after the first call has no further side effects), so calling it again only repeats an operation whose removal (e.g. by storing the value returned by the first call in a local variable and using that) would not change program behaviour. That redundant executed operation constitutes dead code and thus violates MISRA C 2023 Rule 2.2.\n</scenario>\n<additional code>Here are the definitions of symbols that are close to the target function detect_process_cpu_core_count:\nstatic unsigned int\nget_cpu_core_count (void)\n{\n  static unsigned int num_cpu_cores = 0;\n  if (0 == num_cpu_cores)\n    num_cpu_cores = detect_cpu_core_count ();\n  return num_cpu_cores;\n}\n...\nstatic unsigned int\ndetect_cpu_core_count (void)\n{\n  int sys_cpu_count;\n  sys_cpu_count = mhd_tool_get_system_cpu_count ();\n  if (0 >= sys_cpu_count)\n  {\n    int proc_cpu_count;\n    fprintf (stderr, \"Failed to detect the number of logical CPU cores \"\n             \"available on the system.\\n\");\n    proc_cpu_count = mhd_tool_get_proc_cpu_count ();\n    if (0 < proc_cpu_count)\n    {\n      fprintf (stderr, \"The number of CPU cores available for this process \"\n               \"is used as a fallback.\\n\");\n      sys_cpu_count = proc_cpu_count;\n    }\n#ifdef MHD_REAL_CPU_COUNT\n    if (0 >= sys_cpu_count)\n    {\n      fprintf (stderr, \"configure-detected hardcoded number is used \"\n               \"as a fallback.\\n\");\n      sys_cpu_count = MHD_REAL_CPU_COUNT;\n    }\n#endif\n    if (0 >= sys_cpu_count)\n      sys_cpu_count = 1;\n    printf (\"Assuming %d logical CPU core%s on this system.\\n\", sys_cpu_count,\n            (1 == sys_cpu_count) ? \"\" : \"s\");\n  }\n  else\n  {\n    printf (\"Detected %d logical CPU core%s on this system.\\n\", sys_cpu_count,\n            (1 == sys_cpu_count) ? \"\" : \"s\");\n  }\n  return (unsigned int) sys_cpu_count;\n}\n...\nint\nmhd_tool_get_proc_cpu_count (void)\n{\n  int res;\n\n#if defined(__linux__) || defined(__GLIBC__)\n  /* On Linux kernel try first 'sched_getaffinity()' as it should be\n     the native API.\n     Also try it first on other kernels if Glibc is used. */\n  res = mhd_tool_get_proc_cpu_count_sched_getaffinity_ ();\n  if (0 < res)\n    return res;\n\n  res = mhd_tool_get_proc_cpu_count_cpuset_getaffinity_ ();\n  if (0 < res)\n    return res;\n#else  /* ! __linux__ && ! __GLIBC__ */\n  /* On non-Linux kernels 'cpuset_getaffinity()' could be the native API,\n     while 'sched_getaffinity()' could be implemented in compatibility layer. */\n  res = mhd_tool_get_proc_cpu_count_cpuset_getaffinity_ ();\n  if (0 < res)\n    return res;\n\n  res = mhd_tool_get_proc_cpu_count_sched_getaffinity_ ();\n  if (0 < res)\n    return res;\n#endif /* ! __linux__ && ! __GLIBC__ */\n\n  res = mhd_tool_get_proc_cpu_count_sched_getaffinity_np_ ();\n  if (0 < res)\n    return res;\n\n  res = mhd_tool_get_proc_cpu_count_w32_ ();\n  if (0 < res)\n    return res;\n\n  return -1;\n}\n...\nstatic int\nmhd_tool_get_proc_cpu_count_sched_getaffinity_ (void)\n{\n  int ret = -1;\n#if defined(HAVE_SCHED_GETAFFINITY) && defined(HAVE_GETPID)\n  /* Glibc style */\n  if (0 >= ret)\n  {\n    cpu_set_t cur_set;\n    if (0 == sched_getaffinity (getpid (), sizeof (cur_set), &cur_set))\n    {\n#ifdef HAVE_CPU_COUNT\n      ret = CPU_COUNT (&cur_set);\n#else  /* ! HAVE_CPU_COUNT */\n      unsigned int i;\n      ret = 0;\n      for (i = 0; i < CPU_SETSIZE_SAFE; ++i)\n      {\n        if (CPU_ISSET (i, &cur_set))\n          ++ret;\n      }\n      if (0 == ret)\n        ret = -1;\n#endif /* ! HAVE_CPU_COUNT */\n    }\n  }\n#ifdef HAVE_CPU_COUNT_S\n  if (0 >= ret)\n  {\n    /* Use 256 times larger size than size for default maximum CPU number.\n       Hopefully it would be enough even for exotic situations. */\n    static const unsigned int set_size_cpus = 256 * CPU_SETSIZE;\n    const size_t set_size_bytes = CPU_ALLOC_SIZE (set_size_cpus);\n    cpu_set_t *p_set;\n\n    p_set = CPU_ALLOC (set_size_cpus);\n    if (NULL != p_set)\n    {\n      if (0 == sched_getaffinity (getpid (), set_size_bytes, p_set))\n      {\n#ifndef MHD_FUNC_CPU_COUNT_S_GETS_CPUS\n        ret = CPU_COUNT_S (set_size_bytes, p_set);\n#else  /* MHD_FUNC_CPU_COUNT_S_GETS_CPUS */\n        ret = CPU_COUNT_S (set_size_cpus, p_set);\n#endif /* MHD_FUNC_CPU_COUNT_S_GETS_CPUS */\n      }\n      CPU_FREE (p_set);\n    }\n  }\n#endif /* HAVE_CPU_COUNT_S */\n#endif /* HAVE_SCHED_GETAFFINITY && HAVE_GETPID */\n  if (0 >= ret)\n    return -1;\n  return ret;\n}\n...\nstatic int\nmhd_tool_get_proc_cpu_count_cpuset_getaffinity_ (void)\n{\n  int ret = -1;\n#if defined(HAVE_CPUSET_GETAFFINITY)\n  /* FreeBSD style */\n  if (0 >= ret)\n  {\n    cpuset_t cur_mask;\n    /* The should get \"anonymous\" mask/set. The anonymous mask is always\n       a subset of the assigned set (which is a subset of the root set). */\n    if (0 == cpuset_getaffinity (CPU_LEVEL_WHICH, CPU_WHICH_PID, (id_t) -1,\n                                 sizeof (cur_mask), &cur_mask))\n    {\n#ifdef HAVE_CPU_COUNT\n      ret = CPU_COUNT (&cur_mask);\n#else  /* ! HAVE_CPU_COUNT */\n      unsigned int i;\n      ret = 0;\n      for (i = 0; i < CPU_SETSIZE_SAFE; ++i)\n      {\n        if (CPU_ISSET (i, &cur_mask))\n          ++ret;\n      }\n      if (0 == ret)\n        ret = -1;\n#endif /* ! HAVE_CPU_COUNT */\n    }\n  }\n#ifdef HAVE_CPU_COUNT_S\n  if (0 >= ret)\n  {\n    /* Use 256 times larger size than size for default maximum CPU number.\n       Hopefully it would be enough even for exotic situations. */\n    static const unsigned int mask_size_cpus = 256 * CPU_SETSIZE;\n    const size_t mask_size_bytes = CPU_ALLOC_SIZE (mask_size_cpus);\n    cpuset_t *p_mask;\n\n    p_mask = CPU_ALLOC (mask_size_cpus);\n    if (NULL != p_mask)\n    {\n      if (0 == cpuset_getaffinity (CPU_LEVEL_WHICH, CPU_WHICH_PID, (id_t) -1,\n                                   mask_size_bytes, p_mask))\n      {\n#ifndef MHD_FUNC_CPU_COUNT_S_GETS_CPUS\n        ret = CPU_COUNT_S (mask_size_bytes, p_mask);\n#else  /* MHD_FUNC_CPU_COUNT_S_GETS_CPUS */\n        ret = CPU_COUNT_S (mask_size_cpus, p_mask);\n#endif /* MHD_FUNC_CPU_COUNT_S_GETS_CPUS */\n      }\n      CPU_FREE (p_mask);\n    }\n  }\n#endif /* HAVE_CPU_COUNT_S */\n#endif /* HAVE_CPUSET_GETAFFINITY */\n  if (0 >= ret)\n    return -1;\n  return ret;\n}\n...\nstatic int\nmhd_tool_get_proc_cpu_count_sched_getaffinity_np_ (void)\n{\n  int ret = -1;\n#if defined(HAVE_SCHED_GETAFFINITY_NP) && defined(HAVE_GETPID)\n  /* NetBSD style */\n  cpuset_t *cpuset_ptr;\n  cpuset_ptr = cpuset_create ();\n  if (NULL != cpuset_ptr)\n  {\n    if (0 == sched_getaffinity_np (getpid (), cpuset_size (cpuset_ptr),\n                                   cpuset_ptr))\n    {\n      cpuid_t cpu_num;\n#if defined(HAVE_SYSCONF) && defined(HAVE_DECL__SC_NPROCESSORS_CONF)\n      unsigned int max_num = 0;\n      long sc_value;\n      sc_value = sysconf (_SC_NPROCESSORS_ONLN);\n      if (0 < sc_value)\n        max_num = (unsigned int) sc_value;\n      if (0 < max_num)\n      {\n        ret = 0;\n        for (cpu_num = 0; cpu_num < max_num; ++cpu_num)\n          if (0 < cpuset_isset (cpu_num, cpuset_ptr))\n            ++ret;\n      }\n      else /* Combined with the next 'if' */\n#endif /* HAVE_SYSCONF && HAVE_DECL__SC_NPROCESSORS_CONF */\n      if (1)\n      {\n        int res;\n        cpu_num = 0;\n        ret = 0;\n        do\n        {\n          res = cpuset_isset (cpu_num++, cpuset_ptr);\n          if (0 < res)\n            ++ret;\n        } while (0 <= res);\n      }\n#ifdef __NetBSD__\n      if (0 == ret)\n      {\n        /* On NetBSD \"unset\" affinity (exactly zero CPUs) means\n           \"all CPUs are available\". */\n        ret = mhd_tool_get_sys_cpu_count_sysctl_ ();\n      }\n#endif /* __NetBSD__ */\n    }\n    cpuset_destroy (cpuset_ptr);\n  }\n#endif /* HAVE_SCHED_GETAFFINITY_NP && HAVE_GETPID */\n  if (0 >= ret)\n    return -1;\n  return ret;\n}\n...\nstatic int\nmhd_tool_get_proc_cpu_count_w32_ (void)\n{\n  int ret = -1;\n#if defined(_WIN32) && ! defined(__CYGWIN__)\n  /* W32 Native */\n  /**\n   * Maximum used number of CPU groups.\n   * Improvement: Implement dynamic allocation when it would be reasonable\n   */\n#define MHDT_MAX_GROUP_COUNT 128\n  /**\n   * The count of logical CPUs as returned by GetProcessAffinityMask()\n   */\n  int count_by_proc_aff_mask;\n  count_by_proc_aff_mask = -1;\n  if (1)\n  {\n    DWORD_PTR proc_aff;\n    DWORD_PTR sys_aff;\n\n    if (GetProcessAffinityMask (GetCurrentProcess (), &proc_aff, &sys_aff))\n    {\n      /* Count all set bits */\n      for (count_by_proc_aff_mask = 0; 0 != proc_aff; proc_aff &= proc_aff - 1)\n        ++count_by_proc_aff_mask;\n    }\n  }\n  if (0 < count_by_proc_aff_mask)\n  {\n    HMODULE k32hndl;\n    k32hndl = LoadLibraryA (\"kernel32.dll\");\n    if (NULL != k32hndl)\n    {\n      typedef BOOL (WINAPI *GPGA_PTR)(HANDLE hProcess,\n                                      PUSHORT GroupCount,\n                                      PUSHORT GroupArray);\n      GPGA_PTR ptrGetProcessGroupAffinity;\n      ptrGetProcessGroupAffinity =\n        (GPGA_PTR) (void *) GetProcAddress (k32hndl,\n                                            \"GetProcessGroupAffinity\");\n      if (NULL == ptrGetProcessGroupAffinity)\n      {\n        /* Windows version before Win7 */\n        /* No processor groups supported, the process affinity mask gives full picture */\n        ret = count_by_proc_aff_mask;\n      }\n      else\n      {\n        /* Windows version Win7 or later */\n        /* Processor groups are supported */\n        USHORT arr_elements = MHDT_MAX_GROUP_COUNT;\n        USHORT groups_arr[MHDT_MAX_GROUP_COUNT]; /* Hopefully should be enough */\n        /* Improvement: Implement dynamic allocation when it would be reasonable */\n        /**\n         * Exactly one processor group is assigned to the process\n         */\n        bool single_cpu_group_assigned; /**< Exactly one processor group is assigned to the process */\n        struct mhdt_GR_AFFINITY\n        {\n          KAFFINITY Mask;\n          WORD Group;\n          WORD Reserved[3];\n        };\n        typedef BOOL (WINAPI *GPDCSM_PTR)(HANDLE Process,\n                                          struct mhdt_GR_AFFINITY *CpuSetMasks,\n                                          USHORT CpuSetMaskCount,\n                                          USHORT *RequiredMaskCount);\n        GPDCSM_PTR ptrGetProcessDefaultCpuSetMasks;\n        bool win_fe_or_later;\n        bool cpu_set_mask_assigned;\n\n        single_cpu_group_assigned = false;\n        if (ptrGetProcessGroupAffinity (GetCurrentProcess (), &arr_elements,\n                                        groups_arr))\n        {\n          if (1 == arr_elements)\n          {\n            /* Exactly one processor group assigned to the process */\n            single_cpu_group_assigned = true;\n#if 0 /* Disabled code */\n            /* The value returned by GetThreadGroupAffinity() is not relevant as\n               for the new threads the process affinity mask is used. */\n            ULONG_PTR proc_aff2;\n            typedef BOOL (WINAPI *GTGA_PTR)(HANDLE hThread,\n                                            struct mhdt_GR_AFFINITY *\n                                            GroupAffinity);\n            GTGA_PTR ptrGetThreadGroupAffinity;\n            ptrGetThreadGroupAffinity =\n              (GTGA_PTR) (void *) GetProcAddress (k32hndl,\n                                                  \"GetThreadGroupAffinity\");\n            if (NULL != ptrGetThreadGroupAffinity)\n            {\n              struct mhdt_GR_AFFINITY thr_gr_aff;\n              if (ptrGetThreadGroupAffinity (GetCurrentThread (), &thr_gr_aff))\n                proc_aff2 = (ULONG_PTR) thr_gr_aff.Mask;\n            }\n#endif /* Disabled code */\n          }\n        }\n        ptrGetProcessDefaultCpuSetMasks =\n          (GPDCSM_PTR) (void *) GetProcAddress (k32hndl,\n                                                \"GetProcessDefaultCpuSetMasks\");\n        if (NULL != ptrGetProcessDefaultCpuSetMasks)\n        {\n          /* This is Iron Release / Codename Fe\n             (also know as Windows 11 and Windows Server 2022)\n             or later version */\n          struct mhdt_GR_AFFINITY gr_affs[MHDT_MAX_GROUP_COUNT]; /* Hopefully should be enough */\n          /* Improvement: Implement dynamic allocation when it would be reasonable */\n          USHORT num_elm;\n\n          win_fe_or_later = true;\n\n          if (ptrGetProcessDefaultCpuSetMasks (GetCurrentProcess (), gr_affs,\n                                               sizeof (gr_affs)\n                                               / sizeof (gr_affs[0]), &num_elm))\n          {\n            if (0 == num_elm)\n            {\n              /* No group mask set */\n              cpu_set_mask_assigned = false;\n            }\n            else\n              cpu_set_mask_assigned = true;\n          }\n          else\n            cpu_set_mask_assigned = true; /* Assume the worst case */\n        }\n        else\n        {\n          win_fe_or_later = false;\n          cpu_set_mask_assigned = false;\n        }\n        if (! win_fe_or_later)\n        {\n          /* The OS is not capable of distributing threads across different\n             processor groups. Results reported by GetProcessAffinityMask()\n             are relevant for the main processor group for the process. */\n          ret = count_by_proc_aff_mask;\n        }\n        else\n        {\n          /* The of is capable of automatic threads distribution across\n             processor groups. */\n          if (cpu_set_mask_assigned)\n          {\n            /* Assigned Default CpuSet Masks combines with \"classic\"\n               affinity in the not fully clear way. The combination\n               is not documented and this functionality could be changed\n               any moment. */\n            ret = -1;\n          }\n          else\n          {\n            if (! single_cpu_group_assigned)\n            {\n              /* This is a multi processor group process on Win11 (or later).\n                 Each processor group may have different affinity and\n                 the OS has not API to get it.\n                 For example, affinity to the main processor group could be\n                 assigned by SetProcessAffinityMask() function, which converts\n                 the process to the single-processor-group type, but if\n                 SetThreadGroupAffinity() is called later and bind the thread\n                 to another processor group, the process becomes multi-processor-\n                 group again, however the initial affinity mask is still used\n                 for the initial (main) processor group. There is no API to read\n                 it.\n                 It is also possible that processor groups have different number\n                 of processors. */\n              ret = -1;\n            }\n            else\n            {\n              /* Single-processor-group process on Win11 (or later) without\n                 assigned Default CpuSet Masks. */\n              ret = count_by_proc_aff_mask;\n            }\n          }\n        }\n      }\n      FreeLibrary (k32hndl);\n    }\n  }\n#endif /* _WIN32 && ! __CYGWIN__ */\n  if (0 >= ret)\n    return -1;\n  return ret;\n}\n...\nstatic unsigned int\nget_process_cpu_core_count (void)\n{\n  static unsigned int proc_num_cpu_cores = 0;\n  if (0 == proc_num_cpu_cores)\n    proc_num_cpu_cores = detect_process_cpu_core_count ();\n  return proc_num_cpu_cores;\n}\n...\nstatic unsigned int\nget_num_threads (void)\n{\n#if 0  /* disalbed code */\n  static const unsigned int max_threads = 32;\n#endif /* disalbed code */\n  if (0 < num_threads)\n    return num_threads;\n\n  num_threads = get_cpu_core_count () / 2;\n  if (0 == num_threads)\n    num_threads = 1;\n  else\n  {\n    unsigned int num_proc_cpus;\n    num_proc_cpus = get_process_cpu_core_count ();\n    if (num_proc_cpus >= num_threads)\n    {\n      printf (\"Using half of all available CPU cores, assuming the other half \"\n              \"is used by client / requests generator.\\n\");\n    }\n    else\n    {\n      printf (\"Using all CPU cores available for this process as more than \"\n              \"half of CPU cores on this system are still available for use \"\n              \"by client / requests generator.\\n\");\n      num_threads = num_proc_cpus;\n    }\n  }\n#if 0  /* disalbed code */\n  if (max_threads < num_threads)\n  {\n    printf (\"Number of threads are limited to %u as more threads \"\n            \"are unlikely to improve the performance.\\n\", max_threads);\n    num_threads = max_threads;\n  }\n#endif /* disalbed code */\n\n  return num_threads;\n}\n...\nstatic void\ncheck_apply_param__all_cpus (void)\n{\n  if (! tool_params.all_cpus)\n    return;\n\n  num_threads = get_process_cpu_core_count ();\n  printf (\"Requested use of all available CPU cores for MHD threads.\\n\");\n  if (get_cpu_core_count () == num_threads)\n    print_all_cores_used ();\n}\n...\nstatic void\ncheck_apply_param__threads (void)\n{\n  if (0 == tool_params.threads)\n    return;\n\n  num_threads = tool_params.threads;\n\n  if (get_process_cpu_core_count () < num_threads)\n  {\n    fprintf (stderr, \"WARNING: The requested number of threads (%u) is \"\n             \"higher than the number of detected available CPU cores (%u).\\n\",\n             num_threads, get_process_cpu_core_count ());\n    fprintf (stderr, \"This decreases the performance. \"\n             \"Consider using fewer threads.\\n\");\n  }\n  if (get_cpu_core_count () == num_threads)\n  {\n    printf (\"The requested number of threads is equal to the number of \"\n            \"detected CPU cores.\\n\");\n    print_all_cores_used ();\n  }\n}\n</additional code>\n\n<instruction>\nJudge whether the report is correct or not.\n</instruction>\n",
  "is_report_correct": false,
  "explanation": "The underlying observation is correct (there is a redundant executed call that can be removed), but the report as written is not correct. The redundant second call to get_process_cpu_core_count() occurs in check_apply_param__threads (used as an argument to fprintf) rather than inside detect_process_cpu_core_count. get_process_cpu_core_count() caches its result in a static variable, so after the first call the second call has no side effects and removing it (or reusing the previously obtained value) would not change program behaviour \u2014 that matches MISRA C 2023 Rule 2.2 (dead code). So there is a Rule 2.2 issue in the project (the redundant call should be replaced by a local variable reuse), but the specific function flagged by agent A (detect_process_cpu_core_count) is incorrect. Therefore the report as stated is not correct."
}