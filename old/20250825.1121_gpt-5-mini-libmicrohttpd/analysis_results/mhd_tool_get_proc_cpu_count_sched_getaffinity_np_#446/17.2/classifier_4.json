{
  "user_message": "<misra_rule>\nMISRA C 2023 Rule 17.2 is: Functions shall not call themselves, either directly or indirectly.\n\n</misra_rule>\n<response format>\nProvide your answer with these fields.\n- is_rule_violated: whether the rule is violated or not (true/false),\n- scenario: a specific violation scenario.\n</response format>\n<target_code>\nHere is the code of mhd_tool_get_proc_cpu_count_sched_getaffinity_np_:\n```c\nstatic int\nmhd_tool_get_proc_cpu_count_sched_getaffinity_np_ (void)\n{\n  int ret = -1;\n#if defined(HAVE_SCHED_GETAFFINITY_NP) && defined(HAVE_GETPID)\n  /* NetBSD style */\n  cpuset_t *cpuset_ptr;\n  cpuset_ptr = cpuset_create ();\n  if (NULL != cpuset_ptr)\n  {\n    if (0 == sched_getaffinity_np (getpid (), cpuset_size (cpuset_ptr),\n                                   cpuset_ptr))\n    {\n      cpuid_t cpu_num;\n#if defined(HAVE_SYSCONF) && defined(HAVE_DECL__SC_NPROCESSORS_CONF)\n      unsigned int max_num = 0;\n      long sc_value;\n      sc_value = sysconf (_SC_NPROCESSORS_ONLN);\n      if (0 < sc_value)\n        max_num = (unsigned int) sc_value;\n      if (0 < max_num)\n      {\n        ret = 0;\n        for (cpu_num = 0; cpu_num < max_num; ++cpu_num)\n          if (0 < cpuset_isset (cpu_num, cpuset_ptr))\n            ++ret;\n      }\n      else /* Combined with the next 'if' */\n#endif /* HAVE_SYSCONF && HAVE_DECL__SC_NPROCESSORS_CONF */\n      if (1)\n      {\n        int res;\n        cpu_num = 0;\n        ret = 0;\n        do\n        {\n          res = cpuset_isset (cpu_num++, cpuset_ptr);\n          if (0 < res)\n            ++ret;\n        } while (0 <= res);\n      }\n#ifdef __NetBSD__\n      if (0 == ret)\n      {\n        /* On NetBSD \"unset\" affinity (exactly zero CPUs) means\n           \"all CPUs are available\". */\n        ret = mhd_tool_get_sys_cpu_count_sysctl_ ();\n      }\n#endif /* __NetBSD__ */\n    }\n    cpuset_destroy (cpuset_ptr);\n  }\n#endif /* HAVE_SCHED_GETAFFINITY_NP && HAVE_GETPID */\n  if (0 >= ret)\n    return -1;\n  return ret;\n}\n```\n</target_code>\n<additional code>Here are the definitions of symbols that are close to the target function mhd_tool_get_proc_cpu_count_sched_getaffinity_np_:\nstatic int\nmhd_tool_get_sys_cpu_count_sysctl_ (void)\n{\n  int ret = -1;\n  /* Do not use sysctl() function on GNU/Linux even if\n     sysctl() is available */\n#ifndef __linux__\n#ifdef HAVE_SYSCTLBYNAME\n  if (0 >= ret)\n  {\n    size_t value_size = sizeof (ret);\n    /* Darwin: The number of available logical CPUs */\n    if ((0 != sysctlbyname (\"hw.logicalcpu\", &ret, &value_size,\n                            NULL, 0))\n        || (sizeof (ret) != value_size))\n      ret = -1;\n  }\n  if (0 >= ret)\n  {\n    size_t value_size = sizeof (ret);\n    /* FreeBSD: The number of online CPUs */\n    if ((0 != sysctlbyname (\"kern.smp.cpus\", &ret, &value_size,\n                            NULL, 0))\n        || (sizeof (ret) != value_size))\n      ret = -1;\n  }\n  if (0 >= ret)\n  {\n    size_t value_size = sizeof (ret);\n    /* Darwin: The current number of CPUs available to run threads */\n    if ((0 != sysctlbyname (\"hw.activecpu\", &ret, &value_size,\n                            NULL, 0))\n        || (sizeof (ret) != value_size))\n      ret = -1;\n  }\n  if (0 >= ret)\n  {\n    size_t value_size = sizeof (ret);\n    /* OpenBSD, NetBSD: The number of online CPUs */\n    if ((0 != sysctlbyname (\"hw.ncpuonline\", &ret, &value_size,\n                            NULL, 0))\n        || (sizeof (ret) != value_size))\n      ret = -1;\n  }\n  if (0 >= ret)\n  {\n    size_t value_size = sizeof (ret);\n    /* Darwin: The old/alternative name for \"hw.activecpu\" */\n    if ((0 != sysctlbyname (\"hw.availcpu\", &ret, &value_size,\n                            NULL, 0))\n        || (sizeof (ret) != value_size))\n      ret = -1;\n  }\n#endif /* HAVE_SYSCTLBYNAME */\n#if defined(HAVE_SYSCTL) && \\\n  defined(HAS_DECL_CTL_HW) && \\\n  defined(HAS_DECL_HW_NCPUONLINE)\n  if (0 >= ret)\n  {\n    /* OpenBSD, NetBSD: The number of online CPUs */\n    int mib[2] = {CTL_HW, HW_NCPUONLINE};\n    size_t value_size = sizeof (ret);\n    if ((0 != sysctl (mib, 2, &ret, &value_size, NULL, 0))\n        || (sizeof (ret) != value_size))\n      ret = -1;\n  }\n#endif /* HAVE_SYSCTL && HAS_DECL_CTL_HW && HAS_DECL_HW_NCPUONLINE */\n#if defined(HAVE_SYSCTL) && \\\n  defined(HAS_DECL_CTL_HW) && \\\n  defined(HAS_DECL_HW_AVAILCPU)\n  if (0 >= ret)\n  {\n    /* Darwin: The MIB name for \"hw.activecpu\" */\n    int mib[2] = {CTL_HW, HW_AVAILCPU};\n    size_t value_size = sizeof (ret);\n    if ((0 != sysctl (mib, 2, &ret, &value_size, NULL, 0))\n        || (sizeof (ret) != value_size))\n      ret = -1;\n  }\n#endif /* HAVE_SYSCTL && HAS_DECL_CTL_HW && HAS_DECL_HW_AVAILCPU */\n#endif /* ! __linux__ */\n  if (0 >= ret)\n    return -1;\n  return ret;\n}\n...\nint\nmhd_tool_get_proc_cpu_count (void)\n{\n  int res;\n\n#if defined(__linux__) || defined(__GLIBC__)\n  /* On Linux kernel try first 'sched_getaffinity()' as it should be\n     the native API.\n     Also try it first on other kernels if Glibc is used. */\n  res = mhd_tool_get_proc_cpu_count_sched_getaffinity_ ();\n  if (0 < res)\n    return res;\n\n  res = mhd_tool_get_proc_cpu_count_cpuset_getaffinity_ ();\n  if (0 < res)\n    return res;\n#else  /* ! __linux__ && ! __GLIBC__ */\n  /* On non-Linux kernels 'cpuset_getaffinity()' could be the native API,\n     while 'sched_getaffinity()' could be implemented in compatibility layer. */\n  res = mhd_tool_get_proc_cpu_count_cpuset_getaffinity_ ();\n  if (0 < res)\n    return res;\n\n  res = mhd_tool_get_proc_cpu_count_sched_getaffinity_ ();\n  if (0 < res)\n    return res;\n#endif /* ! __linux__ && ! __GLIBC__ */\n\n  res = mhd_tool_get_proc_cpu_count_sched_getaffinity_np_ ();\n  if (0 < res)\n    return res;\n\n  res = mhd_tool_get_proc_cpu_count_w32_ ();\n  if (0 < res)\n    return res;\n\n  return -1;\n}\n...\nstatic int\nmhd_tool_get_proc_cpu_count_sched_getaffinity_ (void)\n{\n  int ret = -1;\n#if defined(HAVE_SCHED_GETAFFINITY) && defined(HAVE_GETPID)\n  /* Glibc style */\n  if (0 >= ret)\n  {\n    cpu_set_t cur_set;\n    if (0 == sched_getaffinity (getpid (), sizeof (cur_set), &cur_set))\n    {\n#ifdef HAVE_CPU_COUNT\n      ret = CPU_COUNT (&cur_set);\n#else  /* ! HAVE_CPU_COUNT */\n      unsigned int i;\n      ret = 0;\n      for (i = 0; i < CPU_SETSIZE_SAFE; ++i)\n      {\n        if (CPU_ISSET (i, &cur_set))\n          ++ret;\n      }\n      if (0 == ret)\n        ret = -1;\n#endif /* ! HAVE_CPU_COUNT */\n    }\n  }\n#ifdef HAVE_CPU_COUNT_S\n  if (0 >= ret)\n  {\n    /* Use 256 times larger size than size for default maximum CPU number.\n       Hopefully it would be enough even for exotic situations. */\n    static const unsigned int set_size_cpus = 256 * CPU_SETSIZE;\n    const size_t set_size_bytes = CPU_ALLOC_SIZE (set_size_cpus);\n    cpu_set_t *p_set;\n\n    p_set = CPU_ALLOC (set_size_cpus);\n    if (NULL != p_set)\n    {\n      if (0 == sched_getaffinity (getpid (), set_size_bytes, p_set))\n      {\n#ifndef MHD_FUNC_CPU_COUNT_S_GETS_CPUS\n        ret = CPU_COUNT_S (set_size_bytes, p_set);\n#else  /* MHD_FUNC_CPU_COUNT_S_GETS_CPUS */\n        ret = CPU_COUNT_S (set_size_cpus, p_set);\n#endif /* MHD_FUNC_CPU_COUNT_S_GETS_CPUS */\n      }\n      CPU_FREE (p_set);\n    }\n  }\n#endif /* HAVE_CPU_COUNT_S */\n#endif /* HAVE_SCHED_GETAFFINITY && HAVE_GETPID */\n  if (0 >= ret)\n    return -1;\n  return ret;\n}\n...\nstatic int\nmhd_tool_get_proc_cpu_count_cpuset_getaffinity_ (void)\n{\n  int ret = -1;\n#if defined(HAVE_CPUSET_GETAFFINITY)\n  /* FreeBSD style */\n  if (0 >= ret)\n  {\n    cpuset_t cur_mask;\n    /* The should get \"anonymous\" mask/set. The anonymous mask is always\n       a subset of the assigned set (which is a subset of the root set). */\n    if (0 == cpuset_getaffinity (CPU_LEVEL_WHICH, CPU_WHICH_PID, (id_t) -1,\n                                 sizeof (cur_mask), &cur_mask))\n    {\n#ifdef HAVE_CPU_COUNT\n      ret = CPU_COUNT (&cur_mask);\n#else  /* ! HAVE_CPU_COUNT */\n      unsigned int i;\n      ret = 0;\n      for (i = 0; i < CPU_SETSIZE_SAFE; ++i)\n      {\n        if (CPU_ISSET (i, &cur_mask))\n          ++ret;\n      }\n      if (0 == ret)\n        ret = -1;\n#endif /* ! HAVE_CPU_COUNT */\n    }\n  }\n#ifdef HAVE_CPU_COUNT_S\n  if (0 >= ret)\n  {\n    /* Use 256 times larger size than size for default maximum CPU number.\n       Hopefully it would be enough even for exotic situations. */\n    static const unsigned int mask_size_cpus = 256 * CPU_SETSIZE;\n    const size_t mask_size_bytes = CPU_ALLOC_SIZE (mask_size_cpus);\n    cpuset_t *p_mask;\n\n    p_mask = CPU_ALLOC (mask_size_cpus);\n    if (NULL != p_mask)\n    {\n      if (0 == cpuset_getaffinity (CPU_LEVEL_WHICH, CPU_WHICH_PID, (id_t) -1,\n                                   mask_size_bytes, p_mask))\n      {\n#ifndef MHD_FUNC_CPU_COUNT_S_GETS_CPUS\n        ret = CPU_COUNT_S (mask_size_bytes, p_mask);\n#else  /* MHD_FUNC_CPU_COUNT_S_GETS_CPUS */\n        ret = CPU_COUNT_S (mask_size_cpus, p_mask);\n#endif /* MHD_FUNC_CPU_COUNT_S_GETS_CPUS */\n      }\n      CPU_FREE (p_mask);\n    }\n  }\n#endif /* HAVE_CPU_COUNT_S */\n#endif /* HAVE_CPUSET_GETAFFINITY */\n  if (0 >= ret)\n    return -1;\n  return ret;\n}\n...\nstatic int\nmhd_tool_get_proc_cpu_count_w32_ (void)\n{\n  int ret = -1;\n#if defined(_WIN32) && ! defined(__CYGWIN__)\n  /* W32 Native */\n  /**\n   * Maximum used number of CPU groups.\n   * Improvement: Implement dynamic allocation when it would be reasonable\n   */\n#define MHDT_MAX_GROUP_COUNT 128\n  /**\n   * The count of logical CPUs as returned by GetProcessAffinityMask()\n   */\n  int count_by_proc_aff_mask;\n  count_by_proc_aff_mask = -1;\n  if (1)\n  {\n    DWORD_PTR proc_aff;\n    DWORD_PTR sys_aff;\n\n    if (GetProcessAffinityMask (GetCurrentProcess (), &proc_aff, &sys_aff))\n    {\n      /* Count all set bits */\n      for (count_by_proc_aff_mask = 0; 0 != proc_aff; proc_aff &= proc_aff - 1)\n        ++count_by_proc_aff_mask;\n    }\n  }\n  if (0 < count_by_proc_aff_mask)\n  {\n    HMODULE k32hndl;\n    k32hndl = LoadLibraryA (\"kernel32.dll\");\n    if (NULL != k32hndl)\n    {\n      typedef BOOL (WINAPI *GPGA_PTR)(HANDLE hProcess,\n                                      PUSHORT GroupCount,\n                                      PUSHORT GroupArray);\n      GPGA_PTR ptrGetProcessGroupAffinity;\n      ptrGetProcessGroupAffinity =\n        (GPGA_PTR) (void *) GetProcAddress (k32hndl,\n                                            \"GetProcessGroupAffinity\");\n      if (NULL == ptrGetProcessGroupAffinity)\n      {\n        /* Windows version before Win7 */\n        /* No processor groups supported, the process affinity mask gives full picture */\n        ret = count_by_proc_aff_mask;\n      }\n      else\n      {\n        /* Windows version Win7 or later */\n        /* Processor groups are supported */\n        USHORT arr_elements = MHDT_MAX_GROUP_COUNT;\n        USHORT groups_arr[MHDT_MAX_GROUP_COUNT]; /* Hopefully should be enough */\n        /* Improvement: Implement dynamic allocation when it would be reasonable */\n        /**\n         * Exactly one processor group is assigned to the process\n         */\n        bool single_cpu_group_assigned; /**< Exactly one processor group is assigned to the process */\n        struct mhdt_GR_AFFINITY\n        {\n          KAFFINITY Mask;\n          WORD Group;\n          WORD Reserved[3];\n        };\n        typedef BOOL (WINAPI *GPDCSM_PTR)(HANDLE Process,\n                                          struct mhdt_GR_AFFINITY *CpuSetMasks,\n                                          USHORT CpuSetMaskCount,\n                                          USHORT *RequiredMaskCount);\n        GPDCSM_PTR ptrGetProcessDefaultCpuSetMasks;\n        bool win_fe_or_later;\n        bool cpu_set_mask_assigned;\n\n        single_cpu_group_assigned = false;\n        if (ptrGetProcessGroupAffinity (GetCurrentProcess (), &arr_elements,\n                                        groups_arr))\n        {\n          if (1 == arr_elements)\n          {\n            /* Exactly one processor group assigned to the process */\n            single_cpu_group_assigned = true;\n#if 0 /* Disabled code */\n            /* The value returned by GetThreadGroupAffinity() is not relevant as\n               for the new threads the process affinity mask is used. */\n            ULONG_PTR proc_aff2;\n            typedef BOOL (WINAPI *GTGA_PTR)(HANDLE hThread,\n                                            struct mhdt_GR_AFFINITY *\n                                            GroupAffinity);\n            GTGA_PTR ptrGetThreadGroupAffinity;\n            ptrGetThreadGroupAffinity =\n              (GTGA_PTR) (void *) GetProcAddress (k32hndl,\n                                                  \"GetThreadGroupAffinity\");\n            if (NULL != ptrGetThreadGroupAffinity)\n            {\n              struct mhdt_GR_AFFINITY thr_gr_aff;\n              if (ptrGetThreadGroupAffinity (GetCurrentThread (), &thr_gr_aff))\n                proc_aff2 = (ULONG_PTR) thr_gr_aff.Mask;\n            }\n#endif /* Disabled code */\n          }\n        }\n        ptrGetProcessDefaultCpuSetMasks =\n          (GPDCSM_PTR) (void *) GetProcAddress (k32hndl,\n                                                \"GetProcessDefaultCpuSetMasks\");\n        if (NULL != ptrGetProcessDefaultCpuSetMasks)\n        {\n          /* This is Iron Release / Codename Fe\n             (also know as Windows 11 and Windows Server 2022)\n             or later version */\n          struct mhdt_GR_AFFINITY gr_affs[MHDT_MAX_GROUP_COUNT]; /* Hopefully should be enough */\n          /* Improvement: Implement dynamic allocation when it would be reasonable */\n          USHORT num_elm;\n\n          win_fe_or_later = true;\n\n          if (ptrGetProcessDefaultCpuSetMasks (GetCurrentProcess (), gr_affs,\n                                               sizeof (gr_affs)\n                                               / sizeof (gr_affs[0]), &num_elm))\n          {\n            if (0 == num_elm)\n            {\n              /* No group mask set */\n              cpu_set_mask_assigned = false;\n            }\n            else\n              cpu_set_mask_assigned = true;\n          }\n          else\n            cpu_set_mask_assigned = true; /* Assume the worst case */\n        }\n        else\n        {\n          win_fe_or_later = false;\n          cpu_set_mask_assigned = false;\n        }\n        if (! win_fe_or_later)\n        {\n          /* The OS is not capable of distributing threads across different\n             processor groups. Results reported by GetProcessAffinityMask()\n             are relevant for the main processor group for the process. */\n          ret = count_by_proc_aff_mask;\n        }\n        else\n        {\n          /* The of is capable of automatic threads distribution across\n             processor groups. */\n          if (cpu_set_mask_assigned)\n          {\n            /* Assigned Default CpuSet Masks combines with \"classic\"\n               affinity in the not fully clear way. The combination\n               is not documented and this functionality could be changed\n               any moment. */\n            ret = -1;\n          }\n          else\n          {\n            if (! single_cpu_group_assigned)\n            {\n              /* This is a multi processor group process on Win11 (or later).\n                 Each processor group may have different affinity and\n                 the OS has not API to get it.\n                 For example, affinity to the main processor group could be\n                 assigned by SetProcessAffinityMask() function, which converts\n                 the process to the single-processor-group type, but if\n                 SetThreadGroupAffinity() is called later and bind the thread\n                 to another processor group, the process becomes multi-processor-\n                 group again, however the initial affinity mask is still used\n                 for the initial (main) processor group. There is no API to read\n                 it.\n                 It is also possible that processor groups have different number\n                 of processors. */\n              ret = -1;\n            }\n            else\n            {\n              /* Single-processor-group process on Win11 (or later) without\n                 assigned Default CpuSet Masks. */\n              ret = count_by_proc_aff_mask;\n            }\n          }\n        }\n      }\n      FreeLibrary (k32hndl);\n    }\n  }\n#endif /* _WIN32 && ! __CYGWIN__ */\n  if (0 >= ret)\n    return -1;\n  return ret;\n}\n...\nint\nmhd_tool_get_system_cpu_count (void)\n{\n  int res;\n\n  /* Try specialised APIs first */\n  res = mhd_tool_get_sys_cpu_count_special_api_ ();\n  if (0 < res)\n    return res;\n\n  /* Try sysctl*(). This is typically a direct interface to\n     kernel values. */\n  res = mhd_tool_get_sys_cpu_count_sysctl_ ();\n  if (0 < res)\n    return res;\n\n  /* Try sysconf() as the last resort as this is a generic interface\n     which can be implemented by parsing system files. */\n  res = mhd_tool_get_sys_cpu_count_sysconf_ ();\n#if ! defined(__linux__) && ! defined(__GLIBC__)\n  if (0 < res)\n    return res;\n#else  /* __linux__ || __GLIBC__ */\n  if (2 < res)\n    return res;\n  if (0 < res)\n  {\n    /* '1' or '2' could a be fallback number.\n     * See get_nprocs_fallback() in glibc\n       sysdeps/unix/sysv/linux/getsysstats.c */\n\n    int proc_cpu_count;\n\n    proc_cpu_count = mhd_tool_get_proc_cpu_count ();\n    if (proc_cpu_count == res)\n    {\n      /* The detected number of CPUs available for the process\n         is equal to the detected number of system CPUs.\n         Assume detected number is correct. */\n      return res;\n    }\n  }\n#endif /* __linux__ || __GLIBC__  */\n\n  /* Try available fallbacks */\n\n  res = mhd_tool_get_sys_cpu_count_sysctl_fallback_ ();\n  if (0 < res)\n    return res;\n\n  res = mhd_tool_get_sys_cpu_count_sysconf_fallback_ ();\n#if ! defined(__linux__) && ! defined(__GLIBC__)\n  if (0 < res)\n    return res;\n#else  /* __linux__ || __GLIBC__ */\n  if (2 < res)\n    return res;\n#endif /* __linux__ || __GLIBC__  */\n\n  return -1; /* Cannot detect */\n}\n...\nstatic unsigned int\ndetect_cpu_core_count (void)\n{\n  int sys_cpu_count;\n  sys_cpu_count = mhd_tool_get_system_cpu_count ();\n  if (0 >= sys_cpu_count)\n  {\n    int proc_cpu_count;\n    fprintf (stderr, \"Failed to detect the number of logical CPU cores \"\n             \"available on the system.\\n\");\n    proc_cpu_count = mhd_tool_get_proc_cpu_count ();\n    if (0 < proc_cpu_count)\n    {\n      fprintf (stderr, \"The number of CPU cores available for this process \"\n               \"is used as a fallback.\\n\");\n      sys_cpu_count = proc_cpu_count;\n    }\n#ifdef MHD_REAL_CPU_COUNT\n    if (0 >= sys_cpu_count)\n    {\n      fprintf (stderr, \"configure-detected hardcoded number is used \"\n               \"as a fallback.\\n\");\n      sys_cpu_count = MHD_REAL_CPU_COUNT;\n    }\n#endif\n    if (0 >= sys_cpu_count)\n      sys_cpu_count = 1;\n    printf (\"Assuming %d logical CPU core%s on this system.\\n\", sys_cpu_count,\n            (1 == sys_cpu_count) ? \"\" : \"s\");\n  }\n  else\n  {\n    printf (\"Detected %d logical CPU core%s on this system.\\n\", sys_cpu_count,\n            (1 == sys_cpu_count) ? \"\" : \"s\");\n  }\n  return (unsigned int) sys_cpu_count;\n}\n...\nstatic unsigned int\ndetect_process_cpu_core_count (void)\n{\n  unsigned int num_proc_cpu_cores;\n  unsigned int sys_cpu_cores;\n  int res;\n\n  sys_cpu_cores = get_cpu_core_count ();\n  res = mhd_tool_get_proc_cpu_count ();\n  if (0 > res)\n  {\n    fprintf (stderr, \"Cannot detect the number of logical CPU cores available \"\n             \"for this process.\\n\");\n    if (1 != sys_cpu_cores)\n      printf (\"Assuming all %u system logical CPU cores are available to run \"\n              \"threads of this process.\\n\", sys_cpu_cores);\n    else\n      printf (\"Assuming single logical CPU core available for this process.\\n\");\n    num_proc_cpu_cores = sys_cpu_cores;\n  }\n  else\n  {\n    printf (\"Detected %d logical CPU core%s available to run threads \"\n            \"of this process.\\n\", res, (1 == res) ? \"\" : \"s\");\n    num_proc_cpu_cores = (unsigned int) res;\n  }\n  if (num_proc_cpu_cores > sys_cpu_cores)\n  {\n    fprintf (stderr, \"WARNING: Detected number of CPU cores available \"\n             \"for this process (%u) is larger than detected number \"\n             \"of CPU cores on the system (%u).\\n\",\n             num_proc_cpu_cores, sys_cpu_cores);\n    num_proc_cpu_cores = sys_cpu_cores;\n    fprintf (stderr, \"Using %u as the number of logical CPU cores available \"\n             \"for this process.\\n\", num_proc_cpu_cores);\n  }\n  return num_proc_cpu_cores;\n}\n</additional code>\n<target_code>\nHere is the code fragment that you need to analyze:\n```c\nres = mhd_tool_get_proc_cpu_count_sched_getaffinity_ ();\n```\nFocus on the above code fragment and judge whether it violates the rule 17.2 or not.\n</target_code>\n",
  "is_rule_violated": false,
  "scenario": "The fragment calls mhd_tool_get_proc_cpu_count_sched_getaffinity_() from mhd_tool_get_proc_cpu_count (or another caller). This is a call to a different function (no identical name), and there is no evidence in the provided code that this call leads back (directly or indirectly) to the caller, so no recursion is introduced."
}