{
  "user_message": "<misra_rule>\nMISRA C 2023 Rule 14.2 is: A for loop shall be well-formed.\nThe three clauses of a for statement are the:\n1. First clause shall be empty or an expression whose set the value of the loop counter or define and intialize the loop counter.\n2. Second clause shall be an expression that has no persistent side effects, and shall use the loop counter and optionally loop control flags, and shall not use any other object that is modified in the for loop body.\n3.Third clause shall be an expression whose modify only the value of the loop counter, and shall not use objects that are modified in the for loop body.\n4. There shall only be one loop counter in a for loop, which shall not be modified in for loop body. A loop control flag is defined as single identifier denoting an object with Boolean type that is used in the second clause. The behaviour of a for loop body includes the behaviour of any functions called within that statement. \n</misra_rule>\n<response format>\nProvide your answer with these fields.\n- is_rule_violated: whether the rule is violated or not (true/false),\n- scenario: a specific violation scenario.\n</response format>\n<target_code>\nHere is the code of lfs_file_write:\n```c\nlfs_ssize_t lfs_file_write(lfs_t *lfs, lfs_file_t *file,\n        const void *buffer, lfs_size_t size) {\n    int err = LFS_LOCK(lfs->cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_file_write(%p, %p, %p, %\"PRIu32\")\",\n            (void*)lfs, (void*)file, buffer, size);\n    LFS_ASSERT(lfs_mlist_isopen(lfs->mlist, (struct lfs_mlist*)file));\n\n    lfs_ssize_t res = lfs_file_write_(lfs, file, buffer, size);\n\n    LFS_TRACE(\"lfs_file_write -> %\"PRId32, res);\n    LFS_UNLOCK(lfs->cfg);\n    return res;\n}\n```\n</target_code>\n<additional code>Here are the definitions of symbols that are close to the target function lfs_file_write:\nstatic lfs_ssize_t lfs_file_write_(lfs_t *lfs, lfs_file_t *file,\n        const void *buffer, lfs_size_t size) {\n    LFS_ASSERT((file->flags & LFS_O_WRONLY) == LFS_O_WRONLY);\n\n    if (file->flags & LFS_F_READING) {\n        // drop any reads\n        int err = lfs_file_flush(lfs, file);\n        if (err) {\n            return err;\n        }\n    }\n\n    if ((file->flags & LFS_O_APPEND) && file->pos < file->ctz.size) {\n        file->pos = file->ctz.size;\n    }\n\n    if (file->pos + size > lfs->file_max) {\n        // Larger than file limit?\n        return LFS_ERR_FBIG;\n    }\n\n    if (!(file->flags & LFS_F_WRITING) && file->pos > file->ctz.size) {\n        // fill with zeros\n        lfs_off_t pos = file->pos;\n        file->pos = file->ctz.size;\n\n        while (file->pos < pos) {\n            lfs_ssize_t res = lfs_file_flushedwrite(lfs, file, &(uint8_t){0}, 1);\n            if (res < 0) {\n                return res;\n            }\n        }\n    }\n\n    lfs_ssize_t nsize = lfs_file_flushedwrite(lfs, file, buffer, size);\n    if (nsize < 0) {\n        return nsize;\n    }\n\n    file->flags &= ~LFS_F_ERRED;\n    return nsize;\n}\n...\nstatic int lfs_file_flush(lfs_t *lfs, lfs_file_t *file) {\n    if (file->flags & LFS_F_READING) {\n        if (!(file->flags & LFS_F_INLINE)) {\n            lfs_cache_drop(lfs, &file->cache);\n        }\n        file->flags &= ~LFS_F_READING;\n    }\n\n#ifndef LFS_READONLY\n    if (file->flags & LFS_F_WRITING) {\n        lfs_off_t pos = file->pos;\n\n        if (!(file->flags & LFS_F_INLINE)) {\n            // copy over anything after current branch\n            lfs_file_t orig = {\n                .ctz.head = file->ctz.head,\n                .ctz.size = file->ctz.size,\n                .flags = LFS_O_RDONLY,\n                .pos = file->pos,\n                .cache = lfs->rcache,\n            };\n            lfs_cache_drop(lfs, &lfs->rcache);\n\n            while (file->pos < file->ctz.size) {\n                // copy over a byte at a time, leave it up to caching\n                // to make this efficient\n                uint8_t data;\n                lfs_ssize_t res = lfs_file_flushedread(lfs, &orig, &data, 1);\n                if (res < 0) {\n                    return res;\n                }\n\n                res = lfs_file_flushedwrite(lfs, file, &data, 1);\n                if (res < 0) {\n                    return res;\n                }\n\n                // keep our reference to the rcache in sync\n                if (lfs->rcache.block != LFS_BLOCK_NULL) {\n                    lfs_cache_drop(lfs, &orig.cache);\n                    lfs_cache_drop(lfs, &lfs->rcache);\n                }\n            }\n\n            // write out what we have\n            while (true) {\n                int err = lfs_bd_flush(lfs, &file->cache, &lfs->rcache, true);\n                if (err) {\n                    if (err == LFS_ERR_CORRUPT) {\n                        goto relocate;\n                    }\n                    return err;\n                }\n\n                break;\n\nrelocate:\n                LFS_DEBUG(\"Bad block at 0x%\"PRIx32, file->block);\n                err = lfs_file_relocate(lfs, file);\n                if (err) {\n                    return err;\n                }\n            }\n        } else {\n            file->pos = lfs_max(file->pos, file->ctz.size);\n        }\n\n        // actual file updates\n        file->ctz.head = file->block;\n        file->ctz.size = file->pos;\n        file->flags &= ~LFS_F_WRITING;\n        file->flags |= LFS_F_DIRTY;\n\n        file->pos = pos;\n    }\n#endif\n\n    return 0;\n}\n...\nstatic lfs_ssize_t lfs_file_flushedwrite(lfs_t *lfs, lfs_file_t *file,\n        const void *buffer, lfs_size_t size) {\n    const uint8_t *data = buffer;\n    lfs_size_t nsize = size;\n\n    if ((file->flags & LFS_F_INLINE) &&\n            lfs_max(file->pos+nsize, file->ctz.size) > lfs->inline_max) {\n        // inline file doesn't fit anymore\n        int err = lfs_file_outline(lfs, file);\n        if (err) {\n            file->flags |= LFS_F_ERRED;\n            return err;\n        }\n    }\n\n    while (nsize > 0) {\n        // check if we need a new block\n        if (!(file->flags & LFS_F_WRITING) ||\n                file->off == lfs->cfg->block_size) {\n            if (!(file->flags & LFS_F_INLINE)) {\n                if (!(file->flags & LFS_F_WRITING) && file->pos > 0) {\n                    // find out which block we're extending from\n                    int err = lfs_ctz_find(lfs, NULL, &file->cache,\n                            file->ctz.head, file->ctz.size,\n                            file->pos-1, &file->block, &(lfs_off_t){0});\n                    if (err) {\n                        file->flags |= LFS_F_ERRED;\n                        return err;\n                    }\n\n                    // mark cache as dirty since we may have read data into it\n                    lfs_cache_zero(lfs, &file->cache);\n                }\n\n                // extend file with new blocks\n                lfs_alloc_ckpoint(lfs);\n                int err = lfs_ctz_extend(lfs, &file->cache, &lfs->rcache,\n                        file->block, file->pos,\n                        &file->block, &file->off);\n                if (err) {\n                    file->flags |= LFS_F_ERRED;\n                    return err;\n                }\n            } else {\n                file->block = LFS_BLOCK_INLINE;\n                file->off = file->pos;\n            }\n\n            file->flags |= LFS_F_WRITING;\n        }\n\n        // program as much as we can in current block\n        lfs_size_t diff = lfs_min(nsize, lfs->cfg->block_size - file->off);\n        while (true) {\n            int err = lfs_bd_prog(lfs, &file->cache, &lfs->rcache, true,\n                    file->block, file->off, data, diff);\n            if (err) {\n                if (err == LFS_ERR_CORRUPT) {\n                    goto relocate;\n                }\n                file->flags |= LFS_F_ERRED;\n                return err;\n            }\n\n            break;\nrelocate:\n            err = lfs_file_relocate(lfs, file);\n            if (err) {\n                file->flags |= LFS_F_ERRED;\n                return err;\n            }\n        }\n\n        file->pos += diff;\n        file->off += diff;\n        data += diff;\n        nsize -= diff;\n\n        lfs_alloc_ckpoint(lfs);\n    }\n\n    return size;\n}\n...\nstatic bool lfs_mlist_isopen(struct lfs_mlist *head,\n        struct lfs_mlist *node) {\n    for (struct lfs_mlist **p = &head; *p; p = &(*p)->next) {\n        if (*p == (struct lfs_mlist*)node) {\n            return true;\n        }\n    }\n\n    return false;\n}\n...\n#define LFS_LOCK(cfg) ((void)cfg,0)\n...\n#define LFS_UNLOCK(cfg) ((void)cfg)\n...\n#define LFS_TRACE(__VA_ARGS__) \n...\n#define LFS_ASSERT(test) assert(test)\n...\ntypedef struct lfs {\n    lfs_cache_t rcache;\n    lfs_cache_t pcache;\n\n    lfs_block_t root[2];\n    struct lfs_mlist {\n        struct lfs_mlist *next;\n        uint16_t id;\n        uint8_t type;\n        lfs_mdir_t m;\n    } *mlist;\n    uint32_t seed;\n\n    lfs_gstate_t gstate;\n    lfs_gstate_t gdisk;\n    lfs_gstate_t gdelta;\n\n    struct lfs_lookahead {\n        lfs_block_t start;\n        lfs_block_t size;\n        lfs_block_t next;\n        lfs_block_t ckpoint;\n        uint8_t *buffer;\n    } lookahead;\n\n    const struct lfs_config *cfg;\n    lfs_size_t block_count;\n    lfs_size_t name_max;\n    lfs_size_t file_max;\n    lfs_size_t attr_max;\n    lfs_size_t inline_max;\n\n#ifdef LFS_MIGRATE\n    struct lfs1 *lfs1;\n#endif\n} lfs_t\n...\ntypedef struct lfs_file {\n    struct lfs_file *next;\n    uint16_t id;\n    uint8_t type;\n    lfs_mdir_t m;\n\n    struct lfs_ctz {\n        lfs_block_t head;\n        lfs_size_t size;\n    } ctz;\n\n    uint32_t flags;\n    lfs_off_t pos;\n    lfs_block_t block;\n    lfs_off_t off;\n    lfs_cache_t cache;\n\n    const struct lfs_file_config *cfg;\n} lfs_file_t\n...\nstruct lfs_mlist {\n        struct lfs_mlist *next;\n        uint16_t id;\n        uint8_t type;\n        lfs_mdir_t m;\n    }\n...\ntypedef uint32_t lfs_size_t\n...\ntypedef int32_t  lfs_ssize_t\n...\nstruct lfs_config {\n    // Opaque user provided context that can be used to pass\n    // information to the block device operations\n    void *context;\n\n    // Read a region in a block. Negative error codes are propagated\n    // to the user.\n    int (*read)(const struct lfs_config *c, lfs_block_t block,\n            lfs_off_t off, void *buffer, lfs_size_t size);\n\n    // Program a region in a block. The block must have previously\n    // been erased. Negative error codes are propagated to the user.\n    // May return LFS_ERR_CORRUPT if the block should be considered bad.\n    int (*prog)(const struct lfs_config *c, lfs_block_t block,\n            lfs_off_t off, const void *buffer, lfs_size_t size);\n\n    // Erase a block. A block must be erased before being programmed.\n    // The state of an erased block is undefined. Negative error codes\n    // are propagated to the user.\n    // May return LFS_ERR_CORRUPT if the block should be considered bad.\n    int (*erase)(const struct lfs_config *c, lfs_block_t block);\n\n    // Sync the state of the underlying block device. Negative error codes\n    // are propagated to the user.\n    int (*sync)(const struct lfs_config *c);\n\n#ifdef LFS_THREADSAFE\n    // Lock the underlying block device. Negative error codes\n    // are propagated to the user.\n    int (*lock)(const struct lfs_config *c);\n\n    // Unlock the underlying block device. Negative error codes\n    // are propagated to the user.\n    int (*unlock)(const struct lfs_config *c);\n#endif\n\n    // Minimum size of a block read in bytes. All read operations will be a\n    // multiple of this value.\n    lfs_size_t read_size;\n\n    // Minimum size of a block program in bytes. All program operations will be\n    // a multiple of this value.\n    lfs_size_t prog_size;\n\n    // Size of an erasable block in bytes. This does not impact ram consumption\n    // and may be larger than the physical erase size. However, non-inlined\n    // files take up at minimum one block. Must be a multiple of the read and\n    // program sizes.\n    lfs_size_t block_size;\n\n    // Number of erasable blocks on the device. Defaults to block_count stored\n    // on disk when zero.\n    lfs_size_t block_count;\n\n    // Number of erase cycles before littlefs evicts metadata logs and moves\n    // the metadata to another block. Suggested values are in the\n    // range 100-1000, with large values having better performance at the cost\n    // of less consistent wear distribution.\n    //\n    // Set to -1 to disable block-level wear-leveling.\n    int32_t block_cycles;\n\n    // Size of block caches in bytes. Each cache buffers a portion of a block in\n    // RAM. The littlefs needs a read cache, a program cache, and one additional\n    // cache per file. Larger caches can improve performance by storing more\n    // data and reducing the number of disk accesses. Must be a multiple of the\n    // read and program sizes, and a factor of the block size.\n    lfs_size_t cache_size;\n\n    // Size of the lookahead buffer in bytes. A larger lookahead buffer\n    // increases the number of blocks found during an allocation pass. The\n    // lookahead buffer is stored as a compact bitmap, so each byte of RAM\n    // can track 8 blocks.\n    lfs_size_t lookahead_size;\n\n    // Threshold for metadata compaction during lfs_fs_gc in bytes. Metadata\n    // pairs that exceed this threshold will be compacted during lfs_fs_gc.\n    // Defaults to ~88% block_size when zero, though the default may change\n    // in the future.\n    //\n    // Note this only affects lfs_fs_gc. Normal compactions still only occur\n    // when full.\n    //\n    // Set to -1 to disable metadata compaction during lfs_fs_gc.\n    lfs_size_t compact_thresh;\n\n    // Optional statically allocated read buffer. Must be cache_size.\n    // By default lfs_malloc is used to allocate this buffer.\n    void *read_buffer;\n\n    // Optional statically allocated program buffer. Must be cache_size.\n    // By default lfs_malloc is used to allocate this buffer.\n    void *prog_buffer;\n\n    // Optional statically allocated lookahead buffer. Must be lookahead_size.\n    // By default lfs_malloc is used to allocate this buffer.\n    void *lookahead_buffer;\n\n    // Optional upper limit on length of file names in bytes. No downside for\n    // larger names except the size of the info struct which is controlled by\n    // the LFS_NAME_MAX define. Defaults to LFS_NAME_MAX or name_max stored on\n    // disk when zero.\n    lfs_size_t name_max;\n\n    // Optional upper limit on files in bytes. No downside for larger files\n    // but must be <= LFS_FILE_MAX. Defaults to LFS_FILE_MAX or file_max stored\n    // on disk when zero.\n    lfs_size_t file_max;\n\n    // Optional upper limit on custom attributes in bytes. No downside for\n    // larger attributes size but must be <= LFS_ATTR_MAX. Defaults to\n    // LFS_ATTR_MAX or attr_max stored on disk when zero.\n    lfs_size_t attr_max;\n\n    // Optional upper limit on total space given to metadata pairs in bytes. On\n    // devices with large blocks (e.g. 128kB) setting this to a low size (2-8kB)\n    // can help bound the metadata compaction time. Must be <= block_size.\n    // Defaults to block_size when zero.\n    lfs_size_t metadata_max;\n\n    // Optional upper limit on inlined files in bytes. Inlined files live in\n    // metadata and decrease storage requirements, but may be limited to\n    // improve metadata-related performance. Must be <= cache_size, <=\n    // attr_max, and <= block_size/8. Defaults to the largest possible\n    // inline_max when zero.\n    //\n    // Set to -1 to disable inlined files.\n    lfs_size_t inline_max;\n\n#ifdef LFS_MULTIVERSION\n    // On-disk version to use when writing in the form of 16-bit major version\n    // + 16-bit minor version. This limiting metadata to what is supported by\n    // older minor versions. Note that some features will be lost. Defaults to \n    // to the most recent minor version when zero.\n    uint32_t disk_version;\n#endif\n}\n</additional code>\n<target_code>\nHere is the code fragment that you need to analyze:\n```c\nfor (struct lfs_mlist **p = &head; *p; p = &(*p)->next) {\n        if (*p == (struct lfs_mlist*)node) {\n            return true;\n        }\n    }\n```\nFocus on the above code fragment and judge whether it violates the rule 14.2 or not.\n</target_code>\n",
  "is_rule_violated": false,
  "scenario": "The for loop is compliant: it defines and initializes a single loop counter 'p' in the first clause; the second clause '*p' is a pure expression with no persistent side effects and only uses the loop counter; the third clause 'p = &(*p)->next' modifies only the loop counter (it reads the next pointer but does not modify any object that the loop body alters); there is only one loop counter and it is not modified in the loop body. No called functions in the loop body introduce additional side effects."
}