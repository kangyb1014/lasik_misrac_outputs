{
  "user_message": "<misra_rule>\nMISRA C 2023 Rule 8.13 is: A pointer should point to a const-qualified type whenever possible.\n\n</misra_rule>\n<response format>\nProvide your answer with these fields.\n- is_rule_violated: whether the rule is violated or not (true/false),\n- scenario: a specific violation scenario.\n</response format>\n<target_code>\nHere is the code of mhd_tool_get_system_cpu_count:\n```c\nint\nmhd_tool_get_system_cpu_count (void)\n{\n  int res;\n\n  /* Try specialised APIs first */\n  res = mhd_tool_get_sys_cpu_count_special_api_ ();\n  if (0 < res)\n    return res;\n\n  /* Try sysctl*(). This is typically a direct interface to\n     kernel values. */\n  res = mhd_tool_get_sys_cpu_count_sysctl_ ();\n  if (0 < res)\n    return res;\n\n  /* Try sysconf() as the last resort as this is a generic interface\n     which can be implemented by parsing system files. */\n  res = mhd_tool_get_sys_cpu_count_sysconf_ ();\n#if ! defined(__linux__) && ! defined(__GLIBC__)\n  if (0 < res)\n    return res;\n#else  /* __linux__ || __GLIBC__ */\n  if (2 < res)\n    return res;\n  if (0 < res)\n  {\n    /* '1' or '2' could a be fallback number.\n     * See get_nprocs_fallback() in glibc\n       sysdeps/unix/sysv/linux/getsysstats.c */\n\n    int proc_cpu_count;\n\n    proc_cpu_count = mhd_tool_get_proc_cpu_count ();\n    if (proc_cpu_count == res)\n    {\n      /* The detected number of CPUs available for the process\n         is equal to the detected number of system CPUs.\n         Assume detected number is correct. */\n      return res;\n    }\n  }\n#endif /* __linux__ || __GLIBC__  */\n\n  /* Try available fallbacks */\n\n  res = mhd_tool_get_sys_cpu_count_sysctl_fallback_ ();\n  if (0 < res)\n    return res;\n\n  res = mhd_tool_get_sys_cpu_count_sysconf_fallback_ ();\n#if ! defined(__linux__) && ! defined(__GLIBC__)\n  if (0 < res)\n    return res;\n#else  /* __linux__ || __GLIBC__ */\n  if (2 < res)\n    return res;\n#endif /* __linux__ || __GLIBC__  */\n\n  return -1; /* Cannot detect */\n}\n```\n</target_code>\n<additional code>Here are the definitions of symbols that are close to the target function mhd_tool_get_system_cpu_count:\nstatic int\nmhd_tool_get_sys_cpu_count_special_api_ (void)\n{\n  int ret = -1;\n#ifdef HAVE_PSTAT_GETDYNAMIC\n  if (0 >= ret)\n  {\n    /* HP-UX things */\n    struct pst_dynamic psd_data;\n    memset ((void *) &psd_data, 0, sizeof (psd_data));\n    if (1 == pstat_getdynamic (&psd_data, sizeof (psd_data), (size_t) 1, 0))\n    {\n      if (0 < psd_data.psd_proc_cnt)\n        ret = (int) psd_data.psd_proc_cnt;\n    }\n  }\n#endif /* HAVE_PSTAT_GETDYNAMIC */\n#ifdef HAVE_VXCPUENABLEDGET\n  if (0 >= ret)\n  {\n    /* VxWorks */\n    cpuset_t enb_set;\n    enb_set = vxCpuEnabledGet ();\n    /* Count set bits */\n    for (ret = 0; 0 != enb_set; enb_set &= enb_set - 1)\n      ++ret;\n  }\n#endif /* HAVE_VXCPUENABLEDGET */\n#if defined(_WIN32) && ! defined (__CYGWIN__)\n  if (0 >= ret)\n  {\n    /* Native W32 */\n    HMODULE k32hndl;\n    k32hndl = LoadLibraryA (\"kernel32.dll\");\n    if (NULL != k32hndl)\n    {\n      typedef DWORD (WINAPI *GAPC_PTR)(WORD GroupNumber);\n      GAPC_PTR ptrGetActiveProcessorCount;\n      /* Available on W7 or later */\n      ptrGetActiveProcessorCount =\n        (GAPC_PTR) (void *) GetProcAddress (k32hndl, \"GetActiveProcessorCount\");\n      if (NULL != ptrGetActiveProcessorCount)\n      {\n        DWORD res;\n        res = ptrGetActiveProcessorCount (ALL_PROCESSOR_GROUPS);\n        ret = (int) res;\n        if (res != (DWORD) ret)\n          ret = -1; /* Overflow */\n      }\n    }\n    if ((0 >= ret) && (NULL != k32hndl))\n    {\n      typedef void (WINAPI *GNSI_PTR)(SYSTEM_INFO *pSysInfo);\n      GNSI_PTR ptrGetNativeSystemInfo;\n      /* May give incorrect (low) result on versions from W7 to W11\n         when more then 64 CPUs are available */\n      ptrGetNativeSystemInfo =\n        (GNSI_PTR) (void *) GetProcAddress (k32hndl, \"GetNativeSystemInfo\");\n      if (NULL != ptrGetNativeSystemInfo)\n      {\n        SYSTEM_INFO sysInfo;\n\n        memset ((void *) &sysInfo, 0, sizeof (sysInfo));\n        ptrGetNativeSystemInfo (&sysInfo);\n        ret = (int) sysInfo.dwNumberOfProcessors;\n        if (sysInfo.dwNumberOfProcessors != (DWORD) ret)\n          ret = -1; /* Overflow */\n      }\n    }\n    if (NULL != k32hndl)\n      FreeLibrary (k32hndl);\n  }\n  if (0 >= ret)\n  {\n    /* May give incorrect (low) result on versions from W7 to W11\n       when more then 64 CPUs are available */\n    SYSTEM_INFO sysInfo;\n    memset ((void *) &sysInfo, 0, sizeof (sysInfo));\n    GetSystemInfo (&sysInfo);\n    ret = (int) sysInfo.dwNumberOfProcessors;\n    if (sysInfo.dwNumberOfProcessors != (DWORD) ret)\n      ret = -1; /* Overflow */\n  }\n#endif /* _WIN32 && ! __CYGWIN__ */\n  if (0 >= ret)\n    return -1;\n  return ret;\n}\n...\nstatic int\nmhd_tool_get_sys_cpu_count_sysctl_ (void)\n{\n  int ret = -1;\n  /* Do not use sysctl() function on GNU/Linux even if\n     sysctl() is available */\n#ifndef __linux__\n#ifdef HAVE_SYSCTLBYNAME\n  if (0 >= ret)\n  {\n    size_t value_size = sizeof (ret);\n    /* Darwin: The number of available logical CPUs */\n    if ((0 != sysctlbyname (\"hw.logicalcpu\", &ret, &value_size,\n                            NULL, 0))\n        || (sizeof (ret) != value_size))\n      ret = -1;\n  }\n  if (0 >= ret)\n  {\n    size_t value_size = sizeof (ret);\n    /* FreeBSD: The number of online CPUs */\n    if ((0 != sysctlbyname (\"kern.smp.cpus\", &ret, &value_size,\n                            NULL, 0))\n        || (sizeof (ret) != value_size))\n      ret = -1;\n  }\n  if (0 >= ret)\n  {\n    size_t value_size = sizeof (ret);\n    /* Darwin: The current number of CPUs available to run threads */\n    if ((0 != sysctlbyname (\"hw.activecpu\", &ret, &value_size,\n                            NULL, 0))\n        || (sizeof (ret) != value_size))\n      ret = -1;\n  }\n  if (0 >= ret)\n  {\n    size_t value_size = sizeof (ret);\n    /* OpenBSD, NetBSD: The number of online CPUs */\n    if ((0 != sysctlbyname (\"hw.ncpuonline\", &ret, &value_size,\n                            NULL, 0))\n        || (sizeof (ret) != value_size))\n      ret = -1;\n  }\n  if (0 >= ret)\n  {\n    size_t value_size = sizeof (ret);\n    /* Darwin: The old/alternative name for \"hw.activecpu\" */\n    if ((0 != sysctlbyname (\"hw.availcpu\", &ret, &value_size,\n                            NULL, 0))\n        || (sizeof (ret) != value_size))\n      ret = -1;\n  }\n#endif /* HAVE_SYSCTLBYNAME */\n#if defined(HAVE_SYSCTL) && \\\n  defined(HAS_DECL_CTL_HW) && \\\n  defined(HAS_DECL_HW_NCPUONLINE)\n  if (0 >= ret)\n  {\n    /* OpenBSD, NetBSD: The number of online CPUs */\n    int mib[2] = {CTL_HW, HW_NCPUONLINE};\n    size_t value_size = sizeof (ret);\n    if ((0 != sysctl (mib, 2, &ret, &value_size, NULL, 0))\n        || (sizeof (ret) != value_size))\n      ret = -1;\n  }\n#endif /* HAVE_SYSCTL && HAS_DECL_CTL_HW && HAS_DECL_HW_NCPUONLINE */\n#if defined(HAVE_SYSCTL) && \\\n  defined(HAS_DECL_CTL_HW) && \\\n  defined(HAS_DECL_HW_AVAILCPU)\n  if (0 >= ret)\n  {\n    /* Darwin: The MIB name for \"hw.activecpu\" */\n    int mib[2] = {CTL_HW, HW_AVAILCPU};\n    size_t value_size = sizeof (ret);\n    if ((0 != sysctl (mib, 2, &ret, &value_size, NULL, 0))\n        || (sizeof (ret) != value_size))\n      ret = -1;\n  }\n#endif /* HAVE_SYSCTL && HAS_DECL_CTL_HW && HAS_DECL_HW_AVAILCPU */\n#endif /* ! __linux__ */\n  if (0 >= ret)\n    return -1;\n  return ret;\n}\n...\nstatic int\nmhd_tool_get_sys_cpu_count_sysconf_ (void)\n{\n  int ret = -1;\n#if defined(HAVE_SYSCONF) && \\\n  (defined(HAS_DECL__SC_NPROCESSORS_ONLN) || defined(HAS_DECL__SC_NPROC_ONLN))\n  long value = -1;\n#ifdef HAS_DECL__SC_NPROCESSORS_ONLN\n  if (0 >= value)\n    value = sysconf (_SC_NPROCESSORS_ONLN);\n#endif /* HAS_DECL__SC_NPROCESSORS_ONLN */\n#ifdef HAS_DECL__SC_NPROC_ONLN\n  if (0 >= value)\n    value = sysconf (_SC_NPROC_ONLN);\n#endif /* HAS_DECL__SC_NPROC_ONLN */\n  if (0 >= value)\n    return -1;\n  ret = (int) value;\n  if ((long) ret != value)\n    return -1; /* Overflow */\n#endif /* HAVE_SYSCONF &&\n          (HAS_DECL__SC_NPROCESSORS_ONLN || HAS_DECL__SC_NPROC_ONLN) */\n  return ret;\n}\n...\nint\nmhd_tool_get_proc_cpu_count (void)\n{\n  int res;\n\n#if defined(__linux__) || defined(__GLIBC__)\n  /* On Linux kernel try first 'sched_getaffinity()' as it should be\n     the native API.\n     Also try it first on other kernels if Glibc is used. */\n  res = mhd_tool_get_proc_cpu_count_sched_getaffinity_ ();\n  if (0 < res)\n    return res;\n\n  res = mhd_tool_get_proc_cpu_count_cpuset_getaffinity_ ();\n  if (0 < res)\n    return res;\n#else  /* ! __linux__ && ! __GLIBC__ */\n  /* On non-Linux kernels 'cpuset_getaffinity()' could be the native API,\n     while 'sched_getaffinity()' could be implemented in compatibility layer. */\n  res = mhd_tool_get_proc_cpu_count_cpuset_getaffinity_ ();\n  if (0 < res)\n    return res;\n\n  res = mhd_tool_get_proc_cpu_count_sched_getaffinity_ ();\n  if (0 < res)\n    return res;\n#endif /* ! __linux__ && ! __GLIBC__ */\n\n  res = mhd_tool_get_proc_cpu_count_sched_getaffinity_np_ ();\n  if (0 < res)\n    return res;\n\n  res = mhd_tool_get_proc_cpu_count_w32_ ();\n  if (0 < res)\n    return res;\n\n  return -1;\n}\n...\nstatic int\nmhd_tool_get_sys_cpu_count_sysctl_fallback_ (void)\n{\n  int ret = -1;\n  /* Do not use sysctl() function on GNU/Linux even if\n     sysctl() is available */\n#ifndef __linux__\n#ifdef HAVE_SYSCTLBYNAME\n  if (0 >= ret)\n  {\n    size_t value_size = sizeof (ret);\n    /* FreeBSD, OpenBSD, NetBSD, Darwin (and others?): The number of CPUs */\n    if ((0 != sysctlbyname (\"hw.ncpu\", &ret, &value_size,\n                            NULL, 0))\n        || (sizeof (ret) != value_size))\n      ret = -1;\n  }\n#endif /* HAVE_SYSCTLBYNAME */\n#if defined(HAVE_SYSCTL) && \\\n  defined(HAS_DECL_CTL_HW) && \\\n  defined(HAS_DECL_HW_NCPU)\n  if (0 >= ret)\n  {\n    /* FreeBSD, OpenBSD, NetBSD, Darwin (and others?): The number of CPUs */\n    int mib[2] = {CTL_HW, HW_NCPU};\n    size_t value_size = sizeof (ret);\n    if ((0 != sysctl (mib, 2, &ret, &value_size, NULL, 0))\n        || (sizeof (ret) != value_size))\n      ret = -1;\n  }\n#endif /* HAVE_SYSCTL && HAS_DECL_CTL_HW && HAS_DECL_HW_NCPU */\n#endif /* ! __linux__ */\n  if (0 >= ret)\n    return -1;\n  return ret;\n}\n...\nstatic int\nmhd_tool_get_sys_cpu_count_sysconf_fallback_ (void)\n{\n  int ret = -1;\n#if defined(HAVE_SYSCONF) && \\\n  (defined(HAS_DECL__SC_CRAY_NCPU) || defined(HAS_DECL__SC_NPROCESSORS_CONF))\n  long value = -1;\n#ifdef HAS_DECL__SC_CRAY_NCPU\n  if (0 >= value)\n    value = sysconf (_SC_CRAY_NCPU);\n#endif /* HAS_DECL__SC_CRAY_NCPU */\n#ifdef HAS_DECL__SC_NPROCESSORS_CONF\n  if (0 >= value)\n    value = sysconf (_SC_NPROCESSORS_CONF);\n#endif /* HAS_DECL__SC_NPROCESSORS_CONF */\n  if (0 >= value)\n    return -1;\n  ret = (int) value;\n  if ((long) ret != value)\n    return -1; /* Overflow */\n#endif /* HAVE_SYSCONF &&\n          (HAS_DECL__SC_CRAY_NCPU || HAS_DECL__SC_NPROCESSORS_CONF) */\n  return ret;\n}\n...\nstatic int\nmhd_tool_get_proc_cpu_count_sched_getaffinity_ (void)\n{\n  int ret = -1;\n#if defined(HAVE_SCHED_GETAFFINITY) && defined(HAVE_GETPID)\n  /* Glibc style */\n  if (0 >= ret)\n  {\n    cpu_set_t cur_set;\n    if (0 == sched_getaffinity (getpid (), sizeof (cur_set), &cur_set))\n    {\n#ifdef HAVE_CPU_COUNT\n      ret = CPU_COUNT (&cur_set);\n#else  /* ! HAVE_CPU_COUNT */\n      unsigned int i;\n      ret = 0;\n      for (i = 0; i < CPU_SETSIZE_SAFE; ++i)\n      {\n        if (CPU_ISSET (i, &cur_set))\n          ++ret;\n      }\n      if (0 == ret)\n        ret = -1;\n#endif /* ! HAVE_CPU_COUNT */\n    }\n  }\n#ifdef HAVE_CPU_COUNT_S\n  if (0 >= ret)\n  {\n    /* Use 256 times larger size than size for default maximum CPU number.\n       Hopefully it would be enough even for exotic situations. */\n    static const unsigned int set_size_cpus = 256 * CPU_SETSIZE;\n    const size_t set_size_bytes = CPU_ALLOC_SIZE (set_size_cpus);\n    cpu_set_t *p_set;\n\n    p_set = CPU_ALLOC (set_size_cpus);\n    if (NULL != p_set)\n    {\n      if (0 == sched_getaffinity (getpid (), set_size_bytes, p_set))\n      {\n#ifndef MHD_FUNC_CPU_COUNT_S_GETS_CPUS\n        ret = CPU_COUNT_S (set_size_bytes, p_set);\n#else  /* MHD_FUNC_CPU_COUNT_S_GETS_CPUS */\n        ret = CPU_COUNT_S (set_size_cpus, p_set);\n#endif /* MHD_FUNC_CPU_COUNT_S_GETS_CPUS */\n      }\n      CPU_FREE (p_set);\n    }\n  }\n#endif /* HAVE_CPU_COUNT_S */\n#endif /* HAVE_SCHED_GETAFFINITY && HAVE_GETPID */\n  if (0 >= ret)\n    return -1;\n  return ret;\n}\n...\nstatic int\nmhd_tool_get_proc_cpu_count_cpuset_getaffinity_ (void)\n{\n  int ret = -1;\n#if defined(HAVE_CPUSET_GETAFFINITY)\n  /* FreeBSD style */\n  if (0 >= ret)\n  {\n    cpuset_t cur_mask;\n    /* The should get \"anonymous\" mask/set. The anonymous mask is always\n       a subset of the assigned set (which is a subset of the root set). */\n    if (0 == cpuset_getaffinity (CPU_LEVEL_WHICH, CPU_WHICH_PID, (id_t) -1,\n                                 sizeof (cur_mask), &cur_mask))\n    {\n#ifdef HAVE_CPU_COUNT\n      ret = CPU_COUNT (&cur_mask);\n#else  /* ! HAVE_CPU_COUNT */\n      unsigned int i;\n      ret = 0;\n      for (i = 0; i < CPU_SETSIZE_SAFE; ++i)\n      {\n        if (CPU_ISSET (i, &cur_mask))\n          ++ret;\n      }\n      if (0 == ret)\n        ret = -1;\n#endif /* ! HAVE_CPU_COUNT */\n    }\n  }\n#ifdef HAVE_CPU_COUNT_S\n  if (0 >= ret)\n  {\n    /* Use 256 times larger size than size for default maximum CPU number.\n       Hopefully it would be enough even for exotic situations. */\n    static const unsigned int mask_size_cpus = 256 * CPU_SETSIZE;\n    const size_t mask_size_bytes = CPU_ALLOC_SIZE (mask_size_cpus);\n    cpuset_t *p_mask;\n\n    p_mask = CPU_ALLOC (mask_size_cpus);\n    if (NULL != p_mask)\n    {\n      if (0 == cpuset_getaffinity (CPU_LEVEL_WHICH, CPU_WHICH_PID, (id_t) -1,\n                                   mask_size_bytes, p_mask))\n      {\n#ifndef MHD_FUNC_CPU_COUNT_S_GETS_CPUS\n        ret = CPU_COUNT_S (mask_size_bytes, p_mask);\n#else  /* MHD_FUNC_CPU_COUNT_S_GETS_CPUS */\n        ret = CPU_COUNT_S (mask_size_cpus, p_mask);\n#endif /* MHD_FUNC_CPU_COUNT_S_GETS_CPUS */\n      }\n      CPU_FREE (p_mask);\n    }\n  }\n#endif /* HAVE_CPU_COUNT_S */\n#endif /* HAVE_CPUSET_GETAFFINITY */\n  if (0 >= ret)\n    return -1;\n  return ret;\n}\n...\nstatic int\nmhd_tool_get_proc_cpu_count_sched_getaffinity_np_ (void)\n{\n  int ret = -1;\n#if defined(HAVE_SCHED_GETAFFINITY_NP) && defined(HAVE_GETPID)\n  /* NetBSD style */\n  cpuset_t *cpuset_ptr;\n  cpuset_ptr = cpuset_create ();\n  if (NULL != cpuset_ptr)\n  {\n    if (0 == sched_getaffinity_np (getpid (), cpuset_size (cpuset_ptr),\n                                   cpuset_ptr))\n    {\n      cpuid_t cpu_num;\n#if defined(HAVE_SYSCONF) && defined(HAVE_DECL__SC_NPROCESSORS_CONF)\n      unsigned int max_num = 0;\n      long sc_value;\n      sc_value = sysconf (_SC_NPROCESSORS_ONLN);\n      if (0 < sc_value)\n        max_num = (unsigned int) sc_value;\n      if (0 < max_num)\n      {\n        ret = 0;\n        for (cpu_num = 0; cpu_num < max_num; ++cpu_num)\n          if (0 < cpuset_isset (cpu_num, cpuset_ptr))\n            ++ret;\n      }\n      else /* Combined with the next 'if' */\n#endif /* HAVE_SYSCONF && HAVE_DECL__SC_NPROCESSORS_CONF */\n      if (1)\n      {\n        int res;\n        cpu_num = 0;\n        ret = 0;\n        do\n        {\n          res = cpuset_isset (cpu_num++, cpuset_ptr);\n          if (0 < res)\n            ++ret;\n        } while (0 <= res);\n      }\n#ifdef __NetBSD__\n      if (0 == ret)\n      {\n        /* On NetBSD \"unset\" affinity (exactly zero CPUs) means\n           \"all CPUs are available\". */\n        ret = mhd_tool_get_sys_cpu_count_sysctl_ ();\n      }\n#endif /* __NetBSD__ */\n    }\n    cpuset_destroy (cpuset_ptr);\n  }\n#endif /* HAVE_SCHED_GETAFFINITY_NP && HAVE_GETPID */\n  if (0 >= ret)\n    return -1;\n  return ret;\n}\n...\nstatic int\nmhd_tool_get_proc_cpu_count_w32_ (void)\n{\n  int ret = -1;\n#if defined(_WIN32) && ! defined(__CYGWIN__)\n  /* W32 Native */\n  /**\n   * Maximum used number of CPU groups.\n   * Improvement: Implement dynamic allocation when it would be reasonable\n   */\n#define MHDT_MAX_GROUP_COUNT 128\n  /**\n   * The count of logical CPUs as returned by GetProcessAffinityMask()\n   */\n  int count_by_proc_aff_mask;\n  count_by_proc_aff_mask = -1;\n  if (1)\n  {\n    DWORD_PTR proc_aff;\n    DWORD_PTR sys_aff;\n\n    if (GetProcessAffinityMask (GetCurrentProcess (), &proc_aff, &sys_aff))\n    {\n      /* Count all set bits */\n      for (count_by_proc_aff_mask = 0; 0 != proc_aff; proc_aff &= proc_aff - 1)\n        ++count_by_proc_aff_mask;\n    }\n  }\n  if (0 < count_by_proc_aff_mask)\n  {\n    HMODULE k32hndl;\n    k32hndl = LoadLibraryA (\"kernel32.dll\");\n    if (NULL != k32hndl)\n    {\n      typedef BOOL (WINAPI *GPGA_PTR)(HANDLE hProcess,\n                                      PUSHORT GroupCount,\n                                      PUSHORT GroupArray);\n      GPGA_PTR ptrGetProcessGroupAffinity;\n      ptrGetProcessGroupAffinity =\n        (GPGA_PTR) (void *) GetProcAddress (k32hndl,\n                                            \"GetProcessGroupAffinity\");\n      if (NULL == ptrGetProcessGroupAffinity)\n      {\n        /* Windows version before Win7 */\n        /* No processor groups supported, the process affinity mask gives full picture */\n        ret = count_by_proc_aff_mask;\n      }\n      else\n      {\n        /* Windows version Win7 or later */\n        /* Processor groups are supported */\n        USHORT arr_elements = MHDT_MAX_GROUP_COUNT;\n        USHORT groups_arr[MHDT_MAX_GROUP_COUNT]; /* Hopefully should be enough */\n        /* Improvement: Implement dynamic allocation when it would be reasonable */\n        /**\n         * Exactly one processor group is assigned to the process\n         */\n        bool single_cpu_group_assigned; /**< Exactly one processor group is assigned to the process */\n        struct mhdt_GR_AFFINITY\n        {\n          KAFFINITY Mask;\n          WORD Group;\n          WORD Reserved[3];\n        };\n        typedef BOOL (WINAPI *GPDCSM_PTR)(HANDLE Process,\n                                          struct mhdt_GR_AFFINITY *CpuSetMasks,\n                                          USHORT CpuSetMaskCount,\n                                          USHORT *RequiredMaskCount);\n        GPDCSM_PTR ptrGetProcessDefaultCpuSetMasks;\n        bool win_fe_or_later;\n        bool cpu_set_mask_assigned;\n\n        single_cpu_group_assigned = false;\n        if (ptrGetProcessGroupAffinity (GetCurrentProcess (), &arr_elements,\n                                        groups_arr))\n        {\n          if (1 == arr_elements)\n          {\n            /* Exactly one processor group assigned to the process */\n            single_cpu_group_assigned = true;\n#if 0 /* Disabled code */\n            /* The value returned by GetThreadGroupAffinity() is not relevant as\n               for the new threads the process affinity mask is used. */\n            ULONG_PTR proc_aff2;\n            typedef BOOL (WINAPI *GTGA_PTR)(HANDLE hThread,\n                                            struct mhdt_GR_AFFINITY *\n                                            GroupAffinity);\n            GTGA_PTR ptrGetThreadGroupAffinity;\n            ptrGetThreadGroupAffinity =\n              (GTGA_PTR) (void *) GetProcAddress (k32hndl,\n                                                  \"GetThreadGroupAffinity\");\n            if (NULL != ptrGetThreadGroupAffinity)\n            {\n              struct mhdt_GR_AFFINITY thr_gr_aff;\n              if (ptrGetThreadGroupAffinity (GetCurrentThread (), &thr_gr_aff))\n                proc_aff2 = (ULONG_PTR) thr_gr_aff.Mask;\n            }\n#endif /* Disabled code */\n          }\n        }\n        ptrGetProcessDefaultCpuSetMasks =\n          (GPDCSM_PTR) (void *) GetProcAddress (k32hndl,\n                                                \"GetProcessDefaultCpuSetMasks\");\n        if (NULL != ptrGetProcessDefaultCpuSetMasks)\n        {\n          /* This is Iron Release / Codename Fe\n             (also know as Windows 11 and Windows Server 2022)\n             or later version */\n          struct mhdt_GR_AFFINITY gr_affs[MHDT_MAX_GROUP_COUNT]; /* Hopefully should be enough */\n          /* Improvement: Implement dynamic allocation when it would be reasonable */\n          USHORT num_elm;\n\n          win_fe_or_later = true;\n\n          if (ptrGetProcessDefaultCpuSetMasks (GetCurrentProcess (), gr_affs,\n                                               sizeof (gr_affs)\n                                               / sizeof (gr_affs[0]), &num_elm))\n          {\n            if (0 == num_elm)\n            {\n              /* No group mask set */\n              cpu_set_mask_assigned = false;\n            }\n            else\n              cpu_set_mask_assigned = true;\n          }\n          else\n            cpu_set_mask_assigned = true; /* Assume the worst case */\n        }\n        else\n        {\n          win_fe_or_later = false;\n          cpu_set_mask_assigned = false;\n        }\n        if (! win_fe_or_later)\n        {\n          /* The OS is not capable of distributing threads across different\n             processor groups. Results reported by GetProcessAffinityMask()\n             are relevant for the main processor group for the process. */\n          ret = count_by_proc_aff_mask;\n        }\n        else\n        {\n          /* The of is capable of automatic threads distribution across\n             processor groups. */\n          if (cpu_set_mask_assigned)\n          {\n            /* Assigned Default CpuSet Masks combines with \"classic\"\n               affinity in the not fully clear way. The combination\n               is not documented and this functionality could be changed\n               any moment. */\n            ret = -1;\n          }\n          else\n          {\n            if (! single_cpu_group_assigned)\n            {\n              /* This is a multi processor group process on Win11 (or later).\n                 Each processor group may have different affinity and\n                 the OS has not API to get it.\n                 For example, affinity to the main processor group could be\n                 assigned by SetProcessAffinityMask() function, which converts\n                 the process to the single-processor-group type, but if\n                 SetThreadGroupAffinity() is called later and bind the thread\n                 to another processor group, the process becomes multi-processor-\n                 group again, however the initial affinity mask is still used\n                 for the initial (main) processor group. There is no API to read\n                 it.\n                 It is also possible that processor groups have different number\n                 of processors. */\n              ret = -1;\n            }\n            else\n            {\n              /* Single-processor-group process on Win11 (or later) without\n                 assigned Default CpuSet Masks. */\n              ret = count_by_proc_aff_mask;\n            }\n          }\n        }\n      }\n      FreeLibrary (k32hndl);\n    }\n  }\n#endif /* _WIN32 && ! __CYGWIN__ */\n  if (0 >= ret)\n    return -1;\n  return ret;\n}\n</additional code>\n<target_code>\nHere is the code fragment that you need to analyze:\n```c\ncpuset_destroy (cpuset_ptr);\n```\nFocus on the above code fragment and judge whether it violates the rule 8.13 or not.\n</target_code>\n",
  "is_rule_violated": false,
  "scenario": "The pointer cpuset_ptr refers to a modifiable cpuset_t object returned by cpuset_create(), passed to sched_getaffinity_np() to be filled and later destroyed by cpuset_destroy(). Because the object is modified and deallocated, it cannot reasonably be const-qualified; therefore the call cpuset_destroy(cpuset_ptr) does not violate Rule 8.13."
}