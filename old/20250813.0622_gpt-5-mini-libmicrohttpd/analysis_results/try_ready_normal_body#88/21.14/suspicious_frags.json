{
  "user_message": "<misra_rule>\nThe target MISRA C 2023 Rule 21.14 is: The Standard Library function memcmp shall not be used to compare null terminated strings.\n\n</misra_rule>\n<instruction>\nOther agents will judge whether the code follows the MISRA C 2023 guidelines.\nThey will investigate the code fragments you give.\nYour job is to find code fragments in the code that should be investigated to check whether the code follows the MISRA C rule.\n</instruction>\n<response format>\nProvide your answer with these fields.\n- suspicious_frags: The list of suspicious code fragments in the code.\nIt should contain only the code fragments exists in the code. If you do not find any suspicious code fragments, return an empty list for suspicious_frags\n- explanation: The explanation of why other code fragments should NOT be investigated.\nIt is very important to not miss any suspicious code fragments, so please give a sufficient explanation why other code fragments should not be investigated.\nDO NOT give any explanation for the selected suspicious code fragments.\n</response format>\n<target_code>\nHere is the code of try_ready_normal_body:\n```c\nstatic enum MHD_Result\ntry_ready_normal_body (struct MHD_Connection *connection)\n{\n  ssize_t ret;\n  struct MHD_Response *response;\n\n  response = connection->rp.response;\n  mhd_assert (connection->rp.props.send_reply_body);\n\n  if ( (0 == response->total_size) ||\n                     /* TODO: replace the next check with assert */\n       (connection->rp.rsp_write_position == response->total_size) )\n    return MHD_YES;  /* 0-byte response is always ready */\n  if (NULL != response->data_iov)\n  {\n    size_t copy_size;\n\n    if (NULL != connection->rp.resp_iov.iov)\n      return MHD_YES;\n    copy_size = response->data_iovcnt * sizeof(MHD_iovec_);\n    connection->rp.resp_iov.iov = MHD_connection_alloc_memory_ (connection,\n                                                                copy_size);\n    if (NULL == connection->rp.resp_iov.iov)\n    {\n      MHD_mutex_unlock_chk_ (&response->mutex);\n      /* not enough memory */\n      CONNECTION_CLOSE_ERROR (connection,\n                              _ (\"Closing connection (out of memory).\"));\n      return MHD_NO;\n    }\n    memcpy (connection->rp.resp_iov.iov,\n            response->data_iov,\n            copy_size);\n    connection->rp.resp_iov.cnt = response->data_iovcnt;\n    connection->rp.resp_iov.sent = 0;\n    return MHD_YES;\n  }\n  if (NULL == response->crc)\n    return MHD_YES;\n  if ( (response->data_start <=\n        connection->rp.rsp_write_position) &&\n       (response->data_size + response->data_start >\n        connection->rp.rsp_write_position) )\n    return MHD_YES; /* response already ready */\n#if defined(_MHD_HAVE_SENDFILE)\n  if (MHD_resp_sender_sendfile == connection->rp.resp_sender)\n  {\n    /* will use sendfile, no need to bother response crc */\n    return MHD_YES;\n  }\n#endif /* _MHD_HAVE_SENDFILE */\n\n  ret = response->crc (response->crc_cls,\n                       connection->rp.rsp_write_position,\n                       (char *) response->data,\n                       (size_t) MHD_MIN ((uint64_t) response->data_buffer_size,\n                                         response->total_size\n                                         - connection->rp.rsp_write_position));\n  if (0 > ret)\n  {\n    /* either error or http 1.0 transfer, close socket! */\n    /* TODO: do not update total size, check whether response\n     * was really with unknown size */\n    response->total_size = connection->rp.rsp_write_position;\n#if defined(MHD_USE_POSIX_THREADS) || defined(MHD_USE_W32_THREADS)\n    MHD_mutex_unlock_chk_ (&response->mutex);\n#endif\n    if (MHD_CONTENT_READER_END_OF_STREAM == ret)\n      MHD_connection_close_ (connection,\n                             MHD_REQUEST_TERMINATED_COMPLETED_OK);\n    else\n      CONNECTION_CLOSE_ERROR (connection,\n                              _ (\"Closing connection (application reported \" \\\n                                 \"error generating data).\"));\n    return MHD_NO;\n  }\n  response->data_start = connection->rp.rsp_write_position;\n  response->data_size = (size_t) ret;\n  if (0 == ret)\n  {\n    connection->state = MHD_CONNECTION_NORMAL_BODY_UNREADY;\n#if defined(MHD_USE_POSIX_THREADS) || defined(MHD_USE_W32_THREADS)\n    MHD_mutex_unlock_chk_ (&response->mutex);\n#endif\n    return MHD_NO;\n  }\n  return MHD_YES;\n}\n```\n</target_code>\n<additional code>Here are the definitions of symbols that are related to the target function try_ready_normal_body:\n_MHD_EXTERN struct MHD_Response *\nMHD_create_response_from_callback (uint64_t size,\n                                   size_t block_size,\n                                   MHD_ContentReaderCallback crc,\n                                   void *crc_cls,\n                                   MHD_ContentReaderFreeCallback crfc)\n{\n  struct MHD_Response *response;\n\n  if ((NULL == crc) || (0 == block_size))\n    return NULL;\n  if (NULL == (response = MHD_calloc_ (1, sizeof (struct MHD_Response)\n                                       + block_size)))\n    return NULL;\n  response->fd = -1;\n  response->data = (void *) &response[1];\n  response->data_buffer_size = block_size;\n#if defined(MHD_USE_POSIX_THREADS) || defined(MHD_USE_W32_THREADS)\n  if (! MHD_mutex_init_ (&response->mutex))\n  {\n    free (response);\n    return NULL;\n  }\n#endif\n  response->crc = crc;\n  response->crfc = crfc;\n  response->crc_cls = crc_cls;\n  response->reference_count = 1;\n  response->total_size = size;\n  return response;\n}\n...\n_MHD_EXTERN struct MHD_Response *\nMHD_create_response_from_buffer (size_t size,\n                                 void *buffer,\n                                 enum MHD_ResponseMemoryMode mode)\n{\n  if (MHD_RESPMEM_MUST_FREE == mode)\n    return MHD_create_response_from_buffer_with_free_callback_cls (size,\n                                                                   buffer,\n                                                                   &free,\n                                                                   buffer);\n  if (MHD_RESPMEM_MUST_COPY == mode)\n    return MHD_create_response_from_buffer_copy (size,\n                                                 buffer);\n\n  return MHD_create_response_from_buffer_with_free_callback_cls (size,\n                                                                 buffer,\n                                                                 NULL,\n                                                                 NULL);\n}\n...\n_MHD_EXTERN struct MHD_Response *\nMHD_create_response_from_data (size_t size,\n                               void *data,\n                               int must_free,\n                               int must_copy)\n{\n  enum MHD_ResponseMemoryMode mode;\n\n  if (0 != must_copy)\n    mode = MHD_RESPMEM_MUST_COPY;\n  else if (0 != must_free)\n    mode = MHD_RESPMEM_MUST_FREE;\n  else\n    mode = MHD_RESPMEM_PERSISTENT;\n\n  return MHD_create_response_from_buffer (size, data, mode);\n}\n...\n_MHD_EXTERN struct MHD_Response *\nMHD_create_response_from_iovec (const struct MHD_IoVec *iov,\n                                unsigned int iovcnt,\n                                MHD_ContentReaderFreeCallback free_cb,\n                                void *cls)\n{\n  struct MHD_Response *response;\n  unsigned int i;\n  int i_cp = 0;   /**< Index in the copy of iov */\n  uint64_t total_size = 0;\n  const void *last_valid_buffer = NULL;\n\n  if ((NULL == iov) && (0 < iovcnt))\n    return NULL;\n\n  response = MHD_calloc_ (1, sizeof (struct MHD_Response));\n  if (NULL == response)\n    return NULL;\n  if (! MHD_mutex_init_ (&response->mutex))\n  {\n    free (response);\n    return NULL;\n  }\n  /* Calculate final size, number of valid elements, and check 'iov' */\n  for (i = 0; i < iovcnt; ++i)\n  {\n    if (0 == iov[i].iov_len)\n      continue;     /* skip zero-sized elements */\n    if (NULL == iov[i].iov_base)\n    {\n      i_cp = -1;     /* error */\n      break;\n    }\n    if ( (total_size > (total_size + iov[i].iov_len)) ||\n         (INT_MAX == i_cp) ||\n         (SSIZE_MAX < (total_size + iov[i].iov_len)) )\n    {\n      i_cp = -1;     /* overflow */\n      break;\n    }\n    last_valid_buffer = iov[i].iov_base;\n    total_size += iov[i].iov_len;\n#if defined(MHD_POSIX_SOCKETS) || ! defined(_WIN64)\n    i_cp++;\n#else  /* ! MHD_POSIX_SOCKETS && _WIN64 */\n    {\n      int64_t i_add;\n\n      i_add = (int64_t) (iov[i].iov_len / ULONG_MAX);\n      if (0 != iov[i].iov_len % ULONG_MAX)\n        i_add++;\n      if (INT_MAX < (i_add + i_cp))\n      {\n        i_cp = -1;   /* overflow */\n        break;\n      }\n      i_cp += (int) i_add;\n    }\n#endif /* ! MHD_POSIX_SOCKETS && _WIN64 */\n  }\n  if (-1 == i_cp)\n  {\n    /* Some error condition */\n    MHD_mutex_destroy_chk_ (&response->mutex);\n    free (response);\n    return NULL;\n  }\n  response->fd = -1;\n  response->reference_count = 1;\n  response->total_size = total_size;\n  response->crc_cls = cls;\n  response->crfc = free_cb;\n  if (0 == i_cp)\n  {\n    mhd_assert (0 == total_size);\n    return response;\n  }\n  if (1 == i_cp)\n  {\n    mhd_assert (NULL != last_valid_buffer);\n    response->data = last_valid_buffer;\n    response->data_size = (size_t) total_size;\n    return response;\n  }\n  mhd_assert (1 < i_cp);\n  if (1)\n  { /* for local variables local scope only */\n    MHD_iovec_ *iov_copy;\n    int num_copy_elements = i_cp;\n\n    iov_copy = MHD_calloc_ ((size_t) num_copy_elements, \\\n                            sizeof(MHD_iovec_));\n    if (NULL == iov_copy)\n    {\n      MHD_mutex_destroy_chk_ (&response->mutex);\n      free (response);\n      return NULL;\n    }\n    i_cp = 0;\n    for (i = 0; i < iovcnt; ++i)\n    {\n      size_t element_size = iov[i].iov_len;\n      const uint8_t *buf = (const uint8_t *) iov[i].iov_base;\n\n      if (0 == element_size)\n        continue;         /* skip zero-sized elements */\n#if defined(MHD_WINSOCK_SOCKETS) && defined(_WIN64)\n      while (MHD_IOV_ELMN_MAX_SIZE < element_size)\n      {\n        iov_copy[i_cp].iov_base = (char *) _MHD_DROP_CONST (buf);\n        iov_copy[i_cp].iov_len = ULONG_MAX;\n        buf += ULONG_MAX;\n        element_size -= ULONG_MAX;\n        i_cp++;\n      }\n#endif /* MHD_WINSOCK_SOCKETS && _WIN64 */\n      iov_copy[i_cp].iov_base = _MHD_DROP_CONST (buf);\n      iov_copy[i_cp].iov_len = (MHD_iov_size_) element_size;\n      i_cp++;\n    }\n    mhd_assert (num_copy_elements == i_cp);\n    mhd_assert (0 <= i_cp);\n    response->data_iov = iov_copy;\n    response->data_iovcnt = (unsigned int) i_cp;\n  }\n  return response;\n}\n...\nvoid *\nMHD_connection_alloc_memory_ (struct MHD_Connection *connection,\n                              size_t size)\n{\n  struct MHD_Connection *const c = connection; /* a short alias */\n  struct MemoryPool *const pool = c->pool;     /* a short alias */\n  size_t need_to_be_freed = 0; /**< The required amount of additional free memory */\n  void *res;\n\n  res = MHD_pool_try_alloc (pool,\n                            size,\n                            &need_to_be_freed);\n  if (NULL != res)\n    return res;\n\n  if (MHD_pool_is_resizable_inplace (pool,\n                                     c->write_buffer,\n                                     c->write_buffer_size))\n  {\n    if (c->write_buffer_size - c->write_buffer_append_offset >=\n        need_to_be_freed)\n    {\n      char *buf;\n      const size_t new_buf_size = c->write_buffer_size - need_to_be_freed;\n      buf = MHD_pool_reallocate (pool,\n                                 c->write_buffer,\n                                 c->write_buffer_size,\n                                 new_buf_size);\n      mhd_assert (c->write_buffer == buf);\n      mhd_assert (c->write_buffer_append_offset <= new_buf_size);\n      mhd_assert (c->write_buffer_send_offset <= new_buf_size);\n      c->write_buffer_size = new_buf_size;\n      c->write_buffer = buf;\n    }\n    else\n      return NULL;\n  }\n  else if (MHD_pool_is_resizable_inplace (pool,\n                                          c->read_buffer,\n                                          c->read_buffer_size))\n  {\n    if (c->read_buffer_size - c->read_buffer_offset >= need_to_be_freed)\n    {\n      char *buf;\n      const size_t new_buf_size = c->read_buffer_size - need_to_be_freed;\n      buf = MHD_pool_reallocate (pool,\n                                 c->read_buffer,\n                                 c->read_buffer_size,\n                                 new_buf_size);\n      mhd_assert (c->read_buffer == buf);\n      mhd_assert (c->read_buffer_offset <= new_buf_size);\n      c->read_buffer_size = new_buf_size;\n      c->read_buffer = buf;\n    }\n    else\n      return NULL;\n  }\n  else\n    return NULL;\n  res = MHD_pool_allocate (pool, size, true);\n  mhd_assert (NULL != res); /* It has been checked that pool has enough space */\n  return res;\n}\n...\nvoid *\nMHD_pool_try_alloc (struct MemoryPool *pool,\n                    size_t size,\n                    size_t *required_bytes)\n{\n  void *ret;\n  size_t asize;\n\n  mhd_assert (pool->end >= pool->pos);\n  mhd_assert (pool->size >= pool->end - pool->pos);\n  mhd_assert (pool->pos == ROUND_TO_ALIGN (pool->pos));\n  asize = ROUND_TO_ALIGN_PLUS_RED_ZONE (size);\n  if ( (0 == asize) && (0 != size) )\n  { /* size is too close to SIZE_MAX, very unlikely */\n    *required_bytes = SIZE_MAX;\n    return NULL;\n  }\n  if (asize > pool->end - pool->pos)\n  {\n    mhd_assert ((pool->end - pool->pos) == \\\n                ROUND_TO_ALIGN (pool->end - pool->pos));\n    if (asize <= pool->end)\n      *required_bytes = asize - (pool->end - pool->pos);\n    else\n      *required_bytes = SIZE_MAX;\n    return NULL;\n  }\n  *required_bytes = 0;\n  ret = &pool->memory[pool->end - asize];\n  pool->end -= asize;\n  _MHD_UNPOISON_MEMORY (ret, size);\n  return ret;\n}\n...\nvoid *\nMHD_pool_reallocate (struct MemoryPool *pool,\n                     void *old,\n                     size_t old_size,\n                     size_t new_size)\n{\n  size_t asize;\n  uint8_t *new_blc;\n\n  mhd_assert (pool->end >= pool->pos);\n  mhd_assert (pool->size >= pool->end - pool->pos);\n  mhd_assert (old != NULL || old_size == 0);\n  mhd_assert (pool->size >= old_size);\n  mhd_assert (pool->pos == ROUND_TO_ALIGN (pool->pos));\n#if defined(MHD_ASAN_POISON_ACTIVE) && defined(HAVE___ASAN_REGION_IS_POISONED)\n  mhd_assert (NULL == __asan_region_is_poisoned (old, old_size));\n#endif /* MHD_ASAN_POISON_ACTIVE && HAVE___ASAN_REGION_IS_POISONED */\n\n  if (NULL != old)\n  {   /* Have previously allocated data */\n    const size_t old_offset = mp_ptr_diff_ (old, pool->memory);\n    const bool shrinking = (old_size > new_size);\n\n    mhd_assert (mp_ptr_le_ (pool->memory, old));\n    /* (pool->memory + pool->size >= (uint8_t*) old + old_size) */\n    mhd_assert ((pool->size - _MHD_RED_ZONE_SIZE) >= (old_offset + old_size));\n    /* Blocks \"from the end\" must not be reallocated */\n    /* (old_size == 0 || pool->memory + pool->pos > (uint8_t*) old) */\n    mhd_assert ((old_size == 0) || \\\n                (pool->pos > old_offset));\n    mhd_assert ((old_size == 0) || \\\n                ((pool->end - _MHD_RED_ZONE_SIZE) >= (old_offset + old_size)));\n    /* Try resizing in-place */\n    if (shrinking)\n    {     /* Shrinking in-place, zero-out freed part */\n      memset ((uint8_t *) old + new_size, 0, old_size - new_size);\n      _MHD_POISON_MEMORY ((uint8_t *) old + new_size, old_size - new_size);\n    }\n    if (pool->pos ==\n        ROUND_TO_ALIGN_PLUS_RED_ZONE (old_offset + old_size))\n    {     /* \"old\" block is the last allocated block */\n      const size_t new_apos =\n        ROUND_TO_ALIGN_PLUS_RED_ZONE (old_offset + new_size);\n      if (! shrinking)\n      {                               /* Grow in-place, check for enough space. */\n        if ( (new_apos > pool->end) ||\n             (new_apos < pool->pos) ) /* Value wrap */\n          return NULL;                /* No space */\n      }\n      /* Resized in-place */\n      pool->pos = new_apos;\n      _MHD_UNPOISON_MEMORY (old, new_size);\n      return old;\n    }\n    if (shrinking)\n      return old;   /* Resized in-place, freed part remains allocated */\n  }\n  /* Need to allocate new block */\n  asize = ROUND_TO_ALIGN_PLUS_RED_ZONE (new_size);\n  if ( ( (0 == asize) &&\n         (0 != new_size) ) || /* Value wrap, too large new_size. */\n       (asize > pool->end - pool->pos) ) /* Not enough space */\n    return NULL;\n\n  new_blc = pool->memory + pool->pos;\n  pool->pos += asize;\n\n  _MHD_UNPOISON_MEMORY (new_blc, new_size);\n  if (0 != old_size)\n  {\n    /* Move data to new block, old block remains allocated */\n    memcpy (new_blc, old, old_size);\n    /* Zero-out old block */\n    memset (old, 0, old_size);\n    _MHD_POISON_MEMORY (old, old_size);\n  }\n  return new_blc;\n}\n...\nvoid *\nMHD_pool_allocate (struct MemoryPool *pool,\n                   size_t size,\n                   bool from_end)\n{\n  void *ret;\n  size_t asize;\n\n  mhd_assert (pool->end >= pool->pos);\n  mhd_assert (pool->size >= pool->end - pool->pos);\n  mhd_assert (pool->pos == ROUND_TO_ALIGN (pool->pos));\n  asize = ROUND_TO_ALIGN_PLUS_RED_ZONE (size);\n  if ( (0 == asize) && (0 != size) )\n    return NULL; /* size too close to SIZE_MAX */\n  if (asize > pool->end - pool->pos)\n    return NULL;\n  if (from_end)\n  {\n    ret = &pool->memory[pool->end - asize];\n    pool->end -= asize;\n  }\n  else\n  {\n    ret = &pool->memory[pool->pos];\n    pool->pos += asize;\n  }\n  _MHD_UNPOISON_MEMORY (ret, size);\n  return ret;\n}\n...\nstatic void\nconnection_close_error (struct MHD_Connection *connection,\n                        const char *emsg)\n{\n  connection->stop_with_error = true;\n  connection->discard_request = true;\n#ifdef HAVE_MESSAGES\n  if (NULL != emsg)\n    MHD_DLOG (connection->daemon,\n              \"%s\\n\",\n              emsg);\n#else  /* ! HAVE_MESSAGES */\n  (void) emsg; /* Mute compiler warning. */\n#endif /* ! HAVE_MESSAGES */\n  MHD_connection_close_ (connection,\n                         MHD_REQUEST_TERMINATED_WITH_ERROR);\n}\n...\nvoid\nMHD_DLOG (const struct MHD_Daemon *daemon,\n          const char *format,\n          ...)\n{\n  va_list va;\n\n  if (0 == (daemon->options & MHD_USE_ERROR_LOG))\n    return;\n  va_start (va, format);\n  daemon->custom_error_log (daemon->custom_error_log_cls,\n                            format,\n                            va);\n  va_end (va);\n}\n...\nvoid\nMHD_connection_close_ (struct MHD_Connection *connection,\n                       enum MHD_RequestTerminationCode termination_code)\n{\n  struct MHD_Daemon *daemon = connection->daemon;\n  struct MHD_Response *resp = connection->rp.response;\n\n  mhd_assert (! connection->suspended);\n#ifdef MHD_USE_THREADS\n  mhd_assert ( (! MHD_D_IS_USING_THREADS_ (daemon)) || \\\n               MHD_thread_handle_ID_is_current_thread_ (connection->tid) );\n#endif /* MHD_USE_THREADS */\n  if ( (NULL != daemon->notify_completed) &&\n       (connection->rq.client_aware) )\n    daemon->notify_completed (daemon->notify_completed_cls,\n                              connection,\n                              &connection->rq.client_context,\n                              termination_code);\n  connection->rq.client_aware = false;\n  if (NULL != resp)\n  {\n    connection->rp.response = NULL;\n    MHD_destroy_response (resp);\n  }\n  if (NULL != connection->pool)\n  {\n    MHD_pool_destroy (connection->pool);\n    connection->pool = NULL;\n  }\n\n  MHD_connection_mark_closed_ (connection);\n}\n...\n_MHD_EXTERN void\nMHD_destroy_response (struct MHD_Response *response)\n{\n  struct MHD_HTTP_Res_Header *pos;\n\n  if (NULL == response)\n    return;\n#if defined(MHD_USE_POSIX_THREADS) || defined(MHD_USE_W32_THREADS)\n  MHD_mutex_lock_chk_ (&response->mutex);\n#endif\n  if (0 != --(response->reference_count))\n  {\n#if defined(MHD_USE_POSIX_THREADS) || defined(MHD_USE_W32_THREADS)\n    MHD_mutex_unlock_chk_ (&response->mutex);\n#endif\n    return;\n  }\n#if defined(MHD_USE_POSIX_THREADS) || defined(MHD_USE_W32_THREADS)\n  MHD_mutex_unlock_chk_ (&response->mutex);\n  MHD_mutex_destroy_chk_ (&response->mutex);\n#endif\n  if (NULL != response->crfc)\n    response->crfc (response->crc_cls);\n\n  if (NULL != response->data_iov)\n  {\n    free (response->data_iov);\n  }\n\n  while (NULL != response->first_header)\n  {\n    pos = response->first_header;\n    response->first_header = pos->next;\n    free (pos->header);\n    free (pos->value);\n    free (pos);\n  }\n  free (response);\n}\n...\nvoid\nMHD_pool_destroy (struct MemoryPool *pool)\n{\n  if (NULL == pool)\n    return;\n\n  mhd_assert (pool->end >= pool->pos);\n  mhd_assert (pool->size >= pool->end - pool->pos);\n  mhd_assert (pool->pos == ROUND_TO_ALIGN (pool->pos));\n  _MHD_UNPOISON_MEMORY (pool->memory, pool->size);\n  if (! pool->is_mmap)\n    free (pool->memory);\n  else\n#if defined(MAP_ANONYMOUS) && ! defined(_WIN32)\n    munmap (pool->memory,\n            pool->size);\n#elif defined(_WIN32)\n    VirtualFree (pool->memory,\n                 0,\n                 MEM_RELEASE);\n#else\n    abort ();\n#endif\n  free (pool);\n}\n...\nvoid\nMHD_connection_mark_closed_ (struct MHD_Connection *connection)\n{\n  const struct MHD_Daemon *daemon = connection->daemon;\n\n  if (0 == (daemon->options & MHD_USE_TURBO))\n  {\n#ifdef HTTPS_SUPPORT\n    /* For TLS connection use shutdown of TLS layer\n     * and do not shutdown TCP socket. This give more\n     * chances to send TLS closure data to remote side.\n     * Closure of TLS layer will be interpreted by\n     * remote side as end of transmission. */\n    if (0 != (daemon->options & MHD_USE_TLS))\n    {\n      if (! MHD_tls_connection_shutdown (connection))\n        shutdown (connection->socket_fd,\n                  SHUT_WR);\n    }\n    else   /* Combined with next 'shutdown()'. */\n#endif /* HTTPS_SUPPORT */\n    shutdown (connection->socket_fd,\n              SHUT_WR);\n  }\n  connection->state = MHD_CONNECTION_CLOSED;\n  connection->event_loop_info = MHD_EVENT_LOOP_INFO_CLEANUP;\n}\n...\n#define MHD_mutex_unlock_chk_(pmutex) do{if(!MHD_mutex_unlock_(pmutex))MHD_PANIC(_(\"Failed to unlock mutex.\\n\"));\\\n}while(0)\n</additional code>\nPlease find suspicious code fragments in the code and report them. Other agents can not investigate other fragments that you do not report, so it is very important to find all suspicious fragments without missing any. Report the suspicious fragments AS MUCH AS POSSIBLE.",
  "suspicious_frags": [],
  "explanation": "I examined all provided code fragments (try_ready_normal_body and the additional supporting functions). There are no calls to memcmp anywhere in the supplied code. The memory functions present are memcpy and memset, which are used with explicit sizes (not relying on null-terminated string lengths): e.g. memcpy(connection->rp.resp_iov.iov, response->data_iov, copy_size), memcpy(new_blc, old, old_size), memset used to zero-out buffers. No usage of memcmp comparing C strings (no strlen or similar-derived lengths). Therefore there are no code fragments in the provided code that violate MISRA C 2023 Rule 21.14. If there are other source files not included here, they should be scanned for memcmp calls comparing null-terminated strings, but within the supplied codebase fragments none were found."
}